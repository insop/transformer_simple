{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVM, load transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isong/Downloads/ml/sc/xilinx/Github/transformer_simple/src/python\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "OPTIONS  Namespace(batch_size=4, debug=True, depth=1, embedding_size=128, final=False, gradient_clipping=1.0, lr=0.0001, lr_warmup=10000, max_length=512, max_pool=False, model_name='single_transformer.pt', num_epochs=1, num_heads=1, seed=1, tb_dir='./runs', tiny=True, vocab_size=50000)\n",
      "/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "- nr. of training examples 63\n",
      "- nr. of validation examples 63\n",
      "Model's state_dict:\n",
      "token_embedding.weight \t torch.Size([50000, 128])\n",
      "pos_embedding.weight \t torch.Size([512, 128])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.w_o.0.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.w_o.0.bias \t torch.Size([128])\n",
      "trfm_blocks.0.norm1.weight \t torch.Size([128])\n",
      "trfm_blocks.0.norm1.bias \t torch.Size([128])\n",
      "trfm_blocks.0.norm2.weight \t torch.Size([128])\n",
      "trfm_blocks.0.norm2.bias \t torch.Size([128])\n",
      "trfm_blocks.0.ff.0.weight \t torch.Size([512, 128])\n",
      "trfm_blocks.0.ff.0.bias \t torch.Size([512])\n",
      "trfm_blocks.0.ff.2.weight \t torch.Size([128, 512])\n",
      "trfm_blocks.0.ff.2.bias \t torch.Size([128])\n",
      "toprobs.weight \t torch.Size([2, 128])\n",
      "toprobs.bias \t torch.Size([2])\n",
      "token_embedding.weight \t tensor([[ 0.9528, -1.8734, -0.3153,  ..., -1.9832,  0.9401,  0.1321],\n",
      "        [-0.8664,  1.3177, -1.0324,  ...,  1.3094, -0.2082,  1.2808],\n",
      "        [ 0.7864, -0.1419,  0.1412,  ..., -0.5112,  0.1574,  0.0316],\n",
      "        ...,\n",
      "        [-0.9472,  1.5063, -0.1835,  ..., -0.3871, -0.4372,  1.7496],\n",
      "        [ 0.4858,  0.1672,  2.5334,  ..., -0.0217, -0.9964, -1.4022],\n",
      "        [-0.6406, -0.6163,  0.7169,  ..., -1.0507, -0.6153, -0.8775]])\n",
      "pos_embedding.weight \t tensor([[ 0.0504,  0.2696, -0.1473,  ..., -0.3330, -0.5856,  1.0192],\n",
      "        [ 0.3926,  0.1975,  0.0457,  ..., -1.5446,  0.1287, -1.3884],\n",
      "        [ 1.1817, -0.0450, -0.1341,  ...,  0.2380, -1.1963, -0.7562],\n",
      "        ...,\n",
      "        [ 1.5957, -1.4104, -0.8445,  ...,  0.1828, -0.1376, -1.9410],\n",
      "        [ 0.2597,  0.3515, -1.3016,  ..., -0.1396,  0.8884, -0.3777],\n",
      "        [-0.4044,  0.9151, -1.5379,  ...,  1.4077,  1.2072, -0.3265]])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.weight \t tensor([[-0.0307, -0.0246, -0.0167,  ...,  0.0539, -0.0230, -0.0455],\n",
      "        [-0.0465, -0.0297, -0.0005,  ...,  0.0175, -0.0766,  0.0476],\n",
      "        [ 0.0763,  0.0262,  0.0644,  ..., -0.0184,  0.0767,  0.0067],\n",
      "        ...,\n",
      "        [ 0.0658,  0.0761,  0.0624,  ...,  0.0511,  0.0217,  0.0701],\n",
      "        [-0.0246, -0.0156,  0.0551,  ..., -0.0343, -0.0629,  0.0087],\n",
      "        [-0.0410,  0.0833, -0.0456,  ...,  0.0107,  0.0766, -0.0836]])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.bias \t tensor([-0.0867,  0.0181, -0.0045, -0.0038,  0.0679, -0.0066,  0.0279,  0.0519,\n",
      "        -0.0156,  0.0434, -0.0029,  0.0441, -0.0723, -0.0104, -0.0196, -0.0740,\n",
      "         0.0379, -0.0716, -0.0542, -0.0594, -0.0018,  0.0634,  0.0151, -0.0209,\n",
      "        -0.0178,  0.0021, -0.0176,  0.0225, -0.0798, -0.0295,  0.0794,  0.0068,\n",
      "        -0.0096,  0.0594,  0.0798,  0.0668,  0.0851, -0.0436, -0.0020,  0.0618,\n",
      "         0.0366,  0.0787,  0.0092, -0.0513,  0.0188,  0.0627, -0.0449,  0.0246,\n",
      "         0.0502,  0.0081, -0.0540,  0.0574,  0.0469,  0.0854,  0.0596, -0.0708,\n",
      "         0.0731, -0.0057,  0.0454, -0.0120,  0.0857,  0.0178, -0.0364,  0.0077,\n",
      "        -0.0241,  0.0718,  0.0302, -0.0322, -0.0466, -0.0235,  0.0481,  0.0775,\n",
      "         0.0597,  0.0684,  0.0859, -0.0289, -0.0111, -0.0775, -0.0265, -0.0087,\n",
      "        -0.0409, -0.0131, -0.0467,  0.0273,  0.0484, -0.0732,  0.0405,  0.0593,\n",
      "        -0.0539,  0.0094, -0.0349,  0.0855, -0.0088,  0.0064, -0.0142, -0.0073,\n",
      "         0.0082, -0.0036,  0.0464, -0.0115, -0.0288, -0.0567, -0.0412,  0.0874,\n",
      "         0.0546, -0.0284, -0.0592,  0.0690,  0.0260,  0.0417,  0.0262, -0.0628,\n",
      "        -0.0775,  0.0819,  0.0795, -0.0630,  0.0553,  0.0815, -0.0052,  0.0848,\n",
      "        -0.0361, -0.0314,  0.0416,  0.0472, -0.0385,  0.0108, -0.0356,  0.0339])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.weight \t tensor([[-0.0857,  0.0520, -0.0292,  ...,  0.0862,  0.0271,  0.0144],\n",
      "        [ 0.0427,  0.0615, -0.0144,  ...,  0.0077, -0.0476,  0.0036],\n",
      "        [-0.0208,  0.0330,  0.0431,  ...,  0.0444, -0.0057, -0.0122],\n",
      "        ...,\n",
      "        [ 0.0139, -0.0018,  0.0031,  ..., -0.0241, -0.0550,  0.0094],\n",
      "        [-0.0776, -0.0708,  0.0733,  ...,  0.0107,  0.0247,  0.0865],\n",
      "        [ 0.0410,  0.0532, -0.0300,  ...,  0.0560, -0.0810,  0.0191]])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.bias \t tensor([-4.8202e-03,  8.1445e-02,  7.5708e-02,  3.4409e-02,  2.0249e-02,\n",
      "        -7.0641e-02, -8.7059e-04,  5.4776e-02, -2.4713e-02,  5.6421e-02,\n",
      "        -6.5438e-02, -2.7654e-02, -5.7940e-02,  3.8990e-02, -2.9223e-02,\n",
      "         4.9254e-02,  6.3391e-02,  4.3507e-02,  4.9026e-02,  1.0078e-02,\n",
      "         8.5898e-02, -4.4086e-02, -5.0966e-02, -5.8053e-02, -4.9382e-02,\n",
      "        -6.9788e-02, -3.0420e-02, -5.2333e-05, -2.8655e-02, -3.7869e-02,\n",
      "         5.7683e-02, -1.8381e-02,  8.7655e-02, -3.1795e-02,  1.9238e-02,\n",
      "         8.1809e-02,  4.6919e-02,  7.8818e-02, -6.1338e-02,  5.2758e-02,\n",
      "        -2.3586e-02,  7.6268e-02, -1.3142e-02, -2.5725e-03,  7.3329e-02,\n",
      "        -7.3970e-02, -6.0260e-02, -6.2280e-02,  8.3123e-02,  2.1363e-02,\n",
      "        -8.1637e-02,  7.4654e-02,  8.5065e-02,  4.8222e-02, -7.4368e-02,\n",
      "        -6.6834e-02, -8.0146e-02, -8.0723e-02,  4.1801e-02, -6.4414e-02,\n",
      "         7.6282e-02, -4.1288e-02,  2.6052e-02, -8.6553e-02,  8.3440e-02,\n",
      "        -7.1496e-02, -4.8327e-02,  1.4980e-02, -8.0395e-02,  3.9369e-02,\n",
      "         5.6583e-02,  3.2263e-02, -3.8569e-03, -4.8079e-02, -7.8327e-02,\n",
      "         6.0415e-02,  1.9682e-02,  8.0454e-02,  2.3073e-02, -4.3492e-02,\n",
      "        -5.1086e-02, -9.7601e-03, -3.5628e-02,  2.6938e-02,  2.3396e-02,\n",
      "        -8.6386e-02,  5.1139e-02, -7.4308e-02,  2.0656e-02,  7.1695e-02,\n",
      "         5.8293e-02, -3.8582e-02,  5.8478e-02,  2.4789e-02,  6.2318e-02,\n",
      "         7.2543e-02,  1.9619e-03,  3.1341e-02, -4.1071e-02,  6.0549e-02,\n",
      "        -7.8064e-02,  4.3041e-02,  8.7853e-02, -1.6866e-02,  5.6613e-02,\n",
      "        -6.4503e-02, -4.4391e-02,  4.1108e-02,  6.3904e-02, -7.6754e-02,\n",
      "         3.9786e-03,  8.7682e-02, -3.7967e-02, -3.9200e-02,  8.1433e-02,\n",
      "         7.3248e-02,  2.7484e-02, -5.2778e-02, -8.6621e-02, -3.5053e-02,\n",
      "         2.8074e-02, -5.4926e-02, -2.7989e-02,  7.7363e-02, -1.0657e-02,\n",
      "         2.3270e-02, -2.4987e-02, -6.7364e-02])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.weight \t tensor([[-0.0175, -0.0859, -0.0013,  ..., -0.0388,  0.0797, -0.0646],\n",
      "        [ 0.0861, -0.0799, -0.0633,  ..., -0.0745, -0.0434,  0.0763],\n",
      "        [ 0.0214,  0.0426, -0.0480,  ...,  0.0307, -0.0055, -0.0109],\n",
      "        ...,\n",
      "        [ 0.0397,  0.0861, -0.0442,  ..., -0.0784,  0.0312, -0.0343],\n",
      "        [-0.0850,  0.0281, -0.0554,  ..., -0.0651,  0.0201, -0.0308],\n",
      "        [-0.0871,  0.0246, -0.0597,  ..., -0.0147, -0.0443, -0.0419]])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.bias \t tensor([-8.5604e-02, -4.2746e-02,  2.1568e-02,  3.5606e-02, -6.4750e-02,\n",
      "         1.9079e-02,  2.6247e-02,  7.8018e-02,  4.2849e-02, -1.4836e-02,\n",
      "         2.1904e-02,  8.1135e-02,  5.0301e-02, -7.3105e-02,  2.0717e-02,\n",
      "         7.6604e-02, -3.6562e-02,  3.6614e-02, -1.9408e-02,  3.2141e-02,\n",
      "        -4.8473e-02,  2.5658e-02,  7.7058e-02,  8.5010e-02,  6.4587e-02,\n",
      "         7.4291e-02, -3.4060e-03, -1.2816e-02, -6.7004e-02,  3.3590e-02,\n",
      "         4.7102e-02,  7.3439e-02,  8.6892e-03, -1.7411e-02, -4.5809e-02,\n",
      "         6.1832e-02,  1.5504e-02,  4.8145e-02, -8.1396e-03, -3.7263e-02,\n",
      "        -8.7848e-03, -7.2210e-02,  1.7094e-02,  6.4376e-02, -2.4131e-03,\n",
      "         1.1090e-02,  3.7001e-02,  8.4781e-02,  3.7450e-02,  2.4306e-02,\n",
      "         5.5767e-02,  3.2023e-02,  4.6524e-02,  2.5064e-03, -6.2715e-02,\n",
      "         1.6014e-02,  1.5737e-02, -9.1451e-03,  5.1094e-02, -2.2896e-03,\n",
      "         1.5240e-02,  5.7543e-02,  3.3687e-03,  2.2770e-02, -7.8979e-02,\n",
      "         3.3271e-03,  8.1158e-02, -3.3446e-05,  2.5268e-02, -5.6015e-02,\n",
      "        -1.8242e-02, -7.5432e-02,  8.2174e-02,  6.7597e-02,  4.4754e-02,\n",
      "        -7.8346e-02,  7.0745e-03, -5.3314e-02, -3.3850e-02,  5.4979e-02,\n",
      "         3.0620e-03,  3.6197e-02,  8.5335e-02, -6.4582e-02,  6.7499e-02,\n",
      "        -5.0993e-02,  8.0693e-02,  7.6486e-02,  4.5181e-02,  1.0706e-02,\n",
      "         5.9889e-02,  4.4190e-02, -5.2705e-02, -9.9829e-03, -3.3111e-02,\n",
      "        -1.8118e-02, -8.3329e-02, -7.3791e-03, -1.2951e-03,  4.2319e-02,\n",
      "        -7.7402e-02, -3.9425e-02,  4.0822e-02, -7.9683e-02, -6.9291e-02,\n",
      "         7.0096e-02,  2.8994e-02, -2.7556e-03,  3.6040e-02, -3.2964e-03,\n",
      "         8.5637e-03, -2.1293e-02,  7.6486e-03, -6.8735e-02, -7.8819e-02,\n",
      "        -3.6978e-02, -5.0897e-03,  3.3067e-02, -3.0327e-02,  1.6842e-02,\n",
      "         3.6769e-03,  2.5413e-02,  6.3204e-02, -1.1390e-03, -2.4729e-02,\n",
      "         2.7646e-02,  3.7063e-02, -6.2483e-02])\n",
      "trfm_blocks.0.mha.w_o.0.weight \t tensor([[-0.0126,  0.0824,  0.0578,  ...,  0.0012, -0.0600,  0.0326],\n",
      "        [-0.0855, -0.0043,  0.0333,  ..., -0.0086,  0.0766,  0.0140],\n",
      "        [ 0.0120, -0.0321,  0.0272,  ..., -0.0153, -0.0605,  0.0025],\n",
      "        ...,\n",
      "        [ 0.0560, -0.0154, -0.0868,  ...,  0.0221,  0.0776, -0.0593],\n",
      "        [ 0.0205, -0.0513,  0.0241,  ..., -0.0873,  0.0675,  0.0525],\n",
      "        [-0.0151, -0.0692,  0.0606,  ..., -0.0092, -0.0771, -0.0369]])\n",
      "trfm_blocks.0.mha.w_o.0.bias \t tensor([ 0.0108, -0.0531, -0.0729, -0.0817,  0.0561, -0.0750, -0.0784, -0.0358,\n",
      "        -0.0584,  0.0063,  0.0450, -0.0315, -0.0857,  0.0327, -0.0536, -0.0117,\n",
      "         0.0875, -0.0205, -0.0095,  0.0823,  0.0737,  0.0619, -0.0665,  0.0782,\n",
      "        -0.0787, -0.0207, -0.0025,  0.0681,  0.0487, -0.0316, -0.0089,  0.0691,\n",
      "         0.0825, -0.0576,  0.0335, -0.0605, -0.0324,  0.0277, -0.0046,  0.0680,\n",
      "         0.0785, -0.0836, -0.0858, -0.0550,  0.0117,  0.0480, -0.0381,  0.0040,\n",
      "        -0.0761, -0.0008,  0.0875, -0.0035,  0.0264,  0.0424,  0.0169, -0.0219,\n",
      "         0.0780, -0.0583, -0.0844,  0.0163,  0.0592, -0.0823, -0.0121,  0.0574,\n",
      "        -0.0028,  0.0596,  0.0561, -0.0689,  0.0780,  0.0158,  0.0508, -0.0493,\n",
      "        -0.0541,  0.0344, -0.0143, -0.0698, -0.0415, -0.0197,  0.0346,  0.0242,\n",
      "        -0.0671, -0.0376, -0.0556,  0.0343,  0.0692,  0.0804,  0.0681,  0.0528,\n",
      "        -0.0115, -0.0714,  0.0372,  0.0095, -0.0677,  0.0512,  0.0516,  0.0697,\n",
      "         0.0723, -0.0463, -0.0321, -0.0539,  0.0579,  0.0672,  0.0861,  0.0218,\n",
      "        -0.0653,  0.0250,  0.0064, -0.0454, -0.0296, -0.0836, -0.0321, -0.0601,\n",
      "         0.0383,  0.0226,  0.0140, -0.0622,  0.0127,  0.0548,  0.0652,  0.0840,\n",
      "         0.0742,  0.0619,  0.0337,  0.0485, -0.0585,  0.0524,  0.0748,  0.0538])\n",
      "trfm_blocks.0.norm1.weight \t tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "trfm_blocks.0.norm1.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "trfm_blocks.0.norm2.weight \t tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "trfm_blocks.0.norm2.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "trfm_blocks.0.ff.0.weight \t tensor([[-0.0503,  0.0725,  0.0418,  ...,  0.0878,  0.0525,  0.0541],\n",
      "        [-0.0387, -0.0751,  0.0757,  ...,  0.0847, -0.0043,  0.0222],\n",
      "        [ 0.0555,  0.0787, -0.0325,  ...,  0.0040,  0.0596,  0.0636],\n",
      "        ...,\n",
      "        [-0.0424,  0.0161, -0.0189,  ..., -0.0350, -0.0188,  0.0269],\n",
      "        [-0.0597,  0.0209, -0.0913,  ..., -0.0766, -0.0648,  0.0384],\n",
      "        [ 0.0006, -0.0185, -0.0197,  ..., -0.0426,  0.0609, -0.0015]])\n",
      "trfm_blocks.0.ff.0.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "trfm_blocks.0.ff.2.weight \t tensor([[-0.0589, -0.0661,  0.0208,  ..., -0.0921,  0.0262,  0.0216],\n",
      "        [ 0.0699, -0.0348,  0.0564,  ..., -0.0256,  0.0096, -0.0270],\n",
      "        [-0.0772,  0.0137, -0.0891,  ..., -0.0664, -0.0950,  0.0816],\n",
      "        ...,\n",
      "        [-0.0607,  0.0068, -0.0254,  ...,  0.0087,  0.0882, -0.0519],\n",
      "        [ 0.0163, -0.0250, -0.0441,  ..., -0.0031,  0.0201, -0.0632],\n",
      "        [-0.0684, -0.0576,  0.0086,  ..., -0.0925,  0.0342, -0.0471]])\n",
      "trfm_blocks.0.ff.2.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "toprobs.weight \t tensor([[ 0.0390, -0.0582,  0.0740, -0.0141, -0.0310, -0.0328, -0.0191,  0.0020,\n",
      "         -0.0247, -0.0524,  0.0228,  0.0069,  0.0732,  0.0823,  0.0693, -0.0584,\n",
      "          0.0750, -0.0259,  0.0036, -0.0336,  0.0556,  0.0550, -0.0836, -0.0820,\n",
      "          0.0398, -0.0489,  0.0549, -0.0721, -0.0638,  0.0557, -0.0777,  0.0023,\n",
      "         -0.0679,  0.0247,  0.0582,  0.0545, -0.0606,  0.0596, -0.0832, -0.0121,\n",
      "          0.0313,  0.0744, -0.0320, -0.0036, -0.0716,  0.0393, -0.0118,  0.0010,\n",
      "         -0.0458, -0.0616, -0.0759, -0.0756, -0.0769, -0.0814,  0.0026,  0.0112,\n",
      "         -0.0172,  0.0858,  0.0858, -0.0414, -0.0527,  0.0444, -0.0083, -0.0221,\n",
      "         -0.0326,  0.0844,  0.0395, -0.0720, -0.0547,  0.0211, -0.0049, -0.0822,\n",
      "         -0.0566,  0.0838,  0.0824,  0.0219, -0.0211,  0.0031,  0.0872, -0.0603,\n",
      "          0.0280,  0.0346, -0.0812,  0.0365, -0.0113,  0.0593,  0.0624,  0.0339,\n",
      "         -0.0653, -0.0629, -0.0131, -0.0851,  0.0511,  0.0098,  0.0158, -0.0382,\n",
      "          0.0683,  0.0042, -0.0158, -0.0172,  0.0590, -0.0607,  0.0520,  0.0883,\n",
      "          0.0699,  0.0328, -0.0253, -0.0316, -0.0245, -0.0421,  0.0558,  0.0321,\n",
      "          0.0651, -0.0175, -0.0543,  0.0149, -0.0811, -0.0581, -0.0457, -0.0093,\n",
      "         -0.0458, -0.0803,  0.0032,  0.0469, -0.0294,  0.0183,  0.0771,  0.0560],\n",
      "        [-0.0318, -0.0476, -0.0273, -0.0175,  0.0653, -0.0664, -0.0790,  0.0796,\n",
      "          0.0127,  0.0431, -0.0268,  0.0237,  0.0343,  0.0576, -0.0290, -0.0797,\n",
      "          0.0454,  0.0878, -0.0282,  0.0835,  0.0811, -0.0568, -0.0229,  0.0702,\n",
      "          0.0752, -0.0217, -0.0568,  0.0644,  0.0328,  0.0287, -0.0774,  0.0333,\n",
      "         -0.0013, -0.0138, -0.0815,  0.0407, -0.0871, -0.0277,  0.0621,  0.0848,\n",
      "         -0.0006, -0.0313, -0.0568,  0.0847, -0.0134, -0.0533,  0.0178, -0.0087,\n",
      "         -0.0122, -0.0284,  0.0367, -0.0639, -0.0192, -0.0414, -0.0037,  0.0573,\n",
      "          0.0481,  0.0434, -0.0412,  0.0672,  0.0696,  0.0380, -0.0574,  0.0271,\n",
      "          0.0373,  0.0228, -0.0043,  0.0439,  0.0277,  0.0823, -0.0314, -0.0406,\n",
      "         -0.0160, -0.0036, -0.0271, -0.0566,  0.0856, -0.0078, -0.0017, -0.0663,\n",
      "          0.0106, -0.0803,  0.0220, -0.0642, -0.0686, -0.0112, -0.0370, -0.0622,\n",
      "          0.0717,  0.0601,  0.0300,  0.0382,  0.0396,  0.0012,  0.0074, -0.0137,\n",
      "          0.0407, -0.0566, -0.0609,  0.0835,  0.0352, -0.0479,  0.0447,  0.0037,\n",
      "         -0.0208, -0.0371,  0.0744, -0.0722,  0.0545, -0.0692, -0.0152,  0.0622,\n",
      "         -0.0228, -0.0097, -0.0564, -0.0412, -0.0685,  0.0122,  0.0550,  0.0007,\n",
      "         -0.0208, -0.0628,  0.0695, -0.0704,  0.0786,  0.0462,  0.0530,  0.0129]])\n",
      "toprobs.bias \t tensor([-0.0551,  0.0590])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}]\n",
      "\n",
      " epoch 0\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [00:04<00:00, 13.64it/s]\n",
      "-- validation accuracy 0.544\n",
      "Save model to saved_model/single_transformer.pt\n",
      "==============\n",
      "Load model to saved_model/single_transformer1.pt\n",
      "output_test\n",
      "tensor([[-0.7327, -0.6551],\n",
      "        [-0.7253, -0.6620],\n",
      "        [-0.7330, -0.6548],\n",
      "        [-0.7324, -0.6554]], grad_fn=<LogSoftmaxBackward>)\n",
      "output_load\n",
      "tensor([[-0.7327, -0.6551],\n",
      "        [-0.7253, -0.6620],\n",
      "        [-0.7330, -0.6548],\n",
      "        [-0.7324, -0.6554]])\n"
     ]
    }
   ],
   "source": [
    "!python ./experiments/classify.py -e 1 -t -d1 -H1 -D -m single_transformer.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pytorch model to tvm \n",
    "- [tvm reference](https://tvm.apache.org/docs/tutorials/frontend/from_pytorch.html#sphx-glr-tutorials-frontend-from-pytorch-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvm modules\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "from tvm import rpc, autotvm, relay\n",
    "from tvm.contrib import graph_runtime, download\n",
    "from tvm.contrib.debugger import debug_runtime\n",
    "from tvm.relay import transform\n",
    "from tvm import relay\n",
    "\n",
    "import vta\n",
    "from vta.testing import simulator\n",
    "from vta.top import graph_pack\n",
    "\n",
    "# Make sure that TVM was compiled with RPC=1\n",
    "assert tvm.runtime.enabled(\"rpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer modules\n",
    "\n",
    "import transformer_simple\n",
    "import classifier\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"transformer\"\n",
    "# single transformer\n",
    "mx = 512\n",
    "embedding_size = 128\n",
    "vocab_size = 50000\n",
    "NUM_CLS = 2\n",
    "max_pool = False\n",
    "num_heads = 1\n",
    "depth = 1\n",
    "\n",
    "PATH = 'saved_model/single_transformer1.pt'\n",
    "\n",
    "model = classifier.TransformerSimpleClassify(n_seq=mx, dim_emb=embedding_size, dim_internal=embedding_size, \\\n",
    "                                                         num_tokens=vocab_size, num_classes=NUM_CLS, max_pool=max_pool, \\\n",
    "                                                         heads=num_heads, depth=depth)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isong/Downloads/ml/sc/xilinx/Github/transformer_simple/src/python/transformer_simple.py:53: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert e == self.dim_emb, f'Input embedding ({e}) should match the layer embedding ({self.dim_emb})'\n"
     ]
    }
   ],
   "source": [
    "# We grab the TorchScripted model via tracing\n",
    "input_shape = [4, 498]\n",
    "input_data = torch.randint(0, vocab_size, input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the graph to Relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, input_shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type tensor_int8_t {\n",
      "  tensor_nil_int8,\n",
      "  tensor0_int8(int8),\n",
      "  tensor1_int8(Tensor[(?), int8]),\n",
      "  tensor2_int8(Tensor[(?, ?), int8]),\n",
      "  tensor3_int8(Tensor[(?, ?, ?), int8]),\n",
      "  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),\n",
      "  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),\n",
      "  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),\n",
      "}\n",
      "\n",
      "type tensor_uint16_t {\n",
      "  tensor_nil_uint16,\n",
      "  tensor0_uint16(uint16),\n",
      "  tensor1_uint16(Tensor[(?), uint16]),\n",
      "  tensor2_uint16(Tensor[(?, ?), uint16]),\n",
      "  tensor3_uint16(Tensor[(?, ?, ?), uint16]),\n",
      "  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),\n",
      "  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),\n",
      "  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),\n",
      "}\n",
      "\n",
      "type Option[A] {\n",
      "  Some(A),\n",
      "  None,\n",
      "}\n",
      "\n",
      "type tensor_uint8_t {\n",
      "  tensor_nil_uint8,\n",
      "  tensor0_uint8(uint8),\n",
      "  tensor1_uint8(Tensor[(?), uint8]),\n",
      "  tensor2_uint8(Tensor[(?, ?), uint8]),\n",
      "  tensor3_uint8(Tensor[(?, ?, ?), uint8]),\n",
      "  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),\n",
      "  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),\n",
      "  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),\n",
      "}\n",
      "\n",
      "type tensor_int16_t {\n",
      "  tensor_nil_int16,\n",
      "  tensor0_int16(int16),\n",
      "  tensor1_int16(Tensor[(?), int16]),\n",
      "  tensor2_int16(Tensor[(?, ?), int16]),\n",
      "  tensor3_int16(Tensor[(?, ?, ?), int16]),\n",
      "  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),\n",
      "  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),\n",
      "  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),\n",
      "}\n",
      "\n",
      "type List[A] {\n",
      "  Cons(A, List[A]),\n",
      "  Nil,\n",
      "}\n",
      "\n",
      "type tensor_float16_t {\n",
      "  tensor_nil_float16,\n",
      "  tensor0_float16(float16),\n",
      "  tensor1_float16(Tensor[(?), float16]),\n",
      "  tensor2_float16(Tensor[(?, ?), float16]),\n",
      "  tensor3_float16(Tensor[(?, ?, ?), float16]),\n",
      "  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),\n",
      "  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),\n",
      "  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),\n",
      "}\n",
      "\n",
      "type tensor_int32_t {\n",
      "  tensor_nil_int32,\n",
      "  tensor0_int32(int32),\n",
      "  tensor1_int32(Tensor[(?), int32]),\n",
      "  tensor2_int32(Tensor[(?, ?), int32]),\n",
      "  tensor3_int32(Tensor[(?, ?, ?), int32]),\n",
      "  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),\n",
      "  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),\n",
      "  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),\n",
      "}\n",
      "\n",
      "type Tree[A] {\n",
      "  Rose(A, List[Tree[A]]),\n",
      "}\n",
      "\n",
      "type tensor_int64_t {\n",
      "  tensor_nil_int64,\n",
      "  tensor0_int64(int64),\n",
      "  tensor1_int64(Tensor[(?), int64]),\n",
      "  tensor2_int64(Tensor[(?, ?), int64]),\n",
      "  tensor3_int64(Tensor[(?, ?, ?), int64]),\n",
      "  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),\n",
      "  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),\n",
      "  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),\n",
      "}\n",
      "\n",
      "type tensor_float32_t {\n",
      "  tensor_nil_float32,\n",
      "  tensor0_float32(float32),\n",
      "  tensor1_float32(Tensor[(?), float32]),\n",
      "  tensor2_float32(Tensor[(?, ?), float32]),\n",
      "  tensor3_float32(Tensor[(?, ?, ?), float32]),\n",
      "  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),\n",
      "  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),\n",
      "  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),\n",
      "}\n",
      "\n",
      "type tensor_float64_t {\n",
      "  tensor_nil_float64,\n",
      "  tensor0_float64(float64),\n",
      "  tensor1_float64(Tensor[(?), float64]),\n",
      "  tensor2_float64(Tensor[(?, ?), float64]),\n",
      "  tensor3_float64(Tensor[(?, ?, ?), float64]),\n",
      "  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),\n",
      "  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),\n",
      "  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),\n",
      "}\n",
      "\n",
      "def @main(%token_embedding.weight: Tensor[(50000, 128), float32], %input0: Tensor[(4, 498), int64], %pos_embedding.weight: Tensor[(512, 128), float32], %trfm_blocks.0.mha.attentions.0.toqueries.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.toqueries.bias: Tensor[(128), float32], %trfm_blocks.0.mha.attentions.0.tokeys.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.tokeys.bias: Tensor[(128), float32], %trfm_blocks.0.mha.attentions.0.tovalues.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.tovalues.bias: Tensor[(128), float32], %trfm_blocks.0.mha.w_o.0.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.w_o.0.bias: Tensor[(128), float32], %trfm_blocks.0.norm1.weight: Tensor[(128), float32], %trfm_blocks.0.norm1.bias: Tensor[(128), float32], %trfm_blocks.0.ff.0.weight: Tensor[(512, 128), float32], %trfm_blocks.0.ff.0.bias: Tensor[(512), float32], %trfm_blocks.0.ff.2.weight: Tensor[(128, 512), float32], %trfm_blocks.0.ff.2.bias: Tensor[(128), float32], %trfm_blocks.0.norm2.weight: Tensor[(128), float32], %trfm_blocks.0.norm2.bias: Tensor[(128), float32], %toprobs.weight: Tensor[(2, 128), float32], %toprobs.bias: Tensor[(2), float32]) -> Tensor[(4, 2), float32] {\n",
      "  %0 = cast(%input0, dtype=\"int32\") /* ty=Tensor[(4, 498), int32] */;\n",
      "  %1 = take(%token_embedding.weight, %0, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %2 = arange(0 /* ty=int64 */, 498 /* ty=int64 */, 1 /* ty=int64 */, start=meta[relay.Constant][0], stop=meta[relay.Constant][1], step=meta[relay.Constant][2], dtype=\"int64\") /* ty=Tensor[(498), int64] */;\n",
      "  %3 = cast(%2, dtype=\"int32\") /* ty=Tensor[(498), int32] */;\n",
      "  %4 = take(%pos_embedding.weight, %3, axis=0) /* ty=Tensor[(498, 128), float32] */;\n",
      "  %5 = expand_dims(%4, axis=0) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %6 = strided_slice(%5, begin=[0, 0, 0], end=[1, 498, 128], strides=[1, 1, 1]) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %7 = strided_slice(%6, begin=[0, 0, 0], end=[1, 498, 128], strides=[1, 1, 1]) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %8 = repeat(%7, repeats=4, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %9 = add(%1, %8) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %10 = nn.dropout(%9, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %11 = %10.0;\n",
      "  %12 = zeros_like(%11) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %13 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %14 = transpose(%trfm_blocks.0.mha.attentions.0.toqueries.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %15 = reshape(%14, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %16 = broadcast_to(%15, meta[relay.attrs.InitOpAttrs][0]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %17 = transpose(%16, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %18 = nn.batch_matmul(%13, %17) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %19 = reshape(%18, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %20 = add(%19, %trfm_blocks.0.mha.attentions.0.toqueries.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %21 = reshape(%20, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %22 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %23 = transpose(%trfm_blocks.0.mha.attentions.0.tokeys.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %24 = reshape(%23, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %25 = broadcast_to(%24, meta[relay.attrs.InitOpAttrs][1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %26 = transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %27 = nn.batch_matmul(%22, %26) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %28 = reshape(%27, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %29 = add(%28, %trfm_blocks.0.mha.attentions.0.tokeys.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %30 = transpose(%29, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %31 = reshape(%30, newshape=[-1, 128, 498]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %32 = transpose(%31, axes=[0, 2, 1]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %33 = nn.batch_matmul(%21, %32) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %34 = reshape(%33, newshape=[4, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %35 = divide(%34, 11.3137f /* ty=float32 */) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %36 = nn.softmax(%35, axis=2) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %37 = reshape(%36, newshape=[-1, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %38 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %39 = transpose(%trfm_blocks.0.mha.attentions.0.tovalues.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %40 = reshape(%39, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %41 = broadcast_to(%40, meta[relay.attrs.InitOpAttrs][2]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %42 = transpose(%41, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %43 = nn.batch_matmul(%38, %42) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %44 = reshape(%43, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %45 = add(%44, %trfm_blocks.0.mha.attentions.0.tovalues.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %46 = reshape(%45, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %47 = transpose(%46, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %48 = nn.batch_matmul(%37, %47) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %49 = reshape(%48, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %50 = reshape(%49, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %51 = transpose(%trfm_blocks.0.mha.w_o.0.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %52 = reshape(%51, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %53 = broadcast_to(%52, meta[relay.attrs.InitOpAttrs][3]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %54 = transpose(%53, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %55 = nn.batch_matmul(%50, %54) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %56 = reshape(%55, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %57 = add(%56, %trfm_blocks.0.mha.w_o.0.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %58 = add(%12, %57) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %59 = add(%58, %11) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %60 = nn.layer_norm(%59, %trfm_blocks.0.norm1.weight, %trfm_blocks.0.norm1.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %61 = nn.dropout(%60, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %62 = %61.0;\n",
      "  %63 = reshape(%62, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %64 = transpose(%trfm_blocks.0.ff.0.weight, axes=[1, 0]) /* ty=Tensor[(128, 512), float32] */;\n",
      "  %65 = reshape(%64, newshape=[-1, 128, 512]) /* ty=Tensor[(1, 128, 512), float32] */;\n",
      "  %66 = broadcast_to(%65, meta[relay.attrs.InitOpAttrs][4]) /* ty=Tensor[(4, 128, 512), float32] */;\n",
      "  %67 = transpose(%66, axes=[0, 2, 1]) /* ty=Tensor[(4, 512, 128), float32] */;\n",
      "  %68 = nn.batch_matmul(%63, %67) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %69 = reshape(%68, newshape=[4, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %70 = add(%69, %trfm_blocks.0.ff.0.bias) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %71 = nn.relu(%70) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %72 = reshape(%71, newshape=[-1, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %73 = transpose(%trfm_blocks.0.ff.2.weight, axes=[1, 0]) /* ty=Tensor[(512, 128), float32] */;\n",
      "  %74 = reshape(%73, newshape=[-1, 512, 128]) /* ty=Tensor[(1, 512, 128), float32] */;\n",
      "  %75 = broadcast_to(%74, meta[relay.attrs.InitOpAttrs][5]) /* ty=Tensor[(4, 512, 128), float32] */;\n",
      "  %76 = transpose(%75, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 512), float32] */;\n",
      "  %77 = nn.batch_matmul(%72, %76) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %78 = reshape(%77, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %79 = add(%78, %trfm_blocks.0.ff.2.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %80 = add(%79, %62) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %81 = nn.layer_norm(%80, %trfm_blocks.0.norm2.weight, %trfm_blocks.0.norm2.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %82 = nn.dropout(%81, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %83 = %82.0;\n",
      "  %84 = mean(%83, axis=[1]) /* ty=Tensor[(4, 128), float32] */;\n",
      "  %85 = transpose(%toprobs.weight, axes=[1, 0]) /* ty=Tensor[(128, 2), float32] */;\n",
      "  %86 = transpose(%85, axes=[1, 0]) /* ty=Tensor[(2, 128), float32] */;\n",
      "  %87 = nn.dense(%84, %86, units=2) /* ty=Tensor[(4, 2), float32] */;\n",
      "  %88 = add(%87, %toprobs.bias) /* ty=Tensor[(4, 2), float32] */;\n",
      "  nn.log_softmax(%88, axis=1) /* ty=Tensor[(4, 2), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VTA testing\n",
    "from https://tvm.apache.org/docs/vta/tutorials/frontend/deploy_classification.html#sphx-glr-vta-tutorials-frontend-deploy-classification-py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading VTA parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = vta.get_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the platform and model targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()\n",
    "\n",
    "# Set ``device=arm_cpu`` to run inference on the CPU\n",
    "# or ``device=vta`` to run inference on the FPGA.\n",
    "device = \"vta\"\n",
    "target = env.target if device == \"vta\" else env.target_vta_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPGA programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if env.TARGET not in [\"sim\", \"tsim\"]:\n",
    "\n",
    "    # Get remote from tracker node if environment variable is set.\n",
    "    # To set up the tracker, you'll need to follow the \"Auto-tuning\n",
    "    # a convolutional network for VTA\" tutorial.\n",
    "    tracker_host = os.environ.get(\"TVM_TRACKER_HOST\", None)\n",
    "    tracker_port = os.environ.get(\"TVM_TRACKER_PORT\", None)\n",
    "    # Otherwise if you have a device you want to program directly from\n",
    "    # the host, make sure you've set the variables below to the IP of\n",
    "    # your board.\n",
    "    device_host = os.environ.get(\"VTA_RPC_HOST\", \"192.168.2.99\")\n",
    "    device_port = os.environ.get(\"VTA_RPC_PORT\", \"9091\")\n",
    "    if not tracker_host or not tracker_port:\n",
    "        remote = rpc.connect(device_host, int(device_port))\n",
    "    else:\n",
    "        remote = autotvm.measure.request_remote(\n",
    "            env.TARGET, tracker_host, int(tracker_port), timeout=10000\n",
    "        )\n",
    "\n",
    "    # Reconfigure the JIT runtime and FPGA.\n",
    "    # You can program the FPGA with your own custom bitstream\n",
    "    # by passing the path to the bitstream file instead of None.\n",
    "    reconfig_start = time.time()\n",
    "    vta.reconfig_runtime(remote)\n",
    "    vta.program_fpga(remote, bitstream=None)\n",
    "    reconfig_time = time.time() - reconfig_start\n",
    "    print(\"Reconfigured FPGA and RPC runtime in {0:.2f}s!\".format(reconfig_time))\n",
    "\n",
    "# In simulation mode, host the RPC server locally.\n",
    "else:\n",
    "    remote = rpc.LocalSession()\n",
    "\n",
    "# Get execution context from remote\n",
    "ctx = remote.ext_dev(0) if device == \"vta\" else remote.cpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_vta = tvm.te.placeholder(input_shape, name=\"input\", dtype=env.acc_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ext_dev -keys=vta,cpu -device=vta -model=sim_1x16_i8w8a32_15_15_18_17"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the inference graph runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shape_dict = {}\n",
    "# dtype_dict = {}\n",
    "shape_dict.update({k: v.shape for k, v in params.items()})\n",
    "dtype_dict.update({k: str(v.dtype) for k, v in params.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toprobs.bias': (2,),\n",
       " 'toprobs.weight': (2, 128),\n",
       " 'trfm_blocks.0.norm2.bias': (128,),\n",
       " 'trfm_blocks.0.norm2.weight': (128,),\n",
       " 'trfm_blocks.0.ff.2.bias': (128,),\n",
       " 'trfm_blocks.0.ff.2.weight': (128, 512),\n",
       " 'trfm_blocks.0.ff.0.bias': (512,),\n",
       " 'trfm_blocks.0.ff.0.weight': (512, 128),\n",
       " 'trfm_blocks.0.norm1.bias': (128,),\n",
       " 'trfm_blocks.0.norm1.weight': (128,),\n",
       " 'trfm_blocks.0.mha.w_o.0.bias': (128,),\n",
       " 'trfm_blocks.0.mha.w_o.0.weight': (128, 128),\n",
       " 'trfm_blocks.0.mha.attentions.0.tovalues.bias': (128,),\n",
       " 'trfm_blocks.0.mha.attentions.0.tovalues.weight': (128, 128),\n",
       " 'trfm_blocks.0.mha.attentions.0.tokeys.bias': (128,),\n",
       " 'trfm_blocks.0.mha.attentions.0.tokeys.weight': (128, 128),\n",
       " 'trfm_blocks.0.mha.attentions.0.toqueries.bias': (128,),\n",
       " 'trfm_blocks.0.mha.attentions.0.toqueries.weight': (128, 128),\n",
       " 'pos_embedding.weight': (512, 128),\n",
       " 'token_embedding.weight': (50000, 128)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toprobs.bias': 'float32',\n",
       " 'toprobs.weight': 'float32',\n",
       " 'trfm_blocks.0.norm2.bias': 'float32',\n",
       " 'trfm_blocks.0.norm2.weight': 'float32',\n",
       " 'trfm_blocks.0.ff.2.bias': 'float32',\n",
       " 'trfm_blocks.0.ff.2.weight': 'float32',\n",
       " 'trfm_blocks.0.ff.0.bias': 'float32',\n",
       " 'trfm_blocks.0.ff.0.weight': 'float32',\n",
       " 'trfm_blocks.0.norm1.bias': 'float32',\n",
       " 'trfm_blocks.0.norm1.weight': 'float32',\n",
       " 'trfm_blocks.0.mha.w_o.0.bias': 'float32',\n",
       " 'trfm_blocks.0.mha.w_o.0.weight': 'float32',\n",
       " 'trfm_blocks.0.mha.attentions.0.tovalues.bias': 'float32',\n",
       " 'trfm_blocks.0.mha.attentions.0.tovalues.weight': 'float32',\n",
       " 'trfm_blocks.0.mha.attentions.0.tokeys.bias': 'float32',\n",
       " 'trfm_blocks.0.mha.attentions.0.tokeys.weight': 'float32',\n",
       " 'trfm_blocks.0.mha.attentions.0.toqueries.bias': 'float32',\n",
       " 'trfm_blocks.0.mha.attentions.0.toqueries.weight': 'float32',\n",
       " 'pos_embedding.weight': 'float32',\n",
       " 'token_embedding.weight': 'float32'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionNode([Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), Var(input0, ty=TensorType([4, 498], int64)), Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), Var(trfm_blocks.0.mha.attentions.0.toqueries.weight, ty=TensorType([128, 128], float32)), Var(trfm_blocks.0.mha.attentions.0.toqueries.bias, ty=TensorType([128], float32)), Var(trfm_blocks.0.mha.attentions.0.tokeys.weight, ty=TensorType([128, 128], float32)), Var(trfm_blocks.0.mha.attentions.0.tokeys.bias, ty=TensorType([128], float32)), Var(trfm_blocks.0.mha.attentions.0.tovalues.weight, ty=TensorType([128, 128], float32)), Var(trfm_blocks.0.mha.attentions.0.tovalues.bias, ty=TensorType([128], float32)), Var(trfm_blocks.0.mha.w_o.0.weight, ty=TensorType([128, 128], float32)), Var(trfm_blocks.0.mha.w_o.0.bias, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm1.weight, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm1.bias, ty=TensorType([128], float32)), Var(trfm_blocks.0.ff.0.weight, ty=TensorType([512, 128], float32)), Var(trfm_blocks.0.ff.0.bias, ty=TensorType([512], float32)), Var(trfm_blocks.0.ff.2.weight, ty=TensorType([128, 512], float32)), Var(trfm_blocks.0.ff.2.bias, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm2.weight, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm2.bias, ty=TensorType([128], float32)), Var(toprobs.weight, ty=TensorType([2, 128], float32)), Var(toprobs.bias, ty=TensorType([2], float32))], TensorType([4, 2], float32), CallNode(Op(nn.log_softmax), [CallNode(Op(add), [CallNode(Op(nn.dense), [CallNode(Op(mean), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(nn.layer_norm), [CallNode(Op(add), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(nn.relu), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(nn.layer_norm), [CallNode(Op(add), [CallNode(Op(add), [CallNode(Op(zeros_like), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], (nullptr), [TensorType([4, 498, 128], float32)]), CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(nn.softmax), [CallNode(Op(divide), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbccfbc6988), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.attentions.0.toqueries.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbd2e561cd8), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbccfbc9a38), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce87e1408), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce87b37b8), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce87e8408), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.attentions.0.toqueries.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], relay.attrs.ReshapeAttrs(0x7fbcc9aca3a8), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(reshape), [CallNode(Op(transpose), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbce93ac878), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.attentions.0.tokeys.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbcce4a6198), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce93897a8), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce91ac4f8), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce91d8718), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce9185c98), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.attentions.0.tokeys.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], relay.attrs.TransposeAttrs(0x7fbd2e56d018), [TensorType([4, 498, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbcc9a09a58), [TensorType([4, 128, 498], float32)])], relay.attrs.TransposeAttrs(0x7fbce91e1128), [TensorType([4, 128, 498], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce91e9ba8), [TensorType([4, 498, 498], float32)]), Constant(11.313708)], (nullptr), [TensorType([4, 498, 498], float32), TensorType([], float32)])], relay.attrs.SoftmaxAttrs(0x7fbce91e16c8), [TensorType([4, 498, 498], float32)])], relay.attrs.ReshapeAttrs(0x7fbcae5fa188), [TensorType([4, 498, 498], float32)]), CallNode(Op(transpose), [CallNode(Op(reshape), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbd2e5a21f8), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.attentions.0.tovalues.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbce93d3cd8), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbd2e5be2b8), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce92f0158), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce92c0ac8), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce92bc1a8), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.attentions.0.tovalues.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], relay.attrs.ReshapeAttrs(0x7fbcae5cf468), [TensorType([4, 498, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbccfbb97f8), [TensorType([4, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 498], float32), TensorType([4, 128, 498], float32)])], relay.attrs.ReshapeAttrs(0x7fbccfbc5218), [TensorType([4, 498, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce9373118), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.w_o.0.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbd2e5b8d58), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce93c06e8), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce91bb4c8), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce91d7988), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce91e9f48), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.w_o.0.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)]), TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.norm1.weight, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm1.bias, ty=TensorType([128], float32))], relay.attrs.LayerNormAttrs(0x7fbce91fe168), [TensorType([4, 498, 128], float32), TensorType([128], float32), TensorType([128], float32)])], relay.attrs.DropoutAttrs(0x7fbce91d89b8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbce92c2148), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.ff.0.weight, ty=TensorType([512, 128], float32))], relay.attrs.TransposeAttrs(0x7fbce92bb8b8), [TensorType([512, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce92fdba8), [TensorType([128, 512], float32)])], relay.attrs.InitOpAttrs(0x7fbce93a2de8), [TensorType([1, 128, 512], float32)])], relay.attrs.TransposeAttrs(0x7fbce937abb8), [TensorType([4, 128, 512], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 512, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce93aa2f8), [TensorType([4, 498, 512], float32)]), Var(trfm_blocks.0.ff.0.bias, ty=TensorType([512], float32))], (nullptr), [TensorType([4, 498, 512], float32), TensorType([512], float32)])], (nullptr), [TensorType([4, 498, 512], float32)])], relay.attrs.ReshapeAttrs(0x7fbce87f1db8), [TensorType([4, 498, 512], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.ff.2.weight, ty=TensorType([128, 512], float32))], relay.attrs.TransposeAttrs(0x7fbcce4ab078), [TensorType([128, 512], float32)])], relay.attrs.ReshapeAttrs(0x7fbce879eed8), [TensorType([512, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbd2e5a35e8), [TensorType([1, 512, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbd2e5bc038), [TensorType([4, 512, 128], float32)])], (nullptr), [TensorType([4, 498, 512], float32), TensorType([4, 128, 512], float32)])], relay.attrs.ReshapeAttrs(0x7fbd2e59c548), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.ff.2.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)]), TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(nn.layer_norm), [CallNode(Op(add), [CallNode(Op(add), [CallNode(Op(zeros_like), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], (nullptr), [TensorType([4, 498, 128], float32)]), CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(nn.softmax), [CallNode(Op(divide), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbccfbc6988), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.attentions.0.toqueries.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbd2e561cd8), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbccfbc9a38), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce87e1408), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce87b37b8), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce87e8408), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.attentions.0.toqueries.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], relay.attrs.ReshapeAttrs(0x7fbcc9aca3a8), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(reshape), [CallNode(Op(transpose), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbce93ac878), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.attentions.0.tokeys.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbcce4a6198), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce93897a8), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce91ac4f8), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce91d8718), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce9185c98), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.attentions.0.tokeys.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], relay.attrs.TransposeAttrs(0x7fbd2e56d018), [TensorType([4, 498, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbcc9a09a58), [TensorType([4, 128, 498], float32)])], relay.attrs.TransposeAttrs(0x7fbce91e1128), [TensorType([4, 128, 498], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce91e9ba8), [TensorType([4, 498, 498], float32)]), Constant(11.313708)], (nullptr), [TensorType([4, 498, 498], float32), TensorType([], float32)])], relay.attrs.SoftmaxAttrs(0x7fbce91e16c8), [TensorType([4, 498, 498], float32)])], relay.attrs.ReshapeAttrs(0x7fbcae5fa188), [TensorType([4, 498, 498], float32)]), CallNode(Op(transpose), [CallNode(Op(reshape), [CallNode(Op(add), [CallNode(Op(reshape), [CallNode(Op(nn.batch_matmul), [CallNode(Op(reshape), [TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReshapeAttrs(0x7fbd2e5a21f8), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.attentions.0.tovalues.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbce93d3cd8), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbd2e5be2b8), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce92f0158), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce92c0ac8), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce92bc1a8), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.attentions.0.tovalues.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], relay.attrs.ReshapeAttrs(0x7fbcae5cf468), [TensorType([4, 498, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbccfbb97f8), [TensorType([4, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 498], float32), TensorType([4, 128, 498], float32)])], relay.attrs.ReshapeAttrs(0x7fbccfbc5218), [TensorType([4, 498, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce9373118), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(broadcast_to), [CallNode(Op(reshape), [CallNode(Op(transpose), [Var(trfm_blocks.0.mha.w_o.0.weight, ty=TensorType([128, 128], float32))], relay.attrs.TransposeAttrs(0x7fbd2e5b8d58), [TensorType([128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce93c06e8), [TensorType([128, 128], float32)])], relay.attrs.InitOpAttrs(0x7fbce91bb4c8), [TensorType([1, 128, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbce91d7988), [TensorType([4, 128, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 128, 128], float32)])], relay.attrs.ReshapeAttrs(0x7fbce91e9f48), [TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.mha.w_o.0.bias, ty=TensorType([128], float32))], (nullptr), [TensorType([4, 498, 128], float32), TensorType([128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)]), TupleGetItemNode(CallNode(Op(nn.dropout), [CallNode(Op(add), [CallNode(Op(take), [Var(token_embedding.weight, ty=TensorType([50000, 128], float32)), CallNode(Op(cast), [Var(input0, ty=TensorType([4, 498], int64))], relay.attrs.CastAttrs(0x7fbce93ea458), [TensorType([4, 498], int64)])], relay.attrs.TakeAttrs(0x7fbce93b8d18), [TensorType([50000, 128], float32), TensorType([4, 498], int32)]), CallNode(Op(repeat), [CallNode(Op(strided_slice), [CallNode(Op(strided_slice), [CallNode(Op(expand_dims), [CallNode(Op(take), [Var(pos_embedding.weight, ty=TensorType([512, 128], float32)), CallNode(Op(cast), [CallNode(Op(arange), [Constant(0), Constant(498), Constant(1)], relay.attrs.ArangeAttrs(0x7fbccfb8cb98), [TensorType([], int64), TensorType([], int64), TensorType([], int64)])], relay.attrs.CastAttrs(0x7fbccfbbc668), [TensorType([498], int64)])], relay.attrs.TakeAttrs(0x7fbccfbbc7d8), [TensorType([512, 128], float32), TensorType([498], int32)])], relay.attrs.ExpandDimsAttrs(0x7fbccfbaacd8), [TensorType([498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbcca012bc8), [TensorType([1, 498, 128], float32)])], relay.attrs.StridedSliceAttrs(0x7fbccfbcabd8), [TensorType([1, 498, 128], float32)])], relay.attrs.RepeatAttrs(0x7fbccfbcab98), [TensorType([1, 498, 128], float32)])], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)])], relay.attrs.DropoutAttrs(0x7fbccfbb61a8), [TensorType([4, 498, 128], float32)]), 0)], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.norm1.weight, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm1.bias, ty=TensorType([128], float32))], relay.attrs.LayerNormAttrs(0x7fbce91fe168), [TensorType([4, 498, 128], float32), TensorType([128], float32), TensorType([128], float32)])], relay.attrs.DropoutAttrs(0x7fbce91d89b8), [TensorType([4, 498, 128], float32)]), 0)], (nullptr), [TensorType([4, 498, 128], float32), TensorType([4, 498, 128], float32)]), Var(trfm_blocks.0.norm2.weight, ty=TensorType([128], float32)), Var(trfm_blocks.0.norm2.bias, ty=TensorType([128], float32))], relay.attrs.LayerNormAttrs(0x7fbd2e53a058), [TensorType([4, 498, 128], float32), TensorType([128], float32), TensorType([128], float32)])], relay.attrs.DropoutAttrs(0x7fbd2e58d8d8), [TensorType([4, 498, 128], float32)]), 0)], relay.attrs.ReduceAttrs(0x7fbce92cf878), [TensorType([4, 498, 128], float32)]), CallNode(Op(transpose), [CallNode(Op(transpose), [Var(toprobs.weight, ty=TensorType([2, 128], float32))], relay.attrs.TransposeAttrs(0x7fbcc9af6c88), [TensorType([2, 128], float32)])], relay.attrs.TransposeAttrs(0x7fbcc9afd3d8), [TensorType([128, 2], float32)])], relay.attrs.DenseAttrs(0x7fbcc9a966e8), [TensorType([4, 128], float32), TensorType([2, 128], float32)]), Var(toprobs.bias, ty=TensorType([2], float32))], (nullptr), [TensorType([4, 2], float32), TensorType([2], float32)])], relay.attrs.SoftmaxAttrs(0x7fbcc9ac6308), [TensorType([4, 2], float32)]), [], (nullptr))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod[\"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type tensor_int64_t {\n",
      "  tensor_nil_int64,\n",
      "  tensor0_int64(int64),\n",
      "  tensor1_int64(Tensor[(?), int64]),\n",
      "  tensor2_int64(Tensor[(?, ?), int64]),\n",
      "  tensor3_int64(Tensor[(?, ?, ?), int64]),\n",
      "  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),\n",
      "  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),\n",
      "  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),\n",
      "}\n",
      "\n",
      "type Option[A] {\n",
      "  Some(A),\n",
      "  None,\n",
      "}\n",
      "\n",
      "type tensor_float32_t {\n",
      "  tensor_nil_float32,\n",
      "  tensor0_float32(float32),\n",
      "  tensor1_float32(Tensor[(?), float32]),\n",
      "  tensor2_float32(Tensor[(?, ?), float32]),\n",
      "  tensor3_float32(Tensor[(?, ?, ?), float32]),\n",
      "  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),\n",
      "  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),\n",
      "  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),\n",
      "}\n",
      "\n",
      "type List[A] {\n",
      "  Cons(A, List[A]),\n",
      "  Nil,\n",
      "}\n",
      "\n",
      "type Tree[A] {\n",
      "  Rose(A, List[Tree[A]]),\n",
      "}\n",
      "\n",
      "type tensor_int16_t {\n",
      "  tensor_nil_int16,\n",
      "  tensor0_int16(int16),\n",
      "  tensor1_int16(Tensor[(?), int16]),\n",
      "  tensor2_int16(Tensor[(?, ?), int16]),\n",
      "  tensor3_int16(Tensor[(?, ?, ?), int16]),\n",
      "  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),\n",
      "  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),\n",
      "  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),\n",
      "}\n",
      "\n",
      "type tensor_int8_t {\n",
      "  tensor_nil_int8,\n",
      "  tensor0_int8(int8),\n",
      "  tensor1_int8(Tensor[(?), int8]),\n",
      "  tensor2_int8(Tensor[(?, ?), int8]),\n",
      "  tensor3_int8(Tensor[(?, ?, ?), int8]),\n",
      "  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),\n",
      "  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),\n",
      "  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),\n",
      "}\n",
      "\n",
      "type tensor_uint8_t {\n",
      "  tensor_nil_uint8,\n",
      "  tensor0_uint8(uint8),\n",
      "  tensor1_uint8(Tensor[(?), uint8]),\n",
      "  tensor2_uint8(Tensor[(?, ?), uint8]),\n",
      "  tensor3_uint8(Tensor[(?, ?, ?), uint8]),\n",
      "  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),\n",
      "  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),\n",
      "  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),\n",
      "}\n",
      "\n",
      "type tensor_float16_t {\n",
      "  tensor_nil_float16,\n",
      "  tensor0_float16(float16),\n",
      "  tensor1_float16(Tensor[(?), float16]),\n",
      "  tensor2_float16(Tensor[(?, ?), float16]),\n",
      "  tensor3_float16(Tensor[(?, ?, ?), float16]),\n",
      "  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),\n",
      "  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),\n",
      "  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),\n",
      "}\n",
      "\n",
      "type tensor_uint16_t {\n",
      "  tensor_nil_uint16,\n",
      "  tensor0_uint16(uint16),\n",
      "  tensor1_uint16(Tensor[(?), uint16]),\n",
      "  tensor2_uint16(Tensor[(?, ?), uint16]),\n",
      "  tensor3_uint16(Tensor[(?, ?, ?), uint16]),\n",
      "  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),\n",
      "  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),\n",
      "  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),\n",
      "}\n",
      "\n",
      "type tensor_int32_t {\n",
      "  tensor_nil_int32,\n",
      "  tensor0_int32(int32),\n",
      "  tensor1_int32(Tensor[(?), int32]),\n",
      "  tensor2_int32(Tensor[(?, ?), int32]),\n",
      "  tensor3_int32(Tensor[(?, ?, ?), int32]),\n",
      "  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),\n",
      "  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),\n",
      "  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),\n",
      "}\n",
      "\n",
      "type tensor_float64_t {\n",
      "  tensor_nil_float64,\n",
      "  tensor0_float64(float64),\n",
      "  tensor1_float64(Tensor[(?), float64]),\n",
      "  tensor2_float64(Tensor[(?, ?), float64]),\n",
      "  tensor3_float64(Tensor[(?, ?, ?), float64]),\n",
      "  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),\n",
      "  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),\n",
      "  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),\n",
      "}\n",
      "\n",
      "def @main(%token_embedding.weight: Tensor[(50000, 128), float32], %input0: Tensor[(4, 498), int64], %pos_embedding.weight: Tensor[(512, 128), float32], %trfm_blocks.0.mha.attentions.0.toqueries.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.toqueries.bias: Tensor[(128), float32], %trfm_blocks.0.mha.attentions.0.tokeys.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.tokeys.bias: Tensor[(128), float32], %trfm_blocks.0.mha.attentions.0.tovalues.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.tovalues.bias: Tensor[(128), float32], %trfm_blocks.0.mha.w_o.0.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.w_o.0.bias: Tensor[(128), float32], %trfm_blocks.0.norm1.weight: Tensor[(128), float32], %trfm_blocks.0.norm1.bias: Tensor[(128), float32], %trfm_blocks.0.ff.0.weight: Tensor[(512, 128), float32], %trfm_blocks.0.ff.0.bias: Tensor[(512), float32], %trfm_blocks.0.ff.2.weight: Tensor[(128, 512), float32], %trfm_blocks.0.ff.2.bias: Tensor[(128), float32], %trfm_blocks.0.norm2.weight: Tensor[(128), float32], %trfm_blocks.0.norm2.bias: Tensor[(128), float32], %toprobs.weight: Tensor[(2, 128), float32], %toprobs.bias: Tensor[(2), float32]) -> Tensor[(4, 2), float32] {\n",
      "  %0 = cast(%input0, dtype=\"int32\") /* ty=Tensor[(4, 498), int32] */;\n",
      "  %1 = take(%token_embedding.weight, %0, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %2 = arange(0 /* ty=int64 */, 498 /* ty=int64 */, 1 /* ty=int64 */, start=meta[relay.Constant][0], stop=meta[relay.Constant][1], step=meta[relay.Constant][2], dtype=\"int64\") /* ty=Tensor[(498), int64] */;\n",
      "  %3 = cast(%2, dtype=\"int32\") /* ty=Tensor[(498), int32] */;\n",
      "  %4 = take(%pos_embedding.weight, %3, axis=0) /* ty=Tensor[(498, 128), float32] */;\n",
      "  %5 = expand_dims(%4, axis=0) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %6 = strided_slice(%5, begin=[0, 0, 0], end=[1, 498, 128], strides=[1, 1, 1]) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %7 = strided_slice(%6, begin=[0, 0, 0], end=[1, 498, 128], strides=[1, 1, 1]) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %8 = repeat(%7, repeats=4, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %9 = add(%1, %8) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %10 = nn.dropout(%9, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %11 = %10.0;\n",
      "  %12 = zeros_like(%11) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %13 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %14 = transpose(%trfm_blocks.0.mha.attentions.0.toqueries.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %15 = reshape(%14, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %16 = broadcast_to(%15, meta[relay.attrs.InitOpAttrs][0]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %17 = transpose(%16, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %18 = nn.batch_matmul(%13, %17) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %19 = reshape(%18, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %20 = add(%19, %trfm_blocks.0.mha.attentions.0.toqueries.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %21 = reshape(%20, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %22 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %23 = transpose(%trfm_blocks.0.mha.attentions.0.tokeys.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %24 = reshape(%23, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %25 = broadcast_to(%24, meta[relay.attrs.InitOpAttrs][1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %26 = transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %27 = nn.batch_matmul(%22, %26) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %28 = reshape(%27, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %29 = add(%28, %trfm_blocks.0.mha.attentions.0.tokeys.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %30 = transpose(%29, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %31 = reshape(%30, newshape=[-1, 128, 498]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %32 = transpose(%31, axes=[0, 2, 1]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %33 = nn.batch_matmul(%21, %32) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %34 = reshape(%33, newshape=[4, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %35 = divide(%34, 11.3137f /* ty=float32 */) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %36 = nn.softmax(%35, axis=2) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %37 = reshape(%36, newshape=[-1, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %38 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %39 = transpose(%trfm_blocks.0.mha.attentions.0.tovalues.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %40 = reshape(%39, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %41 = broadcast_to(%40, meta[relay.attrs.InitOpAttrs][2]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %42 = transpose(%41, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %43 = nn.batch_matmul(%38, %42) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %44 = reshape(%43, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %45 = add(%44, %trfm_blocks.0.mha.attentions.0.tovalues.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %46 = reshape(%45, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %47 = transpose(%46, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %48 = nn.batch_matmul(%37, %47) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %49 = reshape(%48, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %50 = reshape(%49, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %51 = transpose(%trfm_blocks.0.mha.w_o.0.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %52 = reshape(%51, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %53 = broadcast_to(%52, meta[relay.attrs.InitOpAttrs][3]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %54 = transpose(%53, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %55 = nn.batch_matmul(%50, %54) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %56 = reshape(%55, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %57 = add(%56, %trfm_blocks.0.mha.w_o.0.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %58 = add(%12, %57) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %59 = add(%58, %11) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %60 = nn.layer_norm(%59, %trfm_blocks.0.norm1.weight, %trfm_blocks.0.norm1.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %61 = nn.dropout(%60, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %62 = %61.0;\n",
      "  %63 = reshape(%62, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %64 = transpose(%trfm_blocks.0.ff.0.weight, axes=[1, 0]) /* ty=Tensor[(128, 512), float32] */;\n",
      "  %65 = reshape(%64, newshape=[-1, 128, 512]) /* ty=Tensor[(1, 128, 512), float32] */;\n",
      "  %66 = broadcast_to(%65, meta[relay.attrs.InitOpAttrs][4]) /* ty=Tensor[(4, 128, 512), float32] */;\n",
      "  %67 = transpose(%66, axes=[0, 2, 1]) /* ty=Tensor[(4, 512, 128), float32] */;\n",
      "  %68 = nn.batch_matmul(%63, %67) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %69 = reshape(%68, newshape=[4, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %70 = add(%69, %trfm_blocks.0.ff.0.bias) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %71 = nn.relu(%70) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %72 = reshape(%71, newshape=[-1, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %73 = transpose(%trfm_blocks.0.ff.2.weight, axes=[1, 0]) /* ty=Tensor[(512, 128), float32] */;\n",
      "  %74 = reshape(%73, newshape=[-1, 512, 128]) /* ty=Tensor[(1, 512, 128), float32] */;\n",
      "  %75 = broadcast_to(%74, meta[relay.attrs.InitOpAttrs][5]) /* ty=Tensor[(4, 512, 128), float32] */;\n",
      "  %76 = transpose(%75, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 512), float32] */;\n",
      "  %77 = nn.batch_matmul(%72, %76) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %78 = reshape(%77, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %79 = add(%78, %trfm_blocks.0.ff.2.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %80 = add(%79, %62) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %81 = nn.layer_norm(%80, %trfm_blocks.0.norm2.weight, %trfm_blocks.0.norm2.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %82 = nn.dropout(%81, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %83 = %82.0;\n",
      "  %84 = mean(%83, axis=[1]) /* ty=Tensor[(4, 128), float32] */;\n",
      "  %85 = transpose(%toprobs.weight, axes=[1, 0]) /* ty=Tensor[(128, 2), float32] */;\n",
      "  %86 = transpose(%85, axes=[1, 0]) /* ty=Tensor[(2, 128), float32] */;\n",
      "  %87 = nn.dense(%84, %86, units=2) /* ty=Tensor[(4, 2), float32] */;\n",
      "  %88 = add(%87, %toprobs.bias) /* ty=Tensor[(4, 2), float32] */;\n",
      "  nn.log_softmax(%88, axis=1) /* ty=Tensor[(4, 2), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_name=\"nn.batch_matmul\"\n",
    "end_name=\"add\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if target.device_name == \"vta\":\n",
    "        # Perform quantization in Relay\n",
    "        # Note: We set opt_level to 3 in order to fold batch norm\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "#             with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0], target_vta=True):\n",
    "            with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n",
    "                mod = relay.quantize.quantize(mod, params=params)\n",
    "            # Perform graph packing and constant folding for VTA target\n",
    "#             assert env.BLOCK_IN == env.BLOCK_OUT\n",
    "#             relay_prog = graph_pack(\n",
    "#                 mod[\"main\"],\n",
    "#                 env.BATCH,\n",
    "#                 env.BLOCK_OUT,\n",
    "#                 env.WGT_WIDTH,\n",
    "#                 start_name=start_name,\n",
    "#                 stop_name=end_name,\n",
    "\n",
    "#             )\n",
    "    else:\n",
    "        relay_prog = mod[\"main\"]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%input0: Tensor[(4, 498), int64]) -> Tensor[(4, 2), float32] {\n",
      "  %0 = cast(%input0, dtype=\"int32\") /* ty=Tensor[(4, 498), int32] */;\n",
      "  %1 = take(meta[relay.Constant][0] /* ty=Tensor[(50000, 128), float32] */, %0, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(4, 498, 128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %3 = zeros_like(%2) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %4 = reshape(%2, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %5 = nn.batch_matmul(%4, meta[relay.Constant][2] /* ty=Tensor[(4, 128, 128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %6 = reshape(%5, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %7 = add(%6, meta[relay.Constant][3] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %8 = reshape(%7, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %9 = reshape(%2, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %10 = nn.batch_matmul(%9, meta[relay.Constant][4] /* ty=Tensor[(4, 128, 128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %11 = reshape(%10, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %12 = add(%11, meta[relay.Constant][5] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %13 = transpose(%12, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %14 = reshape(%13, newshape=[-1, 128, 498]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %15 = transpose(%14, axes=[0, 2, 1]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %16 = nn.batch_matmul(%8, %15) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %17 = reshape(%16, newshape=[4, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %18 = divide(%17, 11.3137f /* ty=float32 */) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %19 = nn.softmax(%18, axis=2) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %20 = reshape(%19, newshape=[-1, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %21 = reshape(%2, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %22 = nn.batch_matmul(%21, meta[relay.Constant][6] /* ty=Tensor[(4, 128, 128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %23 = reshape(%22, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %24 = add(%23, meta[relay.Constant][7] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %25 = reshape(%24, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %26 = transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %27 = nn.batch_matmul(%20, %26) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %28 = reshape(%27, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %29 = reshape(%28, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %30 = nn.batch_matmul(%29, meta[relay.Constant][8] /* ty=Tensor[(4, 128, 128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %31 = reshape(%30, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %32 = add(%31, meta[relay.Constant][9] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %33 = add(%3, %32) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %34 = add(%33, %2) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %35 = mean(%34, axis=[-1], keepdims=True) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %36 = subtract(%34, %35) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %37 = variance(%34, %35, axis=[-1], keepdims=True) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %38 = add(%37, 1e-05f /* ty=float32 */) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %39 = sqrt(%38) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %40 = divide(%36, %39) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %41 = multiply(%40, meta[relay.Constant][10] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %42 = add(%41, meta[relay.Constant][11] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %43 = reshape(%42, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %44 = nn.batch_matmul(%43, meta[relay.Constant][12] /* ty=Tensor[(4, 512, 128), float32] */) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %45 = reshape(%44, newshape=[4, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %46 = add(%45, meta[relay.Constant][13] /* ty=Tensor[(512), float32] */) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %47 = nn.relu(%46) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %48 = reshape(%47, newshape=[-1, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %49 = nn.batch_matmul(%48, meta[relay.Constant][14] /* ty=Tensor[(4, 128, 512), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %50 = reshape(%49, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %51 = add(%50, meta[relay.Constant][15] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %52 = add(%51, %42) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %53 = mean(%52, axis=[-1], keepdims=True) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %54 = subtract(%52, %53) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %55 = variance(%52, %53, axis=[-1], keepdims=True) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %56 = add(%55, 1e-05f /* ty=float32 */) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %57 = sqrt(%56) /* ty=Tensor[(4, 498, 1), float32] */;\n",
      "  %58 = divide(%54, %57) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %59 = multiply(%58, meta[relay.Constant][16] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %60 = add(%59, meta[relay.Constant][17] /* ty=Tensor[(128), float32] */) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %61 = mean(%60, axis=[1]) /* ty=Tensor[(4, 128), float32] */;\n",
      "  %62 = nn.dense(%61, meta[relay.Constant][18] /* ty=Tensor[(2, 128), float32] */, units=2) /* ty=Tensor[(4, 2), float32] */;\n",
      "  %63 = add(%62, meta[relay.Constant][19] /* ty=Tensor[(2), float32] */) /* ty=Tensor[(4, 2), float32] */;\n",
      "  nn.log_softmax(%63, axis=1) /* ty=Tensor[(4, 2), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"-target\" is deprecated, use \"-mtriple\" instead.\n",
      "\"-target\" is deprecated, use \"-mtriple\" instead.\n",
      "\"-target\" is deprecated, use \"-mtriple\" instead.\n",
      "\"-target\" is deprecated, use \"-mtriple\" instead.\n",
      "\"-target\" is deprecated, use \"-mtriple\" instead.\n",
      "\"-target\" is deprecated, use \"-mtriple\" instead.\n"
     ]
    }
   ],
   "source": [
    "# Compile Relay program with AlterOpLayout disabled\n",
    "if target.device_name != \"vta\":\n",
    "    with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "        graph, lib, params = relay.build(\n",
    "            mod, target=target, params=params, target_host=env.target_host\n",
    "        )\n",
    "else:\n",
    "    with vta.build_config(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "        lib = relay.build(mod, target=target, params=params, target_host=env.target_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Send the inference library over to the remote RPC server\n",
    "    from tvm.contrib import util\n",
    "    temp = util.tempdir()\n",
    "    lib.export_library(temp.relpath(\"graphlib.tar\"))\n",
    "    remote.upload(temp.relpath(\"graphlib.tar\"))\n",
    "    lib = remote.load_module(\"graphlib.tar\")\n",
    "\n",
    "    # Graph runtime\n",
    "    m = graph_runtime.GraphModule(lib[\"default\"](ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(rpc, 7fbcae67a068)\n"
     ]
    }
   ],
   "source": [
    "print(lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set inputs\n",
    "m.set_input(input_name, tvm.nd.array(input_data))\n",
    "# Execute\n",
    "m.run()\n",
    "# Get outputs\n",
    "tvm_output = m.get_output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.nd.NDArray shape=(4, 2), remote[2]:ext_dev(0)>\n",
       "array([[-0.7253047 , -0.66199154],\n",
       "       [-0.7016208 , -0.68474466],\n",
       "       [-0.73683256, -0.65129066],\n",
       "       [-0.7204744 , -0.666547  ]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47722, 37967, 44802,  ...,  1658,  7251, 32717],\n",
       "        [43559, 46033, 12556,  ..., 15122, 49643,  8711],\n",
       "        [31860, 20540, 38504,  ..., 49632, 45607, 46800],\n",
       "        [21973,  5912, 45115,  ..., 26376, 42772, 39109]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_PATH='saved_model/input_data_vat.pt'\n",
    "torch.save(input_data, INPUT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_output = tvm_output.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_output = torch.from_numpy(np_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7253, -0.6620],\n",
       "        [-0.7016, -0.6847],\n",
       "        [-0.7368, -0.6513],\n",
       "        [-0.7205, -0.6665]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DATA_PATH='saved_model/output_data_vta.pt'\n",
    "torch.save(torch_output, OUTPUT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking VTA operations\n",
    "\n",
    "It seems that there is no operations sent to VTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph runtime\n",
    "m = graph_runtime.GraphModule(lib[\"default\"](ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.set_input(input_name, tvm.nd.array(input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference and gather execution statistics\n",
    "# More on: :py:method:`tvm.runtime.Module.time_evaluator`\n",
    "num = 4  # number of times we run module for a single measurement\n",
    "rep = 3  # number of measurements (we derive std dev from this)\n",
    "timer = m.module.time_evaluator(\"run\", ctx, number=num, repeat=rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :                0\n",
      "\tuop_load_nbytes :                0\n",
      "\tout_store_nbytes:                0\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :                0\n"
     ]
    }
   ],
   "source": [
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    simulator.clear_stats()\n",
    "    timer()\n",
    "    sim_stats = simulator.stats()\n",
    "    print(\"\\nExecution statistics:\")\n",
    "    for k, v in sim_stats.items():\n",
    "        # Since we execute the workload many times, we need to normalize stats\n",
    "        # Note that there is always one warm up run\n",
    "        # Therefore we divide the overall stats by (num * rep + 1)\n",
    "        print(\"\\t{:<16}: {:>16}\".format(k, v // (num * rep + 1)))\n",
    "else:\n",
    "    tcost = timer()\n",
    "    std = np.std(tcost.results) * 1000\n",
    "    mean = tcost.mean * 1000\n",
    "    print(\"\\nPerformed inference in %.2fms (std = %.2f) for %d samples\" % (mean, std, env.BATCH))\n",
    "    print(\"Average per sample inference time: %.2fms\" % (mean / env.BATCH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling the computation (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  [bt] (6) 7   ???                                 0x00007ffee123ab30 0x0 + 140732675631920\n  [bt] (5) 6   libffi.7.dylib                      0x000000010f56bead ffi_call_unix64 + 85\n  [bt] (4) 5   libtvm.dylib                        0x00000001251d6bb6 TVMFuncCall + 70\n  [bt] (3) 4   libtvm.dylib                        0x00000001248a4151 void tvm::runtime::TypedPackedFunc<tvm::te::Schedule (tvm::runtime::Array<tvm::te::Operation, void>)>::AssignTypedLambda<tvm::te::Schedule (*)(tvm::runtime::Array<tvm::te::Operation, void>)>(tvm::te::Schedule (*)(tvm::runtime::Array<tvm::te::Operation, void>))::'lambda'(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const + 337\n  [bt] (2) 3   libtvm.dylib                        0x0000000124861c6c tvm::runtime::TVMMovableArgValue_::operator tvm::runtime::Array<tvm::te::Operation, void><tvm::runtime::Array<tvm::te::Operation, void>, void>() const + 172\n  [bt] (1) 2   libtvm.dylib                        0x0000000124862160 tvm::runtime::Array<tvm::te::Operation, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Array<tvm::te::Operation, void> >() const + 1104\n  [bt] (0) 1   libtvm.dylib                        0x00000001244af50f dmlc::LogMessageFatal::~LogMessageFatal() + 111\n  File \"/Users/isong/Downloads/ml/sc/xilinx/Github/tvm/include/tvm/runtime/packed_func.h\", line 1391\nTVMError: Check failed: ObjectTypeChecker<TObjectRef>: :Check(ptr): Expect Array[Operation] but get Array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-2ab7b92cd461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/ml/sc/xilinx/Github/tvm/python/tvm/te/schedule.py\u001b[0m in \u001b[0;36mcreate_schedule\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ffi_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ml/sc/xilinx/Github/tvm/python/tvm/_ffi/_ctypes/packed_func.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         ):\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  [bt] (6) 7   ???                                 0x00007ffee123ab30 0x0 + 140732675631920\n  [bt] (5) 6   libffi.7.dylib                      0x000000010f56bead ffi_call_unix64 + 85\n  [bt] (4) 5   libtvm.dylib                        0x00000001251d6bb6 TVMFuncCall + 70\n  [bt] (3) 4   libtvm.dylib                        0x00000001248a4151 void tvm::runtime::TypedPackedFunc<tvm::te::Schedule (tvm::runtime::Array<tvm::te::Operation, void>)>::AssignTypedLambda<tvm::te::Schedule (*)(tvm::runtime::Array<tvm::te::Operation, void>)>(tvm::te::Schedule (*)(tvm::runtime::Array<tvm::te::Operation, void>))::'lambda'(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const + 337\n  [bt] (2) 3   libtvm.dylib                        0x0000000124861c6c tvm::runtime::TVMMovableArgValue_::operator tvm::runtime::Array<tvm::te::Operation, void><tvm::runtime::Array<tvm::te::Operation, void>, void>() const + 172\n  [bt] (1) 2   libtvm.dylib                        0x0000000124862160 tvm::runtime::Array<tvm::te::Operation, void> tvm::runtime::TVMPODValue_::AsObjectRef<tvm::runtime::Array<tvm::te::Operation, void> >() const + 1104\n  [bt] (0) 1   libtvm.dylib                        0x00000001244af50f dmlc::LogMessageFatal::~LogMessageFatal() + 111\n  File \"/Users/isong/Downloads/ml/sc/xilinx/Github/tvm/include/tvm/runtime/packed_func.h\", line 1391\nTVMError: Check failed: ObjectTypeChecker<TObjectRef>: :Check(ptr): Expect Array[Operation] but get Array"
     ]
    }
   ],
   "source": [
    "s = te.create_schedule(m.get_output(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TVM compilation (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build GEMM VTA kernel\n",
    "my_gemm = vta.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate code (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mhost = tvm.build(mod, target=target)\n",
    "print(mod.astext(show_meta_data=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Compiled Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tar error:\ntar: no files or directories specified\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c5c14be8beec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLIB_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saved_model/deploy_lib_vta.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIB_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/ml/sc/xilinx/Github/tvm/python/tvm/runtime/module.py\u001b[0m in \u001b[0;36mexport_library\u001b[0;34m(self, file_name, fcompile, addons, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"options\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mfcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ml/sc/xilinx/Github/tvm/python/tvm/contrib/tar.py\u001b[0m in \u001b[0;36mtar\u001b[0;34m(output, files)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Tar error:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tar error:\ntar: no files or directories specified\n"
     ]
    }
   ],
   "source": [
    "# save the graph, lib and params into separate files\n",
    "from tvm.contrib import util\n",
    "\n",
    "LIB_PATH='saved_model/deploy_lib_vta.tar'\n",
    "lib.export_library(LIB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tar error:\ntar: Error opening archive: Failed to open 'saved_model/deploy_lib_vta.tar'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c8255684d166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the module back.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloaded_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIB_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_lib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ml/sc/xilinx/Github/tvm/python/tvm/runtime/module.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(path, fmt)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mtar_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtempdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".tar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0m_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtar_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtar_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0m_cc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ml/sc/xilinx/Github/tvm/python/tvm/contrib/tar.py\u001b[0m in \u001b[0;36muntar\u001b[0;34m(tar_file, directory)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Tar error:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Tar error:\ntar: Error opening archive: Failed to open 'saved_model/deploy_lib_vta.tar'\n"
     ]
    }
   ],
   "source": [
    "# load the module back.\n",
    "loaded_lib = tvm.runtime.load_module(LIB_PATH)\n",
    "\n",
    "\n",
    "m = graph_runtime.GraphModule(loaded_lib[\"default\"](ctx))\n",
    "# Set inputs\n",
    "m.set_input(input_name, tvm.nd.array(input_data))\n",
    "# Execute\n",
    "m.run()\n",
    "# Get outputs\n",
    "tvm_output = m.get_output(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
