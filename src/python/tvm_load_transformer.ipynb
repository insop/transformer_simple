{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVM, load transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isong/Downloads/ml/sc/xilinx/Github/transformer_simple/src/python\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "OPTIONS  Namespace(batch_size=4, debug=True, depth=1, embedding_size=128, final=False, gradient_clipping=1.0, lr=0.0001, lr_warmup=10000, max_length=512, max_pool=False, model_name='single_transformer.pt', num_epochs=1, num_heads=1, seed=1, tb_dir='./runs', tiny=True, vocab_size=50000)\n",
      "/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "- nr. of training examples 63\n",
      "- nr. of validation examples 63\n",
      "Model's state_dict:\n",
      "token_embedding.weight \t torch.Size([50000, 128])\n",
      "pos_embedding.weight \t torch.Size([512, 128])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.w_o.0.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.w_o.0.bias \t torch.Size([128])\n",
      "trfm_blocks.0.norm1.weight \t torch.Size([128])\n",
      "trfm_blocks.0.norm1.bias \t torch.Size([128])\n",
      "trfm_blocks.0.norm2.weight \t torch.Size([128])\n",
      "trfm_blocks.0.norm2.bias \t torch.Size([128])\n",
      "trfm_blocks.0.ff.0.weight \t torch.Size([512, 128])\n",
      "trfm_blocks.0.ff.0.bias \t torch.Size([512])\n",
      "trfm_blocks.0.ff.2.weight \t torch.Size([128, 512])\n",
      "trfm_blocks.0.ff.2.bias \t torch.Size([128])\n",
      "toprobs.weight \t torch.Size([2, 128])\n",
      "toprobs.bias \t torch.Size([2])\n",
      "token_embedding.weight \t tensor([[ 1.2510, -0.9000,  0.1551,  ...,  0.7884,  0.5929,  0.4142],\n",
      "        [-0.7351, -1.6498,  1.9411,  ...,  1.8529, -0.5840, -0.2895],\n",
      "        [-0.5377, -0.9868, -0.3693,  ..., -0.6934,  0.8407, -0.4662],\n",
      "        ...,\n",
      "        [-2.0669, -1.4720,  0.0631,  ..., -0.1309, -0.2451,  0.0402],\n",
      "        [-1.0454,  1.2783, -0.7522,  ...,  0.6201,  1.7511, -2.1809],\n",
      "        [ 0.3131,  0.6908,  1.4389,  ...,  1.7887, -1.5186,  1.8215]])\n",
      "pos_embedding.weight \t tensor([[ 0.5204,  1.2408,  2.0311,  ...,  1.5167, -0.3826, -0.7878],\n",
      "        [ 0.7634,  0.9391,  0.3161,  ..., -1.6810, -0.4139,  1.0620],\n",
      "        [ 1.5444,  1.4940,  0.3453,  ...,  0.2631,  1.5586, -1.1777],\n",
      "        ...,\n",
      "        [-0.4832, -1.7069, -0.1873,  ..., -1.3317,  0.9642, -0.5098],\n",
      "        [-0.9711,  0.0330, -0.9203,  ..., -0.1385,  0.9417, -1.0349],\n",
      "        [-1.4019,  1.1276,  1.3567,  ..., -0.1112, -0.3789, -1.0926]])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.weight \t tensor([[-0.0663, -0.0093, -0.0504,  ..., -0.0677, -0.0769,  0.0171],\n",
      "        [-0.0268,  0.0022,  0.0621,  ..., -0.0604, -0.0556,  0.0603],\n",
      "        [-0.0326,  0.0249, -0.0581,  ...,  0.0673,  0.0717,  0.0649],\n",
      "        ...,\n",
      "        [-0.0659,  0.0256, -0.0671,  ...,  0.0287, -0.0811, -0.0180],\n",
      "        [-0.0711, -0.0295,  0.0707,  ...,  0.0080, -0.0165, -0.0507],\n",
      "        [-0.0059,  0.0177, -0.0355,  ..., -0.0580,  0.0547,  0.0673]])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.bias \t tensor([ 7.9320e-02,  6.1707e-02,  3.1875e-02,  4.5670e-02,  1.5906e-02,\n",
      "         7.1981e-02,  7.1290e-02, -5.5034e-02,  7.4015e-02,  7.4529e-02,\n",
      "        -6.2648e-02, -8.4173e-02,  9.4257e-03, -3.5516e-03,  6.0062e-02,\n",
      "        -2.8453e-03, -8.6490e-02,  4.3969e-02, -3.3732e-02,  5.5258e-02,\n",
      "        -8.0908e-02, -4.4743e-02, -2.9434e-02,  2.6479e-02,  2.1785e-02,\n",
      "         8.5817e-02, -1.4398e-02, -3.8266e-02, -3.4796e-03, -8.1467e-02,\n",
      "        -1.4577e-02,  5.8556e-02,  7.4007e-02, -8.5497e-02, -2.0384e-03,\n",
      "         2.4023e-02,  1.5266e-02,  7.4118e-02, -2.9920e-02,  8.3679e-02,\n",
      "         4.6479e-02,  1.5809e-02, -9.5394e-03,  4.9310e-02, -8.3002e-02,\n",
      "        -6.3331e-02, -7.5974e-02, -1.9990e-02,  7.4331e-02, -8.7516e-02,\n",
      "         6.9359e-02, -4.2039e-02, -5.2494e-02, -5.6355e-02,  6.2891e-02,\n",
      "        -3.3814e-02, -3.1994e-02,  4.3381e-02,  1.9891e-02, -5.2537e-02,\n",
      "        -6.2490e-02, -4.5803e-02,  7.6253e-03, -9.0995e-03, -8.1214e-03,\n",
      "         4.8961e-02, -5.8208e-02,  1.8842e-02,  7.7148e-02, -4.0040e-02,\n",
      "         8.0896e-03, -7.3854e-02, -8.5589e-02,  4.5032e-02,  7.4976e-03,\n",
      "         4.7026e-02, -6.4040e-02,  6.1779e-02,  2.3309e-02, -9.6927e-03,\n",
      "         6.7333e-03,  3.5914e-02, -2.7996e-02, -6.0813e-03,  7.2363e-02,\n",
      "        -1.0204e-02, -8.3692e-03,  5.3741e-03, -6.9285e-02, -4.4161e-02,\n",
      "         3.2223e-02,  2.6170e-02,  8.5197e-02, -7.7961e-02, -8.8249e-02,\n",
      "         8.3453e-02,  2.7590e-02,  4.9938e-02,  4.8131e-02,  5.6310e-02,\n",
      "         7.8378e-02,  8.4398e-02, -2.4886e-03,  3.2746e-02, -3.4001e-02,\n",
      "         6.0319e-03, -1.5462e-02,  5.8869e-03,  7.0276e-02, -7.0460e-05,\n",
      "         5.7188e-02,  7.4890e-02,  1.1498e-02, -1.5290e-02, -2.0724e-02,\n",
      "        -6.7261e-02,  3.3961e-02, -7.1838e-02,  1.8327e-02, -8.7569e-02,\n",
      "        -8.4943e-02,  2.9723e-02, -3.5278e-02,  2.4982e-02,  7.5778e-02,\n",
      "         7.9040e-02, -3.5918e-02,  6.5103e-02])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.weight \t tensor([[-0.0076,  0.0403,  0.0667,  ..., -0.0459,  0.0171,  0.0881],\n",
      "        [ 0.0814,  0.0376, -0.0632,  ...,  0.0132, -0.0685,  0.0563],\n",
      "        [ 0.0420, -0.0149,  0.0232,  ..., -0.0855, -0.0375,  0.0340],\n",
      "        ...,\n",
      "        [ 0.0426,  0.0778,  0.0557,  ...,  0.0366,  0.0317, -0.0487],\n",
      "        [-0.0337,  0.0779, -0.0825,  ..., -0.0844, -0.0152,  0.0607],\n",
      "        [ 0.0402,  0.0307, -0.0193,  ...,  0.0584, -0.0135, -0.0556]])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.bias \t tensor([-0.0503,  0.0750, -0.0622,  0.0068, -0.0380,  0.0866,  0.0056, -0.0589,\n",
      "        -0.0066,  0.0284, -0.0410, -0.0191,  0.0610, -0.0525,  0.0478,  0.0062,\n",
      "        -0.0482,  0.0336,  0.0181, -0.0270,  0.0501, -0.0165, -0.0550,  0.0882,\n",
      "        -0.0426,  0.0242,  0.0492, -0.0768,  0.0421,  0.0739,  0.0210, -0.0796,\n",
      "        -0.0376,  0.0016, -0.0460, -0.0191, -0.0130, -0.0112,  0.0865, -0.0252,\n",
      "         0.0165, -0.0802,  0.0396, -0.0786,  0.0847, -0.0143,  0.0223,  0.0760,\n",
      "        -0.0473, -0.0152, -0.0388,  0.0161, -0.0784, -0.0546, -0.0883, -0.0816,\n",
      "        -0.0265, -0.0442,  0.0341, -0.0804,  0.0014, -0.0764, -0.0079,  0.0587,\n",
      "         0.0136,  0.0182,  0.0601, -0.0700, -0.0249,  0.0622, -0.0765,  0.0692,\n",
      "         0.0775,  0.0385,  0.0716, -0.0717,  0.0631, -0.0172,  0.0113,  0.0658,\n",
      "         0.0531,  0.0550,  0.0166, -0.0561, -0.0793, -0.0307,  0.0100, -0.0785,\n",
      "         0.0658, -0.0613,  0.0542,  0.0538, -0.0163,  0.0829, -0.0281,  0.0431,\n",
      "         0.0648, -0.0158,  0.0819, -0.0088, -0.0317,  0.0219,  0.0758,  0.0789,\n",
      "         0.0201, -0.0466,  0.0246,  0.0196, -0.0747, -0.0427, -0.0708, -0.0189,\n",
      "        -0.0145, -0.0428, -0.0283, -0.0226, -0.0362, -0.0704,  0.0144,  0.0537,\n",
      "         0.0634,  0.0301,  0.0237, -0.0762, -0.0323, -0.0247,  0.0329,  0.0750])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.weight \t tensor([[ 0.0261, -0.0041,  0.0433,  ...,  0.0872, -0.0131,  0.0153],\n",
      "        [-0.0047, -0.0157, -0.0874,  ...,  0.0600,  0.0355,  0.0302],\n",
      "        [-0.0096,  0.0407, -0.0874,  ...,  0.0250,  0.0795, -0.0838],\n",
      "        ...,\n",
      "        [-0.0192, -0.0267,  0.0151,  ...,  0.0561,  0.0877, -0.0080],\n",
      "        [-0.0016, -0.0119, -0.0338,  ...,  0.0681,  0.0873, -0.0139],\n",
      "        [ 0.0859,  0.0774,  0.0775,  ...,  0.0506, -0.0604, -0.0741]])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.bias \t tensor([ 0.0799,  0.0227,  0.0386, -0.0026,  0.0787,  0.0516,  0.0348, -0.0753,\n",
      "        -0.0659,  0.0765,  0.0432, -0.0729,  0.0526,  0.0452, -0.0509,  0.0080,\n",
      "        -0.0834,  0.0111, -0.0228, -0.0787, -0.0361,  0.0318, -0.0285,  0.0619,\n",
      "        -0.0851,  0.0495,  0.0317,  0.0026,  0.0008, -0.0728, -0.0462, -0.0820,\n",
      "        -0.0828, -0.0183, -0.0231, -0.0563,  0.0632,  0.0438,  0.0603, -0.0133,\n",
      "         0.0141, -0.0747,  0.0751, -0.0290, -0.0187,  0.0476,  0.0228, -0.0722,\n",
      "         0.0278, -0.0773,  0.0110, -0.0160,  0.0081,  0.0409, -0.0764,  0.0630,\n",
      "         0.0393, -0.0522, -0.0335,  0.0337,  0.0703,  0.0440,  0.0573, -0.0798,\n",
      "        -0.0294,  0.0350,  0.0472, -0.0365, -0.0349, -0.0270, -0.0108, -0.0407,\n",
      "        -0.0541,  0.0565, -0.0326,  0.0309, -0.0665,  0.0858, -0.0020,  0.0839,\n",
      "        -0.0463, -0.0475, -0.0081, -0.0502, -0.0039, -0.0825, -0.0693, -0.0314,\n",
      "        -0.0586, -0.0832, -0.0059, -0.0214,  0.0753, -0.0249,  0.0677, -0.0200,\n",
      "        -0.0374,  0.0522,  0.0156, -0.0100,  0.0473, -0.0714, -0.0466,  0.0016,\n",
      "         0.0414,  0.0499, -0.0027,  0.0831, -0.0486,  0.0337,  0.0786, -0.0305,\n",
      "         0.0502,  0.0154, -0.0800,  0.0632, -0.0494,  0.0676,  0.0827, -0.0544,\n",
      "         0.0765,  0.0429,  0.0764,  0.0638, -0.0790,  0.0185, -0.0708, -0.0284])\n",
      "trfm_blocks.0.mha.w_o.0.weight \t tensor([[-0.0375, -0.0093,  0.0037,  ...,  0.0836,  0.0328, -0.0358],\n",
      "        [-0.0817, -0.0582,  0.0738,  ..., -0.0205,  0.0150, -0.0739],\n",
      "        [ 0.0633, -0.0562,  0.0766,  ..., -0.0724,  0.0034,  0.0130],\n",
      "        ...,\n",
      "        [-0.0659,  0.0147,  0.0110,  ..., -0.0297, -0.0189,  0.0632],\n",
      "        [ 0.0716, -0.0172, -0.0105,  ..., -0.0140, -0.0063,  0.0560],\n",
      "        [ 0.0341,  0.0064, -0.0549,  ..., -0.0844,  0.0185, -0.0791]])\n",
      "trfm_blocks.0.mha.w_o.0.bias \t tensor([-3.9304e-03, -2.8163e-05, -1.9326e-02, -5.5853e-02, -3.7946e-02,\n",
      "         1.0822e-02,  8.0777e-02,  8.3189e-02,  6.7901e-02,  7.7600e-03,\n",
      "        -5.9209e-02, -1.7579e-02, -5.7792e-02,  4.4044e-02, -4.7727e-02,\n",
      "        -3.6531e-02, -6.7974e-02,  4.4166e-03, -6.8313e-02, -7.2485e-02,\n",
      "        -1.5988e-03, -1.9522e-02, -5.0335e-02, -7.6660e-02, -4.8780e-02,\n",
      "        -3.1780e-02, -1.5747e-02,  4.5561e-04,  5.6233e-02, -6.7509e-02,\n",
      "        -4.6197e-02, -5.7172e-02,  4.5473e-02,  7.4591e-02, -7.9047e-02,\n",
      "         5.2201e-02, -5.5717e-02, -2.2274e-02,  2.6940e-02,  3.4331e-02,\n",
      "        -6.3265e-02, -3.7527e-02, -3.5182e-02,  4.3949e-02, -5.9806e-02,\n",
      "        -4.0980e-02, -5.7120e-02, -3.0977e-02,  5.8348e-02,  1.7097e-03,\n",
      "        -2.4178e-02, -1.3844e-02,  1.7556e-03,  2.0301e-02,  4.1950e-02,\n",
      "         1.6589e-02,  4.6049e-02, -2.4205e-02, -1.4415e-02, -8.5661e-02,\n",
      "         4.0776e-02, -5.6388e-02,  3.0879e-02, -6.0909e-02, -3.5688e-02,\n",
      "        -5.0127e-02, -5.9660e-02, -8.3647e-02, -3.6099e-03,  2.5638e-02,\n",
      "        -1.0007e-02, -8.4920e-02, -4.7632e-02, -8.0656e-02,  6.7952e-02,\n",
      "         2.4018e-02,  2.5797e-02, -7.6454e-02,  7.8002e-02,  6.8922e-02,\n",
      "        -5.1047e-02,  8.1744e-02, -6.7989e-02, -8.3160e-02, -2.8206e-02,\n",
      "        -7.2847e-03, -5.5055e-02, -6.5431e-02, -7.5320e-03,  1.3011e-02,\n",
      "         8.7340e-02, -3.5990e-03,  4.9435e-02,  5.6621e-02,  4.8367e-02,\n",
      "        -1.6352e-02, -3.8647e-02, -4.4854e-02,  4.6067e-02,  1.3908e-02,\n",
      "         1.8269e-02, -3.7360e-02,  2.6664e-02, -3.4924e-02, -7.6424e-02,\n",
      "        -6.8770e-02,  7.5253e-03,  4.2028e-02,  1.7885e-02,  7.4922e-02,\n",
      "         5.9479e-02, -3.6423e-02, -1.1197e-03,  8.4098e-02, -2.6755e-02,\n",
      "        -7.6467e-02,  3.4985e-02, -6.2044e-03, -6.9510e-02,  5.2365e-03,\n",
      "         1.7034e-02, -2.8143e-02, -1.6631e-03,  7.4774e-02,  3.4869e-02,\n",
      "         4.7803e-02,  8.1371e-02,  2.9136e-02])\n",
      "trfm_blocks.0.norm1.weight \t tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "trfm_blocks.0.norm1.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "trfm_blocks.0.norm2.weight \t tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "trfm_blocks.0.norm2.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "trfm_blocks.0.ff.0.weight \t tensor([[-0.0730, -0.0810, -0.0902,  ..., -0.0527,  0.0060, -0.0817],\n",
      "        [-0.0930, -0.0906,  0.0768,  ...,  0.0428, -0.0005,  0.0784],\n",
      "        [ 0.0104, -0.0241, -0.0804,  ..., -0.0456,  0.0564,  0.0065],\n",
      "        ...,\n",
      "        [ 0.0187, -0.0077,  0.0906,  ...,  0.0690, -0.0368, -0.0046],\n",
      "        [-0.0024, -0.0558,  0.0003,  ..., -0.0784, -0.0737, -0.0335],\n",
      "        [-0.0053, -0.0782, -0.0025,  ...,  0.0732, -0.0966, -0.0859]])\n",
      "trfm_blocks.0.ff.0.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "trfm_blocks.0.ff.2.weight \t tensor([[ 0.0603, -0.0621,  0.0569,  ..., -0.0237,  0.0535, -0.0102],\n",
      "        [-0.0787, -0.0327,  0.0550,  ..., -0.0052,  0.0663,  0.0521],\n",
      "        [-0.0038, -0.0160, -0.0029,  ..., -0.0364,  0.0557, -0.0342],\n",
      "        ...,\n",
      "        [ 0.0390, -0.0097, -0.0826,  ..., -0.0505,  0.0514,  0.0099],\n",
      "        [ 0.0822, -0.0477,  0.0554,  ..., -0.0374,  0.0463, -0.0362],\n",
      "        [-0.0733, -0.0376, -0.0784,  ...,  0.0038, -0.0341,  0.0913]])\n",
      "trfm_blocks.0.ff.2.bias \t tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "toprobs.weight \t tensor([[ 0.0061, -0.0607,  0.0836, -0.0774,  0.0174, -0.0161,  0.0109,  0.0115,\n",
      "         -0.0516, -0.0053, -0.0419,  0.0420, -0.0151, -0.0831,  0.0395, -0.0268,\n",
      "          0.0492, -0.0140,  0.0571, -0.0280,  0.0807,  0.0581,  0.0846, -0.0882,\n",
      "          0.0146,  0.0586,  0.0813, -0.0627,  0.0489, -0.0051, -0.0288, -0.0760,\n",
      "          0.0070,  0.0578,  0.0775,  0.0730, -0.0708, -0.0024, -0.0495, -0.0783,\n",
      "          0.0829,  0.0113, -0.0294,  0.0440,  0.0408,  0.0293,  0.0683,  0.0491,\n",
      "         -0.0028,  0.0492,  0.0236,  0.0120,  0.0344, -0.0759, -0.0284,  0.0432,\n",
      "         -0.0790, -0.0685,  0.0345,  0.0458, -0.0055, -0.0803, -0.0392,  0.0592,\n",
      "          0.0004,  0.0093,  0.0197, -0.0324, -0.0756, -0.0142,  0.0656, -0.0537,\n",
      "          0.0746, -0.0055,  0.0882,  0.0256, -0.0122,  0.0614, -0.0024, -0.0169,\n",
      "          0.0270,  0.0682,  0.0492, -0.0718, -0.0626,  0.0108,  0.0015, -0.0054,\n",
      "          0.0202, -0.0024, -0.0250,  0.0531,  0.0529,  0.0137, -0.0096, -0.0724,\n",
      "         -0.0181,  0.0043, -0.0351, -0.0852,  0.0503,  0.0792, -0.0547,  0.0137,\n",
      "          0.0739,  0.0325, -0.0701,  0.0128,  0.0716, -0.0665,  0.0532,  0.0861,\n",
      "          0.0840, -0.0192, -0.0547, -0.0485, -0.0355,  0.0743, -0.0077, -0.0436,\n",
      "         -0.0470, -0.0278, -0.0083,  0.0803, -0.0678, -0.0538,  0.0059,  0.0576],\n",
      "        [-0.0733,  0.0605,  0.0415, -0.0411, -0.0643,  0.0351, -0.0485,  0.0790,\n",
      "          0.0107,  0.0801, -0.0094, -0.0368, -0.0187, -0.0310, -0.0876, -0.0152,\n",
      "         -0.0723,  0.0342,  0.0750,  0.0205, -0.0348, -0.0188,  0.0404,  0.0793,\n",
      "         -0.0825,  0.0620, -0.0002,  0.0065,  0.0195, -0.0726,  0.0414,  0.0099,\n",
      "          0.0546,  0.0121,  0.0601, -0.0592,  0.0191, -0.0719, -0.0507,  0.0613,\n",
      "          0.0054, -0.0600, -0.0784, -0.0321,  0.0653,  0.0583,  0.0126,  0.0731,\n",
      "         -0.0684, -0.0630, -0.0757,  0.0869,  0.0203,  0.0577,  0.0794, -0.0261,\n",
      "         -0.0114, -0.0528,  0.0225,  0.0460,  0.0076,  0.0419, -0.0561, -0.0295,\n",
      "         -0.0275, -0.0687, -0.0086,  0.0853,  0.0648, -0.0358,  0.0776, -0.0583,\n",
      "         -0.0039, -0.0610,  0.0712, -0.0138,  0.0302, -0.0661,  0.0038,  0.0439,\n",
      "          0.0218,  0.0163, -0.0820, -0.0352, -0.0025, -0.0534,  0.0628,  0.0196,\n",
      "          0.0318,  0.0818, -0.0314, -0.0370,  0.0848,  0.0010,  0.0546, -0.0678,\n",
      "         -0.0505,  0.0267, -0.0055, -0.0655, -0.0139, -0.0471, -0.0169,  0.0290,\n",
      "         -0.0716, -0.0565,  0.0574,  0.0193,  0.0824,  0.0589, -0.0134, -0.0304,\n",
      "          0.0382,  0.0363, -0.0609, -0.0634,  0.0265,  0.0308, -0.0200,  0.0597,\n",
      "          0.0109, -0.0564, -0.0636,  0.0490,  0.0336,  0.0675, -0.0403,  0.0818]])\n",
      "toprobs.bias \t tensor([-0.0295,  0.0635])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}]\n",
      "\n",
      " epoch 0\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/Users/isong/anaconda3x/envs/nlu/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 63/63 [00:04<00:00, 13.76it/s]\n",
      "-- validation accuracy 0.46\n",
      "Save model to saved_model/single_transformer.pt\n",
      "==============\n",
      "Load model to saved_model/single_transformer.pt\n",
      "Model's state_dict:\n",
      "token_embedding.weight \t torch.Size([50000, 128])\n",
      "pos_embedding.weight \t torch.Size([512, 128])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.bias \t torch.Size([128])\n",
      "trfm_blocks.0.mha.w_o.0.weight \t torch.Size([128, 128])\n",
      "trfm_blocks.0.mha.w_o.0.bias \t torch.Size([128])\n",
      "trfm_blocks.0.norm1.weight \t torch.Size([128])\n",
      "trfm_blocks.0.norm1.bias \t torch.Size([128])\n",
      "trfm_blocks.0.norm2.weight \t torch.Size([128])\n",
      "trfm_blocks.0.norm2.bias \t torch.Size([128])\n",
      "trfm_blocks.0.ff.0.weight \t torch.Size([512, 128])\n",
      "trfm_blocks.0.ff.0.bias \t torch.Size([512])\n",
      "trfm_blocks.0.ff.2.weight \t torch.Size([128, 512])\n",
      "trfm_blocks.0.ff.2.bias \t torch.Size([128])\n",
      "toprobs.weight \t torch.Size([2, 128])\n",
      "toprobs.bias \t torch.Size([2])\n",
      "token_embedding.weight \t tensor([[ 1.2510, -0.9000,  0.1551,  ...,  0.7884,  0.5929,  0.4142],\n",
      "        [-0.7351, -1.6499,  1.9411,  ...,  1.8529, -0.5839, -0.2895],\n",
      "        [-0.5377, -0.9868, -0.3693,  ..., -0.6934,  0.8407, -0.4662],\n",
      "        ...,\n",
      "        [-2.0669, -1.4720,  0.0631,  ..., -0.1309, -0.2451,  0.0402],\n",
      "        [-1.0454,  1.2783, -0.7522,  ...,  0.6201,  1.7511, -2.1809],\n",
      "        [ 0.3131,  0.6908,  1.4389,  ...,  1.7887, -1.5186,  1.8215]])\n",
      "pos_embedding.weight \t tensor([[ 0.5204,  1.2407,  2.0311,  ...,  1.5167, -0.3825, -0.7878],\n",
      "        [ 0.7634,  0.9391,  0.3161,  ..., -1.6810, -0.4139,  1.0620],\n",
      "        [ 1.5445,  1.4940,  0.3454,  ...,  0.2631,  1.5586, -1.1777],\n",
      "        ...,\n",
      "        [-0.4832, -1.7069, -0.1873,  ..., -1.3317,  0.9642, -0.5099],\n",
      "        [-0.9711,  0.0330, -0.9203,  ..., -0.1386,  0.9418, -1.0349],\n",
      "        [-1.4019,  1.1275,  1.3567,  ..., -0.1112, -0.3789, -1.0926]])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.weight \t tensor([[-0.0663, -0.0093, -0.0504,  ..., -0.0678, -0.0769,  0.0171],\n",
      "        [-0.0268,  0.0022,  0.0621,  ..., -0.0604, -0.0556,  0.0603],\n",
      "        [-0.0325,  0.0249, -0.0581,  ...,  0.0673,  0.0717,  0.0650],\n",
      "        ...,\n",
      "        [-0.0660,  0.0256, -0.0671,  ...,  0.0288, -0.0811, -0.0180],\n",
      "        [-0.0711, -0.0295,  0.0707,  ...,  0.0080, -0.0164, -0.0507],\n",
      "        [-0.0060,  0.0177, -0.0355,  ..., -0.0579,  0.0547,  0.0673]])\n",
      "trfm_blocks.0.mha.attentions.0.toqueries.bias \t tensor([ 7.9311e-02,  6.1683e-02,  3.1845e-02,  4.5665e-02,  1.5888e-02,\n",
      "         7.1976e-02,  7.1261e-02, -5.5056e-02,  7.4036e-02,  7.4502e-02,\n",
      "        -6.2619e-02, -8.4181e-02,  9.4381e-03, -3.5743e-03,  6.0072e-02,\n",
      "        -2.8511e-03, -8.6483e-02,  4.3993e-02, -3.3757e-02,  5.5282e-02,\n",
      "        -8.0927e-02, -4.4757e-02, -2.9434e-02,  2.6461e-02,  2.1801e-02,\n",
      "         8.5828e-02, -1.4425e-02, -3.8262e-02, -3.4570e-03, -8.1497e-02,\n",
      "        -1.4557e-02,  5.8540e-02,  7.3980e-02, -8.5527e-02, -2.0656e-03,\n",
      "         2.4044e-02,  1.5279e-02,  7.4092e-02, -2.9891e-02,  8.3702e-02,\n",
      "         4.6508e-02,  1.5839e-02, -9.5169e-03,  4.9280e-02, -8.3011e-02,\n",
      "        -6.3338e-02, -7.5953e-02, -1.9974e-02,  7.4351e-02, -8.7491e-02,\n",
      "         6.9338e-02, -4.2019e-02, -5.2467e-02, -5.6330e-02,  6.2866e-02,\n",
      "        -3.3790e-02, -3.1968e-02,  4.3356e-02,  1.9911e-02, -5.2557e-02,\n",
      "        -6.2465e-02, -4.5816e-02,  7.5933e-03, -9.0739e-03, -8.1181e-03,\n",
      "         4.8979e-02, -5.8192e-02,  1.8847e-02,  7.7176e-02, -4.0066e-02,\n",
      "         8.1189e-03, -7.3881e-02, -8.5588e-02,  4.5032e-02,  7.5286e-03,\n",
      "         4.7061e-02, -6.4016e-02,  6.1755e-02,  2.3312e-02, -9.7042e-03,\n",
      "         6.7498e-03,  3.5906e-02, -2.7975e-02, -6.0601e-03,  7.2343e-02,\n",
      "        -1.0222e-02, -8.3448e-03,  5.3526e-03, -6.9295e-02, -4.4158e-02,\n",
      "         3.2198e-02,  2.6194e-02,  8.5171e-02, -7.7973e-02, -8.8231e-02,\n",
      "         8.3473e-02,  2.7615e-02,  4.9943e-02,  4.8156e-02,  5.6328e-02,\n",
      "         7.8395e-02,  8.4393e-02, -2.5052e-03,  3.2738e-02, -3.4007e-02,\n",
      "         6.0144e-03, -1.5459e-02,  5.9154e-03,  7.0255e-02, -4.7783e-05,\n",
      "         5.7172e-02,  7.4910e-02,  1.1475e-02, -1.5277e-02, -2.0729e-02,\n",
      "        -6.7238e-02,  3.3970e-02, -7.1820e-02,  1.8355e-02, -8.7541e-02,\n",
      "        -8.4951e-02,  2.9735e-02, -3.5291e-02,  2.4998e-02,  7.5789e-02,\n",
      "         7.9062e-02, -3.5923e-02,  6.5124e-02])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.weight \t tensor([[-0.0076,  0.0403,  0.0667,  ..., -0.0459,  0.0171,  0.0880],\n",
      "        [ 0.0813,  0.0376, -0.0632,  ...,  0.0132, -0.0685,  0.0563],\n",
      "        [ 0.0420, -0.0148,  0.0232,  ..., -0.0855, -0.0375,  0.0341],\n",
      "        ...,\n",
      "        [ 0.0427,  0.0778,  0.0556,  ...,  0.0365,  0.0317, -0.0487],\n",
      "        [-0.0337,  0.0779, -0.0825,  ..., -0.0843, -0.0152,  0.0607],\n",
      "        [ 0.0402,  0.0307, -0.0193,  ...,  0.0584, -0.0135, -0.0556]])\n",
      "trfm_blocks.0.mha.attentions.0.tokeys.bias \t tensor([-0.0503,  0.0750, -0.0622,  0.0068, -0.0380,  0.0866,  0.0056, -0.0589,\n",
      "        -0.0066,  0.0284, -0.0410, -0.0191,  0.0610, -0.0525,  0.0478,  0.0062,\n",
      "        -0.0482,  0.0336,  0.0181, -0.0270,  0.0501, -0.0165, -0.0550,  0.0882,\n",
      "        -0.0426,  0.0242,  0.0492, -0.0768,  0.0421,  0.0739,  0.0210, -0.0796,\n",
      "        -0.0376,  0.0016, -0.0460, -0.0191, -0.0130, -0.0112,  0.0865, -0.0252,\n",
      "         0.0165, -0.0802,  0.0396, -0.0786,  0.0847, -0.0143,  0.0223,  0.0760,\n",
      "        -0.0473, -0.0152, -0.0388,  0.0161, -0.0784, -0.0546, -0.0883, -0.0816,\n",
      "        -0.0265, -0.0442,  0.0341, -0.0804,  0.0014, -0.0764, -0.0079,  0.0587,\n",
      "         0.0136,  0.0182,  0.0601, -0.0700, -0.0249,  0.0622, -0.0765,  0.0692,\n",
      "         0.0775,  0.0385,  0.0716, -0.0717,  0.0631, -0.0172,  0.0113,  0.0658,\n",
      "         0.0531,  0.0550,  0.0166, -0.0561, -0.0793, -0.0307,  0.0100, -0.0785,\n",
      "         0.0658, -0.0613,  0.0542,  0.0538, -0.0163,  0.0829, -0.0281,  0.0431,\n",
      "         0.0648, -0.0158,  0.0819, -0.0088, -0.0317,  0.0219,  0.0758,  0.0789,\n",
      "         0.0201, -0.0466,  0.0246,  0.0196, -0.0747, -0.0427, -0.0708, -0.0189,\n",
      "        -0.0145, -0.0428, -0.0283, -0.0226, -0.0362, -0.0704,  0.0144,  0.0537,\n",
      "         0.0634,  0.0301,  0.0237, -0.0762, -0.0323, -0.0247,  0.0329,  0.0750])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.weight \t tensor([[ 0.0261, -0.0041,  0.0433,  ...,  0.0873, -0.0132,  0.0153],\n",
      "        [-0.0047, -0.0157, -0.0874,  ...,  0.0600,  0.0355,  0.0303],\n",
      "        [-0.0097,  0.0406, -0.0873,  ...,  0.0250,  0.0794, -0.0838],\n",
      "        ...,\n",
      "        [-0.0191, -0.0266,  0.0150,  ...,  0.0561,  0.0877, -0.0079],\n",
      "        [-0.0017, -0.0120, -0.0337,  ...,  0.0681,  0.0873, -0.0140],\n",
      "        [ 0.0859,  0.0773,  0.0775,  ...,  0.0506, -0.0604, -0.0741]])\n",
      "trfm_blocks.0.mha.attentions.0.tovalues.bias \t tensor([ 0.0799,  0.0227,  0.0386, -0.0026,  0.0786,  0.0516,  0.0348, -0.0753,\n",
      "        -0.0659,  0.0765,  0.0432, -0.0729,  0.0526,  0.0452, -0.0509,  0.0081,\n",
      "        -0.0834,  0.0111, -0.0228, -0.0787, -0.0361,  0.0318, -0.0286,  0.0618,\n",
      "        -0.0851,  0.0496,  0.0316,  0.0027,  0.0008, -0.0727, -0.0462, -0.0820,\n",
      "        -0.0828, -0.0183, -0.0231, -0.0563,  0.0632,  0.0438,  0.0603, -0.0132,\n",
      "         0.0140, -0.0747,  0.0751, -0.0289, -0.0187,  0.0477,  0.0228, -0.0721,\n",
      "         0.0278, -0.0773,  0.0110, -0.0159,  0.0081,  0.0408, -0.0764,  0.0629,\n",
      "         0.0393, -0.0521, -0.0336,  0.0337,  0.0702,  0.0440,  0.0573, -0.0798,\n",
      "        -0.0294,  0.0349,  0.0471, -0.0365, -0.0349, -0.0270, -0.0107, -0.0407,\n",
      "        -0.0541,  0.0566, -0.0326,  0.0308, -0.0666,  0.0858, -0.0021,  0.0840,\n",
      "        -0.0463, -0.0475, -0.0082, -0.0502, -0.0039, -0.0825, -0.0694, -0.0314,\n",
      "        -0.0586, -0.0833, -0.0059, -0.0213,  0.0753, -0.0249,  0.0677, -0.0200,\n",
      "        -0.0374,  0.0523,  0.0155, -0.0100,  0.0474, -0.0714, -0.0466,  0.0016,\n",
      "         0.0413,  0.0499, -0.0028,  0.0831, -0.0486,  0.0337,  0.0787, -0.0305,\n",
      "         0.0502,  0.0154, -0.0800,  0.0631, -0.0495,  0.0676,  0.0827, -0.0544,\n",
      "         0.0765,  0.0429,  0.0764,  0.0638, -0.0790,  0.0185, -0.0708, -0.0284])\n",
      "trfm_blocks.0.mha.w_o.0.weight \t tensor([[-0.0375, -0.0092,  0.0037,  ...,  0.0837,  0.0328, -0.0358],\n",
      "        [-0.0817, -0.0582,  0.0738,  ..., -0.0205,  0.0150, -0.0739],\n",
      "        [ 0.0633, -0.0561,  0.0767,  ..., -0.0724,  0.0034,  0.0130],\n",
      "        ...,\n",
      "        [-0.0659,  0.0146,  0.0110,  ..., -0.0297, -0.0189,  0.0632],\n",
      "        [ 0.0716, -0.0172, -0.0105,  ..., -0.0140, -0.0063,  0.0560],\n",
      "        [ 0.0341,  0.0063, -0.0549,  ..., -0.0844,  0.0185, -0.0791]])\n",
      "trfm_blocks.0.mha.w_o.0.bias \t tensor([-3.8992e-03, -6.1249e-05, -1.9295e-02, -5.5887e-02, -3.7913e-02,\n",
      "         1.0791e-02,  8.0806e-02,  8.3162e-02,  6.7867e-02,  7.7290e-03,\n",
      "        -5.9242e-02, -1.7552e-02, -5.7825e-02,  4.4016e-02, -4.7697e-02,\n",
      "        -3.6559e-02, -6.7941e-02,  4.3857e-03, -6.8277e-02, -7.2511e-02,\n",
      "        -1.5675e-03, -1.9491e-02, -5.0301e-02, -7.6691e-02, -4.8751e-02,\n",
      "        -3.1803e-02, -1.5714e-02,  4.2446e-04,  5.6203e-02, -6.7477e-02,\n",
      "        -4.6229e-02, -5.7205e-02,  4.5441e-02,  7.4623e-02, -7.9016e-02,\n",
      "         5.2231e-02, -5.5748e-02, -2.2240e-02,  2.6903e-02,  3.4300e-02,\n",
      "        -6.3237e-02, -3.7496e-02, -3.5150e-02,  4.3982e-02, -5.9839e-02,\n",
      "        -4.1017e-02, -5.7087e-02, -3.0989e-02,  5.8385e-02,  1.7400e-03,\n",
      "        -2.4145e-02, -1.3876e-02,  1.7232e-03,  2.0271e-02,  4.1919e-02,\n",
      "         1.6619e-02,  4.6018e-02, -2.4239e-02, -1.4449e-02, -8.5687e-02,\n",
      "         4.0744e-02, -5.6419e-02,  3.0909e-02, -6.0876e-02, -3.5662e-02,\n",
      "        -5.0094e-02, -5.9629e-02, -8.3679e-02, -3.6401e-03,  2.5675e-02,\n",
      "        -1.0039e-02, -8.4954e-02, -4.7600e-02, -8.0627e-02,  6.7987e-02,\n",
      "         2.4045e-02,  2.5815e-02, -7.6422e-02,  7.8018e-02,  6.8898e-02,\n",
      "        -5.1024e-02,  8.1778e-02, -6.7959e-02, -8.3192e-02, -2.8239e-02,\n",
      "        -7.2554e-03, -5.5090e-02, -6.5467e-02, -7.5592e-03,  1.2979e-02,\n",
      "         8.7305e-02, -3.5673e-03,  4.9400e-02,  5.6590e-02,  4.8334e-02,\n",
      "        -1.6324e-02, -3.8615e-02, -4.4856e-02,  4.6033e-02,  1.3881e-02,\n",
      "         1.8305e-02, -3.7328e-02,  2.6634e-02, -3.4909e-02, -7.6393e-02,\n",
      "        -6.8738e-02,  7.4953e-03,  4.2063e-02,  1.7852e-02,  7.4890e-02,\n",
      "         5.9511e-02, -3.6392e-02, -1.0878e-03,  8.4071e-02, -2.6789e-02,\n",
      "        -7.6501e-02,  3.4952e-02, -6.1804e-03, -6.9486e-02,  5.2052e-03,\n",
      "         1.7004e-02, -2.8113e-02, -1.6980e-03,  7.4803e-02,  3.4838e-02,\n",
      "         4.7774e-02,  8.1402e-02,  2.9107e-02])\n",
      "trfm_blocks.0.norm1.weight \t tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000])\n",
      "trfm_blocks.0.norm1.bias \t tensor([ 3.1549e-05, -3.3513e-05,  3.1265e-05, -3.3621e-05,  3.3204e-05,\n",
      "        -3.1603e-05,  2.9685e-05, -2.7424e-05, -3.4556e-05, -3.1429e-05,\n",
      "        -3.3531e-05,  2.7243e-05, -3.3922e-05, -2.8491e-05,  3.0526e-05,\n",
      "        -2.9128e-05,  3.3730e-05, -3.1526e-05,  3.6683e-05, -2.6426e-05,\n",
      "         3.1727e-05,  3.1055e-05,  3.3457e-05, -3.1216e-05,  2.9182e-05,\n",
      "        -2.3304e-05,  3.3370e-05, -3.1601e-05, -3.1327e-05,  3.2621e-05,\n",
      "        -3.3332e-05, -3.2626e-05, -3.1965e-05,  3.3006e-05,  3.2134e-05,\n",
      "         3.0639e-05, -3.1542e-05,  3.4050e-05, -3.7539e-05, -3.1437e-05,\n",
      "         2.9136e-05,  3.1577e-05,  3.2611e-05,  3.3059e-05, -3.3691e-05,\n",
      "        -3.6819e-05,  3.3134e-05, -1.1089e-05,  3.7169e-05,  3.0728e-05,\n",
      "         3.3051e-05, -3.1689e-05, -3.2978e-05, -3.1081e-05, -3.1199e-05,\n",
      "         3.0370e-05, -3.1535e-05, -3.4281e-05, -3.4261e-05, -2.6128e-05,\n",
      "        -3.1735e-05, -3.0857e-05,  2.9482e-05,  3.3000e-05,  2.7167e-05,\n",
      "         3.3162e-05,  3.1455e-05, -3.2348e-05, -3.0629e-05,  3.7000e-05,\n",
      "        -3.2836e-05, -3.4869e-05,  3.2041e-05,  2.9911e-05,  3.5685e-05,\n",
      "         2.7749e-05,  1.9019e-05,  3.1957e-05,  1.6945e-05, -2.3547e-05,\n",
      "         2.3663e-05,  3.4090e-05,  3.0394e-05, -3.2257e-05, -3.3226e-05,\n",
      "         2.9583e-05, -3.5619e-05, -3.5822e-05, -2.7693e-05, -3.2429e-05,\n",
      "        -3.5302e-05,  3.2003e-05, -3.4924e-05, -3.2067e-05, -3.3128e-05,\n",
      "         2.7883e-05,  3.2450e-05,  6.2582e-07, -3.3772e-05, -2.7709e-05,\n",
      "         3.5569e-05,  3.2337e-05, -3.0472e-05,  1.5410e-05,  3.1463e-05,\n",
      "         3.1806e-05, -3.0359e-05,  3.5091e-05, -3.3393e-05, -3.2366e-05,\n",
      "         3.2361e-05,  3.1870e-05,  3.2248e-05, -2.7800e-05, -3.4868e-05,\n",
      "        -3.4444e-05, -3.3523e-05,  2.4420e-05,  2.4425e-05, -3.1679e-05,\n",
      "        -2.9985e-05,  3.0432e-05, -3.5597e-05,  2.9300e-05, -3.1958e-05,\n",
      "        -3.0290e-05,  3.1426e-05, -2.9544e-05])\n",
      "trfm_blocks.0.norm2.weight \t tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000])\n",
      "trfm_blocks.0.norm2.bias \t tensor([ 3.1803e-05, -3.1811e-05,  3.1817e-05, -3.1820e-05,  3.1813e-05,\n",
      "        -3.1812e-05,  3.1806e-05, -3.1802e-05, -3.1803e-05, -3.1803e-05,\n",
      "        -3.1795e-05,  3.1803e-05,  3.1702e-05, -3.1803e-05,  3.1805e-05,\n",
      "        -3.1779e-05,  3.1811e-05, -3.1800e-05, -3.1832e-05, -3.1804e-05,\n",
      "         3.1804e-05,  3.1803e-05,  3.1798e-05, -3.1810e-05,  3.1812e-05,\n",
      "        -3.1820e-05,  3.1813e-05, -3.1814e-05,  3.1822e-05,  3.1802e-05,\n",
      "        -3.1804e-05, -3.1803e-05, -3.1815e-05,  3.1804e-05,  3.1785e-05,\n",
      "         3.1811e-05, -3.1810e-05,  3.1814e-05,  3.1470e-05, -3.1805e-05,\n",
      "         3.1805e-05,  3.1805e-05,  3.1805e-05,  3.1809e-05, -3.1824e-05,\n",
      "        -3.1822e-05,  3.1802e-05, -3.1790e-05,  3.1801e-05,  3.1807e-05,\n",
      "         3.1812e-05, -3.1803e-05,  3.1783e-05, -3.1808e-05, -3.1806e-05,\n",
      "         3.1810e-05, -3.1812e-05, -3.1787e-05,  3.1773e-05, -2.9989e-05,\n",
      "        -3.1837e-05, -3.1805e-05,  3.1805e-05,  3.1813e-05,  3.1800e-05,\n",
      "         3.1803e-05,  3.1824e-05, -3.1806e-05, -3.1808e-05,  3.1824e-05,\n",
      "        -3.1841e-05,  3.1884e-05,  3.1802e-05,  3.1800e-05,  3.1802e-05,\n",
      "         3.1818e-05, -3.1816e-05,  3.1807e-05, -3.1875e-05, -3.1805e-05,\n",
      "         3.1730e-05,  3.1802e-05,  3.1809e-05, -3.1800e-05, -3.1810e-05,\n",
      "         3.1804e-05, -3.1810e-05, -3.1817e-05, -3.1819e-05, -3.1809e-05,\n",
      "         3.1874e-05,  3.1810e-05, -3.1820e-05,  3.1839e-05, -3.1814e-05,\n",
      "        -3.1779e-05,  3.1817e-05, -3.1819e-05, -3.1819e-05, -3.1826e-05,\n",
      "         3.1803e-05,  3.1811e-05, -3.1816e-05, -3.1791e-05,  3.1808e-05,\n",
      "         3.1808e-05, -3.1805e-05, -3.1870e-05, -3.1768e-05, -3.1809e-05,\n",
      "         3.1801e-05,  3.1805e-05,  3.1802e-05, -3.1801e-05,  3.1872e-05,\n",
      "         3.1834e-05, -3.1814e-05,  3.1800e-05,  3.1808e-05, -3.1812e-05,\n",
      "        -3.1803e-05,  3.1822e-05,  3.1802e-05,  3.1818e-05, -3.1804e-05,\n",
      "        -3.1804e-05,  3.1799e-05, -3.1809e-05])\n",
      "trfm_blocks.0.ff.0.weight \t tensor([[-0.0730, -0.0810, -0.0902,  ..., -0.0527,  0.0060, -0.0817],\n",
      "        [-0.0931, -0.0907,  0.0769,  ...,  0.0428, -0.0005,  0.0784],\n",
      "        [ 0.0104, -0.0241, -0.0804,  ..., -0.0456,  0.0563,  0.0065],\n",
      "        ...,\n",
      "        [ 0.0187, -0.0077,  0.0905,  ...,  0.0690, -0.0367, -0.0045],\n",
      "        [-0.0024, -0.0558,  0.0003,  ..., -0.0784, -0.0736, -0.0335],\n",
      "        [-0.0052, -0.0782, -0.0025,  ...,  0.0732, -0.0965, -0.0859]])\n",
      "trfm_blocks.0.ff.0.bias \t tensor([-2.2338e-05,  3.4032e-05,  3.2880e-05,  3.5536e-05,  3.2784e-05,\n",
      "        -3.4362e-05,  3.4705e-05,  2.6735e-05,  3.1722e-05, -2.2536e-05,\n",
      "        -3.5196e-05,  3.7172e-05, -3.0256e-05, -3.3141e-05, -3.1253e-05,\n",
      "         3.3736e-05, -2.4969e-05,  2.2254e-05,  3.5919e-05, -3.3944e-05,\n",
      "         3.2408e-05, -3.5260e-05,  2.7793e-05, -3.4116e-05,  3.4721e-05,\n",
      "        -3.0675e-05,  2.5044e-05,  2.1671e-05, -2.1253e-05,  3.6294e-05,\n",
      "        -2.3359e-05, -3.5514e-05,  3.4538e-05, -2.3348e-05,  3.2573e-05,\n",
      "        -2.5902e-05, -2.6272e-05,  2.9240e-05,  3.1024e-05, -3.6318e-05,\n",
      "        -3.4765e-05,  3.3110e-05, -3.0100e-05, -3.3981e-05, -2.7277e-05,\n",
      "         3.0748e-05, -2.9971e-05, -3.3305e-05,  3.2730e-05, -3.3785e-05,\n",
      "         2.7295e-05, -2.6355e-05, -3.4616e-05, -2.7684e-05,  2.0026e-05,\n",
      "         3.2957e-05, -3.4056e-05, -2.4429e-05,  3.3560e-05, -3.1962e-05,\n",
      "         2.3138e-05,  3.5810e-05, -2.6666e-05,  3.3062e-05, -2.8009e-05,\n",
      "         3.3151e-05,  2.6466e-05,  2.4662e-05,  3.0190e-05, -3.4887e-05,\n",
      "        -3.2126e-05, -3.3400e-05, -3.2067e-05, -2.3406e-05, -3.4440e-05,\n",
      "        -3.1545e-05, -3.4458e-05,  3.3182e-05, -2.7347e-05, -2.9796e-05,\n",
      "        -3.3114e-05, -2.6856e-05, -3.0742e-05,  2.1198e-05, -2.7916e-05,\n",
      "         2.0582e-05, -3.4738e-05,  2.2564e-05, -2.6286e-05,  2.9998e-05,\n",
      "        -3.2819e-05,  1.9276e-05,  3.7051e-05,  3.3774e-05, -2.9236e-05,\n",
      "         3.4912e-05, -3.2929e-05, -3.4913e-05, -2.4894e-05, -2.5018e-05,\n",
      "         3.2811e-05, -3.3910e-05, -2.5523e-05,  3.5142e-05, -2.5811e-05,\n",
      "         3.5196e-05,  3.2725e-05, -2.0342e-05, -3.2974e-05, -3.5271e-05,\n",
      "         2.1454e-05, -3.2510e-05,  2.2600e-05,  3.3593e-05, -3.3659e-05,\n",
      "         2.9851e-05, -3.2734e-05,  1.8039e-05, -2.2749e-05, -2.5109e-05,\n",
      "        -3.7090e-05, -2.9329e-05,  2.5353e-05,  2.8164e-05, -3.2972e-05,\n",
      "         3.3122e-05, -3.1021e-05, -3.4605e-05,  3.0178e-05,  3.4405e-05,\n",
      "         3.1710e-05, -3.5419e-05,  2.1368e-05, -2.5910e-05,  2.2880e-05,\n",
      "        -3.2362e-05, -3.4898e-05, -3.4435e-05, -3.1421e-05, -3.1601e-05,\n",
      "         3.3282e-05,  2.5065e-05,  2.7875e-05, -3.2858e-05,  3.4442e-05,\n",
      "         3.4922e-05, -3.4742e-05,  3.5987e-05, -2.9468e-05, -2.3290e-05,\n",
      "         3.4509e-05,  3.3714e-05,  2.3214e-05, -2.4247e-05,  3.5217e-05,\n",
      "        -2.5301e-05,  3.5637e-05, -3.1642e-05, -3.2115e-05,  3.5659e-05,\n",
      "        -3.3810e-05,  2.2693e-05,  3.2506e-05,  3.3430e-05,  3.1405e-05,\n",
      "        -3.6530e-05,  2.4656e-05,  3.2899e-05,  2.3981e-05,  3.3674e-05,\n",
      "         3.5412e-05, -3.4890e-05,  2.6856e-05, -3.2621e-05,  2.2758e-05,\n",
      "        -3.4148e-05,  2.6253e-05,  3.1239e-05, -2.0662e-05,  2.8591e-05,\n",
      "         3.4255e-05, -3.4306e-05,  3.3063e-05, -3.4397e-05, -2.5793e-05,\n",
      "         3.5565e-05,  3.5073e-05, -2.8674e-05, -3.0116e-05,  3.4899e-05,\n",
      "         3.0448e-05,  2.9070e-05,  3.4842e-05,  3.4152e-05, -3.1685e-05,\n",
      "         3.4195e-05,  3.0973e-05, -2.1187e-05, -2.3745e-05, -2.6631e-05,\n",
      "         2.6898e-05, -2.7435e-05, -2.3120e-05, -2.3624e-05,  3.4006e-05,\n",
      "         3.4372e-05, -3.4357e-05, -3.0791e-05,  2.1615e-05,  3.4308e-05,\n",
      "         3.1290e-05, -3.3105e-05, -3.2785e-05,  2.7378e-05,  1.6481e-05,\n",
      "         2.1671e-05,  3.5090e-05, -3.2036e-05,  2.4523e-05, -3.5080e-05,\n",
      "        -2.7238e-05, -3.2905e-05, -3.3748e-05, -3.3529e-05,  2.2245e-05,\n",
      "         3.4295e-05, -3.1669e-05,  2.9605e-05, -3.2377e-05, -3.4443e-05,\n",
      "        -3.5481e-05,  3.0812e-05, -2.1456e-05, -2.8434e-05, -2.8007e-05,\n",
      "         3.3064e-05,  3.5597e-05, -3.2442e-05,  2.8007e-05, -3.1259e-05,\n",
      "        -3.3777e-05,  1.3084e-05, -3.4781e-05, -2.1548e-05, -3.1808e-05,\n",
      "        -1.8089e-05, -3.5923e-05,  3.1093e-05,  3.3677e-05,  3.0964e-05,\n",
      "         3.3534e-05,  3.0425e-05,  3.2783e-05, -3.2599e-05, -3.4671e-05,\n",
      "        -3.3888e-05,  2.7507e-05, -3.2596e-05, -3.5023e-05, -3.1619e-05,\n",
      "        -1.5615e-05,  3.4363e-05,  3.2076e-05, -3.4885e-05, -3.1565e-05,\n",
      "        -2.9222e-05, -2.4056e-05, -3.4118e-05,  3.3894e-05, -2.8463e-05,\n",
      "         3.0034e-05,  2.4575e-05,  3.4489e-05,  3.2821e-05, -1.9833e-05,\n",
      "        -2.4755e-05,  3.4963e-05, -3.3959e-05,  3.2563e-05, -3.4538e-05,\n",
      "        -3.5514e-05, -3.5076e-05, -2.6231e-05, -3.0592e-05, -3.1560e-05,\n",
      "         2.2170e-05, -2.1932e-05, -2.4783e-05,  2.5162e-05,  2.3363e-05,\n",
      "         1.5542e-05, -2.1017e-05, -2.4655e-05, -2.5555e-05,  3.6970e-05,\n",
      "         3.5688e-05, -2.8409e-05,  3.4949e-05, -2.8359e-05, -2.7078e-05,\n",
      "        -2.7548e-05,  3.2332e-05,  2.4803e-05,  2.6975e-05,  3.4921e-05,\n",
      "         3.0194e-05, -2.9290e-05, -2.8069e-05, -2.7988e-05,  3.2263e-05,\n",
      "        -2.8813e-05,  2.6263e-05, -2.7965e-05,  2.4933e-05, -3.3573e-05,\n",
      "         3.0543e-05, -3.0256e-05, -3.1225e-05,  3.5989e-05, -3.2872e-05,\n",
      "        -3.4737e-05, -3.2362e-05, -2.0963e-05, -3.1217e-05, -2.1889e-05,\n",
      "         2.6301e-05,  3.3774e-05, -3.4474e-05, -2.4299e-05,  3.4021e-05,\n",
      "        -3.5750e-05, -3.2469e-05, -3.5050e-05,  3.4531e-05, -3.5097e-05,\n",
      "         3.5593e-05,  3.4452e-05, -2.6978e-05,  2.1821e-05,  1.9667e-05,\n",
      "         2.8165e-05, -3.2459e-05, -2.8519e-05,  2.7705e-05,  3.5308e-05,\n",
      "         3.6347e-05,  2.9890e-05,  3.1646e-05,  3.4578e-05, -3.2708e-05,\n",
      "        -2.8385e-05,  2.1048e-05,  2.9689e-05, -2.5905e-05,  3.7236e-05,\n",
      "         3.5295e-05, -2.7669e-05, -2.8971e-05,  3.2182e-05,  2.9888e-05,\n",
      "        -3.4786e-05, -3.5260e-05,  3.3032e-05, -2.3331e-05, -3.3694e-05,\n",
      "         3.3544e-05,  2.9308e-05, -3.1680e-05,  2.2767e-05,  3.3623e-05,\n",
      "        -3.3464e-05,  3.2838e-05,  2.1049e-05, -3.3192e-05,  3.4484e-05,\n",
      "         3.0246e-05,  1.8062e-05, -3.4236e-05,  2.3380e-05, -2.1944e-05,\n",
      "         3.0029e-05, -2.9484e-05, -3.4997e-05,  3.5053e-05,  2.4909e-05,\n",
      "         2.6634e-05,  3.4539e-05,  3.1900e-05,  3.2307e-05,  3.6180e-05,\n",
      "         2.0595e-05,  2.9665e-05,  3.5865e-05, -3.5545e-05,  3.0365e-05,\n",
      "         3.4081e-05,  3.6102e-05,  3.4045e-05,  3.3111e-05, -3.4851e-05,\n",
      "         2.3429e-05, -2.7360e-05,  3.1872e-05,  2.7034e-05,  3.1834e-05,\n",
      "        -2.2189e-05,  2.5130e-05, -3.5143e-05,  3.6149e-05,  3.4484e-05,\n",
      "        -2.8503e-05, -3.2502e-05, -2.3225e-05, -2.6962e-05, -3.0279e-05,\n",
      "        -2.7358e-05, -2.7281e-05,  4.0549e-05,  2.1934e-05,  3.0958e-05,\n",
      "        -3.5084e-05,  3.4538e-05,  3.0531e-05, -3.4382e-05, -3.2118e-05,\n",
      "         2.4385e-05,  3.3238e-05,  3.5253e-05, -3.2864e-05, -3.4755e-05,\n",
      "         3.4979e-05,  3.2339e-05,  1.9517e-05, -2.9364e-05, -3.1976e-05,\n",
      "         3.6024e-05, -2.8434e-05,  3.5195e-05, -3.3079e-05,  2.6469e-05,\n",
      "        -2.6170e-05,  2.9911e-05, -3.3926e-05,  2.7924e-05, -3.4610e-05,\n",
      "        -3.0853e-05,  2.9231e-05, -3.5017e-05,  3.6299e-05,  3.5111e-05,\n",
      "         3.2329e-05,  3.3394e-05,  2.7856e-05,  2.6319e-05,  3.4885e-05,\n",
      "        -2.1995e-05, -3.3595e-05,  3.1059e-05,  3.4859e-05, -3.4776e-05,\n",
      "        -2.1641e-05, -3.1723e-05,  3.5773e-05,  3.3197e-05,  3.4527e-05,\n",
      "         1.9212e-05, -2.8129e-05, -3.3435e-05,  3.5570e-05, -3.2172e-05,\n",
      "         3.4396e-05,  1.9766e-05,  3.0727e-05, -3.5642e-05, -3.1552e-05,\n",
      "        -2.5502e-05,  2.1234e-05,  3.1865e-05, -3.0664e-05, -2.4141e-05,\n",
      "         3.4880e-05, -2.2955e-05, -3.3680e-05, -3.1260e-05,  2.0926e-05,\n",
      "         2.7729e-05, -2.9971e-05,  3.2738e-05,  3.2882e-05, -3.2665e-05,\n",
      "        -2.5749e-05,  3.2830e-05,  3.0039e-05,  2.8385e-05, -2.6223e-05,\n",
      "         3.3377e-05, -2.1011e-05,  4.0382e-05, -2.7976e-05,  2.8537e-05,\n",
      "        -2.2636e-05,  3.4172e-05,  3.5140e-05, -3.4152e-05,  3.4293e-05,\n",
      "        -2.5078e-05,  3.2753e-05,  3.6209e-05,  3.2204e-05, -3.1401e-05,\n",
      "        -3.5039e-05, -3.5909e-05])\n",
      "trfm_blocks.0.ff.2.weight \t tensor([[ 0.0603, -0.0621,  0.0569,  ..., -0.0237,  0.0535, -0.0101],\n",
      "        [-0.0787, -0.0328,  0.0550,  ..., -0.0052,  0.0662,  0.0520],\n",
      "        [-0.0038, -0.0160, -0.0029,  ..., -0.0364,  0.0557, -0.0341],\n",
      "        ...,\n",
      "        [ 0.0389, -0.0098, -0.0827,  ..., -0.0506,  0.0514,  0.0099],\n",
      "        [ 0.0822, -0.0477,  0.0554,  ..., -0.0373,  0.0464, -0.0361],\n",
      "        [-0.0733, -0.0376, -0.0784,  ...,  0.0038, -0.0342,  0.0912]])\n",
      "trfm_blocks.0.ff.2.bias \t tensor([ 3.1394e-05, -3.1850e-05,  3.2374e-05, -3.2575e-05,  3.1855e-05,\n",
      "        -3.1612e-05,  3.1698e-05, -3.1149e-05, -3.1516e-05, -3.1380e-05,\n",
      "        -3.1238e-05,  3.1342e-05, -2.6525e-05, -3.1710e-05,  3.1590e-05,\n",
      "        -3.1590e-05,  3.1624e-05, -3.1514e-05, -3.2357e-05, -3.1315e-05,\n",
      "         3.1606e-05,  3.1151e-05,  3.1271e-05, -3.1678e-05,  3.1833e-05,\n",
      "        -3.1375e-05,  3.1938e-05, -3.1781e-05,  3.2085e-05,  3.1614e-05,\n",
      "        -3.1740e-05, -3.1413e-05, -3.1796e-05,  3.1738e-05,  3.2131e-05,\n",
      "         3.1636e-05, -3.1646e-05,  3.2144e-05, -3.5312e-05, -3.1587e-05,\n",
      "         3.1567e-05,  3.1695e-05,  3.1668e-05,  3.1470e-05, -3.1954e-05,\n",
      "        -3.2231e-05,  3.1602e-05, -2.9757e-05,  3.1415e-05,  3.1628e-05,\n",
      "         3.1825e-05, -3.1339e-05,  3.0733e-05, -3.1552e-05, -3.1605e-05,\n",
      "         3.1533e-05, -3.1710e-05, -3.2137e-05,  3.0336e-05, -2.0959e-05,\n",
      "        -3.2724e-05, -3.1543e-05,  3.0622e-05,  3.2078e-05,  3.1477e-05,\n",
      "         3.1247e-05,  3.2660e-05, -3.1560e-05, -3.1649e-05,  3.2534e-05,\n",
      "        -3.3098e-05,  3.1698e-05,  3.1223e-05,  3.1026e-05,  3.2558e-05,\n",
      "         3.2367e-05, -3.2133e-05,  3.1698e-05, -3.4742e-05, -3.1724e-05,\n",
      "         6.8381e-06,  3.1500e-05,  3.1742e-05, -3.1551e-05, -3.1515e-05,\n",
      "         3.1691e-05, -3.1749e-05, -3.1717e-05, -3.2092e-05, -3.1619e-05,\n",
      "         3.4399e-05,  3.1552e-05, -3.2159e-05,  3.3430e-05, -3.1986e-05,\n",
      "        -2.9475e-05,  3.1888e-05, -3.1628e-05, -3.2330e-05, -3.2155e-05,\n",
      "         3.1424e-05,  3.1895e-05, -3.1600e-05, -3.1759e-05,  3.1716e-05,\n",
      "         3.1606e-05, -3.1458e-05, -3.3021e-05, -2.9997e-05, -3.1689e-05,\n",
      "         3.1545e-05,  3.1519e-05,  3.1374e-05, -3.1494e-05,  3.6374e-05,\n",
      "         3.2670e-05, -3.1662e-05,  3.1050e-05,  2.9834e-05, -3.1782e-05,\n",
      "        -3.1283e-05,  3.2705e-05,  3.1377e-05,  3.1893e-05, -3.1622e-05,\n",
      "        -3.1431e-05,  3.1500e-05, -3.1721e-05])\n",
      "toprobs.weight \t tensor([[ 0.0061, -0.0607,  0.0837, -0.0774,  0.0174, -0.0161,  0.0109,  0.0115,\n",
      "         -0.0515, -0.0053, -0.0419,  0.0420, -0.0151, -0.0831,  0.0395, -0.0268,\n",
      "          0.0493, -0.0140,  0.0571, -0.0280,  0.0807,  0.0581,  0.0846, -0.0883,\n",
      "          0.0146,  0.0586,  0.0814, -0.0628,  0.0489, -0.0051, -0.0288, -0.0759,\n",
      "          0.0070,  0.0578,  0.0775,  0.0731, -0.0708, -0.0023, -0.0496, -0.0783,\n",
      "          0.0828,  0.0113, -0.0294,  0.0440,  0.0408,  0.0292,  0.0683,  0.0492,\n",
      "         -0.0028,  0.0492,  0.0236,  0.0121,  0.0344, -0.0758, -0.0284,  0.0432,\n",
      "         -0.0791, -0.0685,  0.0344,  0.0458, -0.0056, -0.0803, -0.0392,  0.0592,\n",
      "          0.0004,  0.0092,  0.0198, -0.0324, -0.0756, -0.0142,  0.0655, -0.0537,\n",
      "          0.0745, -0.0055,  0.0881,  0.0257, -0.0122,  0.0614, -0.0024, -0.0169,\n",
      "          0.0270,  0.0681,  0.0492, -0.0718, -0.0626,  0.0108,  0.0015, -0.0055,\n",
      "          0.0202, -0.0025, -0.0250,  0.0531,  0.0529,  0.0137, -0.0097, -0.0723,\n",
      "         -0.0181,  0.0043, -0.0351, -0.0852,  0.0502,  0.0793, -0.0548,  0.0137,\n",
      "          0.0739,  0.0325, -0.0701,  0.0128,  0.0716, -0.0665,  0.0532,  0.0861,\n",
      "          0.0840, -0.0191, -0.0547, -0.0484, -0.0355,  0.0743, -0.0077, -0.0436,\n",
      "         -0.0469, -0.0277, -0.0083,  0.0803, -0.0677, -0.0538,  0.0059,  0.0576],\n",
      "        [-0.0732,  0.0605,  0.0414, -0.0411, -0.0644,  0.0351, -0.0485,  0.0790,\n",
      "          0.0107,  0.0800, -0.0094, -0.0367, -0.0186, -0.0310, -0.0876, -0.0152,\n",
      "         -0.0723,  0.0342,  0.0751,  0.0205, -0.0348, -0.0187,  0.0404,  0.0793,\n",
      "         -0.0825,  0.0620, -0.0002,  0.0066,  0.0195, -0.0726,  0.0414,  0.0099,\n",
      "          0.0546,  0.0121,  0.0601, -0.0592,  0.0191, -0.0719, -0.0507,  0.0613,\n",
      "          0.0054, -0.0599, -0.0784, -0.0321,  0.0654,  0.0583,  0.0126,  0.0731,\n",
      "         -0.0684, -0.0629, -0.0757,  0.0869,  0.0203,  0.0577,  0.0794, -0.0261,\n",
      "         -0.0114, -0.0528,  0.0225,  0.0460,  0.0077,  0.0419, -0.0561, -0.0295,\n",
      "         -0.0275, -0.0687, -0.0086,  0.0853,  0.0648, -0.0358,  0.0776, -0.0583,\n",
      "         -0.0038, -0.0610,  0.0712, -0.0138,  0.0303, -0.0661,  0.0038,  0.0439,\n",
      "          0.0219,  0.0163, -0.0820, -0.0352, -0.0025, -0.0534,  0.0628,  0.0196,\n",
      "          0.0318,  0.0818, -0.0315, -0.0371,  0.0849,  0.0010,  0.0546, -0.0678,\n",
      "         -0.0506,  0.0267, -0.0054, -0.0655, -0.0139, -0.0471, -0.0169,  0.0290,\n",
      "         -0.0716, -0.0565,  0.0574,  0.0193,  0.0823,  0.0589, -0.0133, -0.0304,\n",
      "          0.0382,  0.0362, -0.0609, -0.0634,  0.0266,  0.0309, -0.0200,  0.0597,\n",
      "          0.0109, -0.0565, -0.0635,  0.0490,  0.0336,  0.0675, -0.0402,  0.0818]])\n",
      "toprobs.bias \t tensor([-0.0294,  0.0635])\n",
      "Optimizer's state_dict:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state \t {0: {'step': 63, 'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\r\n",
      "          0.0000e+00,  0.0000e+00],\r\n",
      "        [-1.1634e-03,  9.5109e-04, -4.7927e-04,  ...,  7.0324e-04,\r\n",
      "         -4.7953e-04,  1.2503e-03],\r\n",
      "        [-9.8753e-05,  8.8170e-05, -3.6461e-05,  ...,  8.9684e-05,\r\n",
      "         -5.3466e-05,  1.2733e-04],\r\n",
      "        ...,\r\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\r\n",
      "          0.0000e+00,  0.0000e+00],\r\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\r\n",
      "          0.0000e+00,  0.0000e+00],\r\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\r\n",
      "          0.0000e+00,  0.0000e+00]]), 'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\r\n",
      "         0.0000e+00],\r\n",
      "        [6.2477e-07, 4.3881e-07, 1.1684e-07,  ..., 2.2475e-07, 1.1106e-07,\r\n",
      "         7.2727e-07],\r\n",
      "        [8.9104e-09, 6.7384e-09, 1.3663e-09,  ..., 7.6352e-09, 2.9266e-09,\r\n",
      "         1.6498e-08],\r\n",
      "        ...,\r\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\r\n",
      "         0.0000e+00],\r\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\r\n",
      "         0.0000e+00],\r\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\r\n",
      "         0.0000e+00]])}, 1: {'step': 63, 'exp_avg': tensor([[-8.7885e-06,  3.8783e-06, -7.3315e-06,  ...,  5.2755e-06,\r\n",
      "         -2.7911e-06,  1.2115e-05],\r\n",
      "        [-8.5053e-06,  4.7509e-06, -2.4941e-06,  ...,  3.5019e-06,\r\n",
      "          2.8270e-07,  9.9999e-06],\r\n",
      "        [-1.2953e-05,  6.4831e-06, -4.8501e-06,  ...,  8.5063e-06,\r\n",
      "         -4.6193e-06,  1.3468e-05],\r\n",
      "        ...,\r\n",
      "        [-2.6471e-06,  2.9275e-06, -1.7004e-06,  ...,  2.1878e-06,\r\n",
      "         -7.6372e-07,  1.7091e-06],\r\n",
      "        [-1.7081e-06,  1.8933e-06, -7.8935e-07,  ...,  1.5771e-06,\r\n",
      "         -7.8321e-07,  1.5445e-06],\r\n",
      "        [-2.8076e-06,  1.7188e-06,  1.7185e-07,  ...,  1.8515e-06,\r\n",
      "         -4.3134e-07,  3.2661e-06]]), 'exp_avg_sq': tensor([[9.5213e-11, 4.3607e-11, 2.6977e-11,  ..., 2.0211e-11, 1.9025e-11,\r\n",
      "         1.1160e-10],\r\n",
      "        [6.6328e-11, 3.3595e-11, 6.6482e-12,  ..., 1.6872e-11, 7.4290e-12,\r\n",
      "         6.0468e-11],\r\n",
      "        [6.2466e-11, 3.0971e-11, 2.1090e-11,  ..., 3.8616e-11, 2.5518e-11,\r\n",
      "         1.2150e-10],\r\n",
      "        ...,\r\n",
      "        [3.0677e-12, 3.1965e-12, 1.0383e-12,  ..., 2.3725e-12, 4.8397e-13,\r\n",
      "         3.5288e-12],\r\n",
      "        [2.4186e-12, 2.5999e-12, 5.2403e-13,  ..., 1.6390e-12, 1.0611e-12,\r\n",
      "         5.0637e-12],\r\n",
      "        [3.9348e-12, 1.2286e-12, 7.0772e-13,  ..., 3.6588e-12, 1.7452e-12,\r\n",
      "         7.4837e-12]])}, 2: {'step': 63, 'exp_avg': tensor([[-8.7786e-06, -2.2147e-05,  1.9537e-05,  ...,  2.1876e-05,\r\n",
      "         -6.5218e-06, -2.4118e-06],\r\n",
      "        [ 9.6953e-06,  1.1398e-05, -3.0850e-05,  ..., -2.1468e-05,\r\n",
      "          1.0586e-05, -1.0043e-06],\r\n",
      "        [-3.5929e-05, -1.0654e-04,  9.3705e-05,  ...,  8.2217e-05,\r\n",
      "         -3.4020e-05, -2.6713e-05],\r\n",
      "        ...,\r\n",
      "        [ 3.2748e-05,  9.5731e-05, -8.6398e-05,  ..., -8.0920e-05,\r\n",
      "          4.4171e-05,  1.9184e-05],\r\n",
      "        [-1.4313e-05, -3.9709e-05,  3.0741e-05,  ...,  2.4421e-05,\r\n",
      "         -7.7594e-06,  2.5179e-06],\r\n",
      "        [ 3.8155e-05,  1.2056e-04, -1.1737e-04,  ..., -1.0953e-04,\r\n",
      "          5.7495e-05,  2.6733e-05]]), 'exp_avg_sq': tensor([[1.0669e-10, 8.4884e-10, 9.6630e-10,  ..., 8.4020e-10, 1.2653e-10,\r\n",
      "         3.7662e-11],\r\n",
      "        [2.7159e-10, 1.2801e-09, 1.8166e-09,  ..., 1.3406e-09, 1.9634e-10,\r\n",
      "         5.9195e-11],\r\n",
      "        [5.2026e-10, 3.6695e-09, 3.8630e-09,  ..., 3.2293e-09, 4.1191e-10,\r\n",
      "         1.5814e-10],\r\n",
      "        ...,\r\n",
      "        [6.2529e-10, 4.9883e-09, 5.4579e-09,  ..., 4.5049e-09, 9.0440e-10,\r\n",
      "         1.8606e-10],\r\n",
      "        [2.5921e-10, 1.2660e-09, 1.7561e-09,  ..., 1.2737e-09, 1.3424e-10,\r\n",
      "         3.6802e-11],\r\n",
      "        [8.5441e-10, 6.0675e-09, 6.4114e-09,  ..., 5.6331e-09, 9.4647e-10,\r\n",
      "         1.9315e-10]])}, 3: {'step': 63, 'exp_avg': tensor([ 2.1749e-05,  3.8231e-05,  1.5370e-04,  4.5449e-05,  1.0802e-04,\r\n",
      "         1.2959e-05,  8.2559e-05,  6.8057e-05, -8.8255e-05,  1.5754e-04,\r\n",
      "        -8.6262e-05,  2.0936e-05, -4.3095e-05,  3.2753e-05, -4.2039e-05,\r\n",
      "         6.2083e-06,  2.3455e-05, -1.6532e-04,  9.8571e-05, -1.5473e-04,\r\n",
      "         1.1026e-04,  2.4797e-05,  5.3947e-05,  7.9066e-05, -3.3304e-05,\r\n",
      "        -1.1819e-05,  1.6613e-04, -3.5954e-05, -4.9419e-05,  1.4608e-04,\r\n",
      "        -3.5582e-05,  4.6132e-05,  7.1566e-05,  9.5214e-05,  1.7504e-04,\r\n",
      "        -1.5955e-04,  1.1492e-06,  1.1120e-04, -2.2616e-04, -6.3591e-05,\r\n",
      "        -1.4749e-04, -9.1489e-05, -1.0129e-04,  1.8153e-04,  1.2204e-06,\r\n",
      "         4.5481e-05, -6.7642e-05, -1.4901e-05, -3.1588e-05, -5.8625e-05,\r\n",
      "         9.4629e-05, -1.3005e-05, -1.5428e-04, -1.9983e-04,  4.7869e-05,\r\n",
      "        -2.0052e-04, -1.8603e-04,  2.0274e-04, -4.9235e-05,  5.2647e-05,\r\n",
      "        -4.8378e-05,  2.1488e-05,  1.0855e-04, -1.8660e-04, -3.9879e-05,\r\n",
      "        -5.0955e-05, -1.0151e-04, -8.7714e-06, -1.8089e-04,  6.9772e-05,\r\n",
      "        -1.3104e-04,  1.9865e-04, -2.3767e-05, -6.4229e-06, -1.2959e-04,\r\n",
      "        -1.4134e-04, -1.1005e-04,  9.5154e-05, -2.6207e-05, -1.1847e-05,\r\n",
      "        -7.1505e-05, -1.1567e-06, -6.7037e-05, -7.4525e-05,  8.5793e-05,\r\n",
      "         2.9680e-05, -1.0113e-04,  8.5307e-05,  4.4736e-05, -1.1486e-05,\r\n",
      "         1.0762e-04, -1.0741e-04,  9.5491e-05,  2.6207e-05, -4.6903e-05,\r\n",
      "        -9.5463e-05, -2.0530e-04,  2.1554e-05, -1.5070e-04, -1.5154e-04,\r\n",
      "        -6.4199e-05,  2.2875e-05,  8.9266e-05,  5.3691e-05, -2.7038e-05,\r\n",
      "         4.0249e-05,  4.9822e-05, -4.4302e-05,  4.1992e-05, -5.2837e-05,\r\n",
      "         4.8276e-05, -1.2240e-04,  1.9136e-04, -6.3613e-05,  3.6857e-05,\r\n",
      "        -3.4196e-05, -6.4203e-05, -3.6160e-05, -1.4986e-04, -1.0844e-04,\r\n",
      "         1.1899e-05, -1.5407e-05,  2.9116e-05, -5.3053e-05, -6.8150e-05,\r\n",
      "        -8.8015e-05,  5.4360e-05, -1.3382e-04]), 'exp_avg_sq': tensor([1.0811e-09, 4.5446e-09, 8.0253e-09, 3.7444e-09, 7.3292e-09, 4.4746e-09,\r\n",
      "        6.2042e-09, 8.9279e-09, 8.0673e-09, 1.8143e-08, 3.5246e-09, 3.6627e-09,\r\n",
      "        5.8586e-09, 3.2257e-09, 4.2855e-09, 1.8713e-09, 9.9455e-10, 8.1449e-09,\r\n",
      "        7.4474e-09, 1.0101e-08, 6.8720e-09, 3.9145e-09, 5.4067e-09, 7.1724e-09,\r\n",
      "        2.4162e-09, 2.8272e-09, 1.0881e-08, 3.8750e-09, 5.1701e-09, 7.6574e-09,\r\n",
      "        2.4466e-09, 2.5529e-09, 2.3258e-09, 5.1707e-09, 1.6351e-08, 1.6370e-08,\r\n",
      "        2.7929e-09, 8.0002e-09, 1.8590e-08, 2.0139e-09, 9.9944e-09, 6.8360e-09,\r\n",
      "        4.6768e-09, 1.1393e-08, 4.5805e-09, 1.9055e-09, 2.2180e-09, 5.3870e-09,\r\n",
      "        5.5683e-09, 7.2838e-09, 2.1140e-09, 9.8877e-10, 1.5198e-08, 1.4345e-08,\r\n",
      "        1.5667e-09, 1.3095e-08, 1.7799e-08, 1.9882e-08, 1.6844e-09, 1.1048e-08,\r\n",
      "        2.9171e-09, 2.1277e-09, 6.2357e-09, 8.6544e-09, 2.8648e-09, 2.4751e-09,\r\n",
      "        2.0248e-08, 3.1071e-09, 1.4301e-08, 4.4449e-09, 8.1852e-09, 1.9829e-08,\r\n",
      "        3.9610e-09, 3.0362e-09, 9.3555e-09, 9.2832e-09, 6.8362e-09, 3.9728e-09,\r\n",
      "        2.1134e-09, 1.3054e-09, 3.5331e-09, 1.8639e-09, 4.7676e-09, 6.8351e-09,\r\n",
      "        7.9613e-09, 7.5411e-10, 1.0142e-08, 5.9727e-09, 4.6407e-09, 1.0816e-09,\r\n",
      "        1.4951e-08, 9.5789e-09, 6.0592e-09, 1.5155e-09, 3.7787e-09, 4.5602e-09,\r\n",
      "        2.5708e-08, 5.1120e-09, 1.0574e-08, 4.9587e-09, 4.4434e-09, 1.0905e-09,\r\n",
      "        2.5609e-09, 3.6290e-09, 2.2514e-09, 2.6104e-09, 1.7935e-09, 1.7939e-09,\r\n",
      "        2.4989e-09, 3.3154e-09, 1.1648e-09, 1.7794e-08, 1.1641e-08, 5.0384e-09,\r\n",
      "        1.1455e-09, 1.8155e-09, 6.1923e-09, 2.5340e-09, 5.7312e-09, 1.1577e-08,\r\n",
      "        1.7499e-09, 1.7820e-09, 6.4569e-09, 3.1362e-09, 4.8735e-09, 6.4351e-09,\r\n",
      "        2.3795e-09, 6.9521e-09])}, 4: {'step': 63, 'exp_avg': tensor([[ 4.4540e-05,  7.1193e-05, -7.6701e-05,  ..., -6.1674e-05,\r\n",
      "          3.2885e-06,  6.8927e-05],\r\n",
      "        [ 2.5671e-05,  5.6310e-05, -6.3589e-05,  ..., -3.9632e-05,\r\n",
      "          2.2442e-05,  2.1792e-05],\r\n",
      "        [-3.1007e-05, -5.1367e-05,  5.8350e-05,  ...,  4.1108e-05,\r\n",
      "         -6.2451e-06, -4.0941e-05],\r\n",
      "        ...,\r\n",
      "        [-2.8208e-05, -1.9905e-05,  3.1681e-05,  ...,  2.2362e-05,\r\n",
      "          3.5381e-07,  5.3705e-06],\r\n",
      "        [ 8.6227e-05,  1.2883e-04, -1.3700e-04,  ..., -1.1534e-04,\r\n",
      "          2.7728e-05,  1.1564e-04],\r\n",
      "        [ 8.8085e-05,  1.3728e-04, -1.3161e-04,  ..., -1.1238e-04,\r\n",
      "          2.8241e-05,  1.2356e-04]]), 'exp_avg_sq': tensor([[7.8462e-10, 1.9530e-09, 2.4722e-09,  ..., 2.3225e-09, 3.4369e-10,\r\n",
      "         2.2871e-09],\r\n",
      "        [5.4308e-10, 1.5650e-09, 1.9975e-09,  ..., 2.0299e-09, 1.8921e-10,\r\n",
      "         1.5684e-09],\r\n",
      "        [4.6765e-10, 1.0867e-09, 1.3863e-09,  ..., 1.4199e-09, 2.5173e-10,\r\n",
      "         1.3291e-09],\r\n",
      "        ...,\r\n",
      "        [2.1873e-10, 5.3892e-10, 4.5685e-10,  ..., 7.3927e-10, 1.4958e-10,\r\n",
      "         1.1213e-09],\r\n",
      "        [3.1066e-09, 7.1575e-09, 9.1128e-09,  ..., 9.2671e-09, 1.0423e-09,\r\n",
      "         7.8144e-09],\r\n",
      "        [2.8485e-09, 6.5307e-09, 7.7427e-09,  ..., 7.7457e-09, 8.8015e-10,\r\n",
      "         7.2549e-09]])}, 5: {'step': 63, 'exp_avg': tensor([ 1.3098e-12, -1.5724e-12,  1.0840e-12,  7.7956e-13,  3.9281e-12,\r\n",
      "         7.9736e-13,  1.8055e-12, -5.7233e-13,  1.7404e-12,  8.5593e-13,\r\n",
      "         1.3771e-12,  1.4647e-12, -6.0979e-13, -2.8921e-12, -9.6978e-13,\r\n",
      "         1.1725e-12, -1.6028e-12, -4.2372e-12,  1.4676e-12,  4.0165e-13,\r\n",
      "        -3.6871e-13,  8.0122e-13, -3.6969e-12,  1.9631e-12, -1.4824e-12,\r\n",
      "        -3.2872e-12, -3.1370e-12, -4.8663e-13, -1.7392e-12,  9.9275e-13,\r\n",
      "        -8.9506e-13, -1.0849e-12,  3.9258e-12,  3.0509e-12,  2.4480e-14,\r\n",
      "        -1.0514e-12,  7.1539e-13,  2.1411e-12,  6.3982e-12, -1.9250e-12,\r\n",
      "        -3.8836e-12,  1.1380e-12, -1.3131e-12,  6.8674e-13, -5.5072e-12,\r\n",
      "         3.9400e-13,  9.7042e-13,  2.1735e-12, -4.5184e-12,  3.1049e-13,\r\n",
      "        -1.7614e-12, -1.3817e-13,  5.4233e-13, -5.3762e-14,  6.2981e-13,\r\n",
      "         3.5829e-13,  4.5568e-12, -8.8810e-13, -4.1666e-13, -1.2864e-13,\r\n",
      "         2.5665e-12, -1.3006e-12,  2.7265e-12, -2.4860e-12,  2.4373e-12,\r\n",
      "         5.3589e-12, -1.8359e-12,  3.7837e-13,  1.1208e-12,  5.2073e-12,\r\n",
      "        -2.6118e-12, -1.1433e-12,  7.2341e-13, -1.1578e-12, -2.7217e-13,\r\n",
      "        -4.4288e-13, -4.2996e-13,  2.7230e-12, -2.9332e-13, -5.3324e-12,\r\n",
      "         1.0404e-12,  5.9515e-12,  1.0715e-12,  1.7008e-12,  5.9626e-12,\r\n",
      "        -2.2304e-12, -4.7649e-12,  1.7489e-12, -3.5469e-12, -1.0380e-12,\r\n",
      "         5.7273e-13, -1.5945e-12, -4.6352e-13, -6.9308e-13, -1.2520e-13,\r\n",
      "        -4.9914e-13,  2.1412e-12,  3.0516e-12, -4.7677e-13, -1.3886e-12,\r\n",
      "        -1.3321e-13,  1.8943e-12, -2.0378e-12, -5.8453e-13, -5.7823e-12,\r\n",
      "        -8.9032e-13, -2.4171e-12, -1.1669e-12,  4.7783e-13,  6.9738e-13,\r\n",
      "         9.6404e-13, -1.2221e-12, -7.1546e-13,  1.4462e-12,  1.2178e-12,\r\n",
      "        -4.7183e-12,  3.7139e-13,  4.6385e-13, -7.4555e-13,  4.6897e-13,\r\n",
      "         2.5437e-12, -5.5936e-13, -1.2024e-12, -2.7940e-13,  1.1957e-12,\r\n",
      "         6.9159e-13,  3.9836e-12,  1.7797e-12]), 'exp_avg_sq': tensor([5.3314e-24, 4.7891e-24, 4.6689e-24, 1.4314e-23, 2.7342e-23, 1.7770e-23,\r\n",
      "        3.7537e-24, 2.7883e-24, 2.5172e-24, 5.4285e-24, 3.4296e-24, 4.2311e-24,\r\n",
      "        2.3008e-24, 9.6508e-24, 3.0264e-24, 2.5633e-24, 8.3740e-24, 1.3491e-23,\r\n",
      "        3.3024e-24, 3.4636e-24, 3.4150e-24, 3.0042e-24, 1.2567e-23, 2.0796e-24,\r\n",
      "        9.7317e-24, 4.9141e-24, 3.3504e-24, 3.2945e-24, 4.7774e-24, 2.7827e-24,\r\n",
      "        3.4658e-24, 7.0201e-24, 1.5433e-23, 2.7307e-23, 2.2280e-24, 6.7168e-24,\r\n",
      "        6.0305e-24, 6.3552e-24, 2.1271e-23, 9.5626e-24, 8.5441e-24, 1.8555e-24,\r\n",
      "        1.7723e-23, 3.5522e-24, 3.7439e-24, 4.8115e-24, 2.0601e-23, 5.4205e-24,\r\n",
      "        3.8053e-24, 5.9287e-24, 2.6935e-23, 8.2460e-24, 5.5368e-24, 1.4682e-24,\r\n",
      "        4.0451e-24, 5.2272e-24, 2.2958e-23, 2.4846e-24, 3.2382e-24, 2.0663e-24,\r\n",
      "        6.4285e-24, 2.4842e-24, 1.4042e-23, 3.2035e-24, 5.5054e-24, 4.6272e-24,\r\n",
      "        2.0583e-24, 3.6029e-24, 5.8919e-24, 1.8750e-23, 1.1332e-23, 4.2992e-24,\r\n",
      "        2.9465e-24, 3.2562e-23, 3.0412e-24, 3.3620e-24, 2.2293e-24, 1.4617e-23,\r\n",
      "        3.3868e-24, 1.5227e-23, 3.3190e-24, 3.5403e-23, 2.0757e-24, 6.6474e-24,\r\n",
      "        2.1118e-23, 1.2342e-23, 4.2870e-24, 4.2878e-24, 4.3515e-23, 7.7085e-24,\r\n",
      "        4.2512e-24, 2.9046e-24, 5.9440e-24, 5.8947e-24, 5.3168e-24, 5.1795e-24,\r\n",
      "        3.4119e-24, 3.4220e-24, 2.6956e-24, 2.4154e-24, 3.0194e-24, 6.9143e-24,\r\n",
      "        3.8357e-24, 1.2393e-23, 2.9306e-23, 5.8260e-24, 2.5655e-24, 3.7509e-24,\r\n",
      "        1.0690e-23, 1.6745e-23, 2.4446e-24, 1.3947e-23, 6.3106e-24, 1.6547e-24,\r\n",
      "        5.6416e-23, 2.2405e-23, 1.8923e-24, 3.6620e-24, 4.6038e-24, 1.1955e-23,\r\n",
      "        6.4336e-24, 3.3090e-24, 3.2281e-24, 3.9137e-24, 2.9980e-24, 4.1610e-24,\r\n",
      "        1.7823e-23, 1.6394e-23])}, 6: {'step': 63, 'exp_avg': tensor([[ 2.0323e-04,  5.6639e-04, -5.1372e-04,  ..., -5.1787e-04,\r\n",
      "          2.4321e-04,  1.0106e-04],\r\n",
      "        [-1.3477e-04, -3.9664e-04,  3.5744e-04,  ...,  3.5933e-04,\r\n",
      "         -1.6335e-04, -7.1483e-05],\r\n",
      "        [ 2.3460e-04,  6.5996e-04, -6.0919e-04,  ..., -6.0589e-04,\r\n",
      "          2.7758e-04,  1.1264e-04],\r\n",
      "        ...,\r\n",
      "        [-2.2438e-04, -6.4066e-04,  5.9052e-04,  ...,  5.8571e-04,\r\n",
      "         -2.6485e-04, -1.0865e-04],\r\n",
      "        [ 4.7828e-04,  1.3435e-03, -1.2629e-03,  ..., -1.2540e-03,\r\n",
      "          5.7369e-04,  2.2271e-04],\r\n",
      "        [ 3.9437e-04,  1.1010e-03, -1.0109e-03,  ..., -1.0083e-03,\r\n",
      "          4.5783e-04,  1.9510e-04]]), 'exp_avg_sq': tensor([[2.0015e-08, 1.3237e-07, 1.6415e-07,  ..., 1.3495e-07, 2.1631e-08,\r\n",
      "         3.1240e-09],\r\n",
      "        [8.3692e-09, 5.7335e-08, 7.0155e-08,  ..., 5.8264e-08, 9.1674e-09,\r\n",
      "         1.4515e-09],\r\n",
      "        [2.5414e-08, 1.6959e-07, 2.1139e-07,  ..., 1.7297e-07, 2.7257e-08,\r\n",
      "         3.6975e-09],\r\n",
      "        ...,\r\n",
      "        [2.4249e-08, 1.6092e-07, 2.0100e-07,  ..., 1.6465e-07, 2.6094e-08,\r\n",
      "         3.4595e-09],\r\n",
      "        [1.0967e-07, 7.2371e-07, 9.0955e-07,  ..., 7.4573e-07, 1.1880e-07,\r\n",
      "         1.5060e-08],\r\n",
      "        [6.9268e-08, 4.6594e-07, 5.7554e-07,  ..., 4.7239e-07, 7.5074e-08,\r\n",
      "         1.0717e-08]])}, 7: {'step': 63, 'exp_avg': tensor([-7.8443e-04,  5.7867e-04, -8.8393e-04, -5.8390e-04,  1.7657e-03,\r\n",
      "        -1.5854e-03, -1.6862e-03, -4.1184e-04, -1.2902e-03, -1.2582e-03,\r\n",
      "         1.4610e-03, -1.5714e-03, -2.1454e-03,  5.5212e-04, -1.1057e-04,\r\n",
      "        -5.6507e-04,  9.2949e-04,  1.0090e-04,  9.0179e-04,  1.4585e-04,\r\n",
      "         1.3166e-03, -2.5658e-03,  1.3527e-03,  9.4899e-04, -1.0745e-03,\r\n",
      "        -2.4453e-04,  1.1793e-03, -7.3232e-04,  3.9964e-04, -4.5516e-04,\r\n",
      "        -7.8698e-04,  2.2020e-04, -1.5958e-04, -4.6036e-04, -4.9538e-04,\r\n",
      "         1.8849e-03,  2.1467e-03,  3.9852e-05, -1.1689e-03, -8.3703e-04,\r\n",
      "         1.3074e-03,  1.6711e-03,  4.0489e-04, -1.7835e-04, -2.7258e-04,\r\n",
      "        -1.0890e-03, -6.6639e-04, -7.3969e-04,  1.6622e-03,  3.3209e-04,\r\n",
      "         1.5907e-04, -1.1776e-03,  3.4134e-04,  3.5809e-04, -9.4847e-05,\r\n",
      "         1.1003e-04,  2.4423e-03, -8.2527e-04,  5.2786e-04,  4.5947e-04,\r\n",
      "         8.2799e-04,  1.4610e-03, -5.3165e-04,  6.1425e-04,  2.6449e-04,\r\n",
      "         1.6232e-05,  2.4138e-04, -9.6301e-04,  5.9653e-04, -2.5424e-03,\r\n",
      "        -1.0299e-04,  1.9885e-04,  1.0641e-03, -7.4623e-04,  1.7621e-04,\r\n",
      "         1.7558e-04,  2.1532e-04, -2.9098e-03,  8.9649e-05, -5.7775e-04,\r\n",
      "        -3.3276e-04, -3.3393e-04,  1.1253e-03, -6.8129e-04,  6.1518e-04,\r\n",
      "        -1.2068e-03,  6.4153e-04,  1.4292e-04, -5.0637e-04,  5.8116e-05,\r\n",
      "         1.6572e-03, -1.9774e-04,  7.2392e-04,  1.5585e-04,  2.0901e-03,\r\n",
      "         6.7387e-04,  1.2633e-03, -2.6835e-04,  1.1066e-03, -7.5077e-04,\r\n",
      "        -2.0560e-03, -4.2154e-04,  9.5233e-04, -5.6202e-04,  1.8703e-03,\r\n",
      "        -2.7171e-04,  1.0773e-03,  1.3525e-03,  1.4967e-03,  6.3467e-04,\r\n",
      "        -4.1544e-04,  8.1352e-05,  4.1245e-04,  1.1625e-03,  2.8772e-03,\r\n",
      "         1.3038e-03,  1.8901e-04, -5.6108e-04, -1.6664e-03, -5.0786e-06,\r\n",
      "        -3.1035e-03, -1.2888e-03, -1.1838e-03,  5.3517e-04, -1.1721e-04,\r\n",
      "         8.7853e-04, -1.7958e-03, -1.5068e-03]), 'exp_avg_sq': tensor([2.5943e-07, 1.2875e-07, 3.0027e-07, 1.2508e-07, 1.2140e-06, 9.9282e-07,\r\n",
      "        1.0393e-06, 5.1969e-08, 6.7818e-07, 6.1825e-07, 9.2483e-07, 9.2102e-07,\r\n",
      "        1.8684e-06, 1.1107e-07, 1.2951e-08, 1.2488e-07, 3.3383e-07, 8.8870e-09,\r\n",
      "        3.0912e-07, 7.4343e-09, 6.3162e-07, 2.6860e-06, 7.9544e-07, 3.2247e-07,\r\n",
      "        4.6861e-07, 2.1589e-08, 5.1572e-07, 2.0824e-07, 9.3251e-08, 8.4411e-08,\r\n",
      "        2.3589e-07, 3.4302e-08, 1.1447e-08, 9.3477e-08, 1.0023e-07, 1.4531e-06,\r\n",
      "        1.9235e-06, 4.7062e-10, 5.8052e-07, 2.5428e-07, 7.0373e-07, 1.1023e-06,\r\n",
      "        5.9853e-08, 1.4311e-08, 4.3619e-08, 5.1482e-07, 1.7185e-07, 1.8762e-07,\r\n",
      "        1.0944e-06, 4.3958e-08, 7.0712e-09, 5.3770e-07, 5.3264e-08, 5.0156e-08,\r\n",
      "        5.3562e-09, 5.3512e-09, 2.3565e-06, 2.6610e-07, 1.1995e-07, 6.4579e-08,\r\n",
      "        2.8234e-07, 8.1465e-07, 1.0018e-07, 1.5402e-07, 3.3379e-08, 1.3074e-09,\r\n",
      "        2.5687e-08, 3.5785e-07, 1.4295e-07, 2.5920e-06, 7.3405e-09, 2.4786e-08,\r\n",
      "        4.7390e-07, 2.2327e-07, 1.1517e-08, 1.4386e-08, 2.0216e-08, 3.3833e-06,\r\n",
      "        2.7190e-09, 1.5956e-07, 5.1000e-08, 5.1453e-08, 5.1077e-07, 2.2091e-07,\r\n",
      "        1.9084e-07, 5.5679e-07, 1.8370e-07, 8.6066e-09, 1.2356e-07, 8.8647e-09,\r\n",
      "        1.0330e-06, 2.1651e-08, 2.4749e-07, 1.9296e-08, 1.6646e-06, 2.1758e-07,\r\n",
      "        6.3148e-07, 2.6323e-08, 4.7323e-07, 2.2007e-07, 1.6674e-06, 7.2259e-08,\r\n",
      "        4.1904e-07, 1.2000e-07, 1.3941e-06, 3.7969e-08, 4.6020e-07, 7.1171e-07,\r\n",
      "        9.2427e-07, 1.7931e-07, 7.3549e-08, 3.6938e-09, 6.7436e-08, 5.3183e-07,\r\n",
      "        3.2798e-06, 6.5518e-07, 1.6941e-08, 1.1349e-07, 1.0496e-06, 1.1819e-09,\r\n",
      "        3.8097e-06, 7.3065e-07, 6.2973e-07, 1.2057e-07, 1.3360e-08, 2.8870e-07,\r\n",
      "        1.2023e-06, 8.8881e-07])}, 8: {'step': 63, 'exp_avg': tensor([[ 1.0001e-04, -4.3279e-04, -1.0560e-03,  ..., -9.6511e-04,\r\n",
      "         -1.0646e-03,  4.9672e-05],\r\n",
      "        [-6.4262e-05,  3.4787e-04,  8.4073e-04,  ...,  7.7594e-04,\r\n",
      "          9.0318e-04, -2.3709e-05],\r\n",
      "        [ 4.1781e-05, -1.9095e-04, -4.6954e-04,  ..., -4.2739e-04,\r\n",
      "         -4.8473e-04,  2.1426e-05],\r\n",
      "        ...,\r\n",
      "        [-6.4748e-05,  2.9005e-04,  7.2028e-04,  ...,  6.5609e-04,\r\n",
      "          6.9693e-04, -3.2113e-05],\r\n",
      "        [ 2.9377e-05, -1.4715e-04, -3.5457e-04,  ..., -3.2127e-04,\r\n",
      "         -3.5546e-04,  1.8481e-05],\r\n",
      "        [-4.9801e-05,  2.0270e-04,  5.1371e-04,  ...,  4.6697e-04,\r\n",
      "          4.9116e-04, -2.5303e-05]]), 'exp_avg_sq': tensor([[1.0285e-08, 1.1184e-07, 4.5166e-07,  ..., 4.9823e-07, 8.7382e-07,\r\n",
      "         8.7383e-09],\r\n",
      "        [5.0387e-09, 7.3547e-08, 2.9995e-07,  ..., 3.2779e-07, 5.7475e-07,\r\n",
      "         4.7674e-09],\r\n",
      "        [1.8467e-09, 2.1500e-08, 8.7280e-08,  ..., 9.5641e-08, 1.6668e-07,\r\n",
      "         1.6615e-09],\r\n",
      "        ...,\r\n",
      "        [5.3289e-09, 4.8926e-08, 1.9913e-07,  ..., 2.2024e-07, 3.8521e-07,\r\n",
      "         4.4329e-09],\r\n",
      "        [1.2244e-09, 1.2581e-08, 4.9784e-08,  ..., 5.4946e-08, 9.7098e-08,\r\n",
      "         9.8339e-10],\r\n",
      "        [2.9657e-09, 2.3842e-08, 9.7555e-08,  ..., 1.0823e-07, 1.8979e-07,\r\n",
      "         2.4505e-09]])}, 9: {'step': 63, 'exp_avg': tensor([-3.1086e-03,  2.2666e-03, -1.3264e-03,  2.0498e-03, -2.2508e-03,\r\n",
      "         4.5328e-04, -1.6137e-03,  1.1766e-03,  1.2796e-03,  1.9308e-03,\r\n",
      "         7.5446e-04, -1.3899e-03,  5.1242e-04,  1.4844e-03, -3.0948e-03,\r\n",
      "         1.1012e-03, -2.2601e-03,  4.3203e-04, -2.9329e-04,  1.2526e-03,\r\n",
      "        -3.2478e-03, -2.0699e-03, -1.2283e-03,  4.7581e-03, -2.1468e-03,\r\n",
      "         3.3262e-04, -2.4200e-03,  2.0921e-03,  2.0108e-04, -2.9411e-03,\r\n",
      "         1.3385e-03,  2.8007e-03,  1.0362e-03, -2.1207e-03, -1.6729e-03,\r\n",
      "        -7.9147e-04,  1.3108e-03, -1.7812e-03,  3.0727e-04,  4.9017e-03,\r\n",
      "        -1.5489e-03, -2.3486e-03, -3.5961e-04, -1.0031e-03,  9.7305e-04,\r\n",
      "         8.2290e-04, -1.4869e-03,  1.6858e-04, -3.6002e-04, -2.0823e-03,\r\n",
      "        -3.3711e-03,  2.8614e-03,  4.6932e-04,  2.5550e-03,  3.3042e-03,\r\n",
      "        -1.4073e-03,  1.3482e-03,  9.1429e-04,  4.6717e-04,  1.1880e-03,\r\n",
      "         1.2575e-03,  2.2872e-03, -4.2447e-04, -2.8296e-03, -6.1282e-04,\r\n",
      "        -1.4244e-03, -1.6656e-03,  4.0005e-03,  3.8401e-03, -3.5106e-04,\r\n",
      "         1.8967e-04,  8.1697e-04, -2.0015e-03, -9.3658e-04, -9.1854e-04,\r\n",
      "        -1.1828e-03, -1.4706e-04, -3.7265e-03, -1.4469e-04,  6.3555e-04,\r\n",
      "        -6.5243e-04, -1.2331e-03, -4.3636e-03,  4.8812e-04,  2.3054e-03,\r\n",
      "        -1.5101e-04,  1.1321e-03,  8.6357e-04,  6.5064e-04,  2.1593e-03,\r\n",
      "         8.2658e-04, -2.3389e-03,  1.2589e-03,  2.4525e-04,  2.1271e-03,\r\n",
      "        -3.4133e-04, -1.0426e-03,  2.0007e-05,  1.6750e-03,  3.4810e-04,\r\n",
      "        -1.0824e-03, -4.6352e-03,  1.1530e-03, -2.5531e-04, -3.1330e-03,\r\n",
      "        -2.1576e-03,  3.0115e-03, -4.4202e-04,  7.1762e-04,  3.3646e-03,\r\n",
      "        -1.1180e-03, -2.6944e-03, -2.0510e-03,  1.1577e-03,  6.1659e-04,\r\n",
      "         8.7833e-04,  1.2412e-03, -4.8018e-04, -3.9521e-04,  1.8494e-03,\r\n",
      "         1.4623e-03, -1.0513e-03,  1.6027e-04, -1.6668e-03,  2.9814e-03,\r\n",
      "         2.2341e-03, -1.0020e-03,  1.5780e-03]), 'exp_avg_sq': tensor([3.9362e-06, 1.9959e-06, 7.1761e-07, 1.5232e-06, 1.8866e-06, 8.4290e-08,\r\n",
      "        1.1666e-06, 6.7409e-07, 5.7818e-07, 1.5458e-06, 2.1792e-07, 8.9467e-07,\r\n",
      "        1.1656e-07, 1.0306e-06, 4.0504e-06, 5.4026e-07, 1.9631e-06, 7.8595e-08,\r\n",
      "        2.6397e-08, 8.0322e-07, 4.2306e-06, 1.7790e-06, 5.4738e-07, 9.1918e-06,\r\n",
      "        2.0444e-06, 9.3076e-08, 2.2555e-06, 1.7648e-06, 2.2354e-08, 3.3696e-06,\r\n",
      "        6.4810e-07, 3.0813e-06, 4.7235e-07, 1.6096e-06, 1.0536e-06, 2.8653e-07,\r\n",
      "        6.8167e-07, 1.1681e-06, 4.0570e-08, 9.6459e-06, 1.1139e-06, 2.1772e-06,\r\n",
      "        4.4515e-08, 3.7693e-07, 3.4614e-07, 2.3380e-07, 8.5898e-07, 4.2656e-08,\r\n",
      "        4.4463e-08, 1.8217e-06, 4.2752e-06, 3.3016e-06, 8.3930e-08, 2.6962e-06,\r\n",
      "        4.3239e-06, 8.3206e-07, 7.2486e-07, 2.7514e-07, 8.8686e-08, 7.2547e-07,\r\n",
      "        6.3115e-07, 2.1756e-06, 6.6443e-08, 3.0332e-06, 1.8416e-07, 7.4490e-07,\r\n",
      "        1.0728e-06, 6.2179e-06, 6.1757e-06, 3.3508e-08, 1.4692e-08, 2.3043e-07,\r\n",
      "        1.6222e-06, 3.9139e-07, 2.8607e-07, 6.7479e-07, 1.5145e-08, 5.4996e-06,\r\n",
      "        2.3426e-08, 2.3894e-07, 2.4999e-07, 5.7890e-07, 8.0680e-06, 9.6458e-08,\r\n",
      "        2.0494e-06, 1.4405e-08, 4.4052e-07, 2.5700e-07, 2.1984e-07, 1.8124e-06,\r\n",
      "        2.5744e-07, 2.1156e-06, 5.8265e-07, 1.9211e-08, 1.7107e-06, 4.7069e-08,\r",
      "\r\n",
      "        4.3056e-07, 1.0530e-08, 9.9080e-07, 7.0599e-08, 4.1292e-07, 8.2469e-06,\r\n",
      "        5.3538e-07, 4.9860e-08, 3.8737e-06, 1.8438e-06, 3.8717e-06, 8.4805e-08,\r\n",
      "        1.9041e-07, 4.3791e-06, 5.0881e-07, 2.9003e-06, 1.6772e-06, 6.6152e-07,\r\n",
      "        1.3415e-07, 2.9670e-07, 6.0942e-07, 1.4134e-07, 1.0238e-07, 1.3888e-06,\r\n",
      "        8.4142e-07, 5.1124e-07, 9.1437e-09, 1.2044e-06, 3.4267e-06, 2.0302e-06,\r\n",
      "        4.2431e-07, 1.0984e-06])}, 10: {'step': 63, 'exp_avg': tensor([ 1.1997e-03, -1.7781e-03, -1.1249e-03, -1.2804e-03, -1.1209e-03,\r\n",
      "         8.8036e-05,  2.7911e-04,  6.1091e-04,  1.6286e-05,  1.2734e-03,\r\n",
      "         1.4613e-04,  2.5914e-04, -5.0560e-04, -2.2371e-04,  1.9789e-05,\r\n",
      "         3.4669e-04,  7.9185e-04, -4.1494e-05,  3.6808e-04,  2.8079e-04,\r\n",
      "         5.4822e-04,  1.0701e-03,  7.9905e-04, -1.0206e-03, -3.7702e-04,\r\n",
      "        -4.9446e-05, -1.2571e-03, -1.4596e-03, -8.4212e-05,  8.0230e-05,\r\n",
      "        -1.7751e-04,  6.1237e-04, -3.6628e-04, -2.8711e-04,  8.7083e-06,\r\n",
      "        -1.9658e-04,  1.7491e-04, -1.9619e-03, -4.2837e-04,  6.6302e-04,\r\n",
      "         5.7486e-04, -8.8040e-04,  1.6087e-04,  2.7312e-04, -6.6306e-05,\r\n",
      "        -1.1092e-03, -2.5806e-04, -2.3974e-04,  1.3819e-05, -2.4555e-04,\r\n",
      "        -5.8157e-05,  1.3309e-03, -3.4827e-04,  8.8335e-04, -3.7062e-04,\r\n",
      "         5.0205e-04, -1.1841e-04,  7.6492e-05, -3.2274e-04,  4.2266e-05,\r\n",
      "        -5.5500e-04,  1.2961e-03,  2.4598e-04, -2.9818e-03, -2.6590e-04,\r\n",
      "         1.0265e-03, -9.7137e-04,  7.9074e-04,  1.9361e-03, -3.4633e-04,\r\n",
      "        -3.2906e-04,  4.2731e-05,  1.5424e-03,  3.0403e-04, -3.7712e-04,\r\n",
      "        -5.9903e-04,  6.3426e-05,  1.4451e-03, -1.3678e-04, -1.9258e-04,\r\n",
      "         3.4924e-04,  4.4472e-04, -4.7194e-04, -1.8199e-04,  1.3042e-05,\r\n",
      "        -7.7222e-05, -4.9846e-04,  2.5699e-04,  1.6645e-04,  4.6648e-04,\r\n",
      "         3.7721e-04,  2.4745e-04, -4.1355e-05,  1.9797e-04, -8.5051e-04,\r\n",
      "         1.1594e-04, -3.7013e-04,  4.2986e-05, -5.8880e-04, -1.7694e-04,\r\n",
      "         6.0370e-04, -7.6127e-04, -2.2100e-05, -3.5215e-05, -1.1063e-03,\r\n",
      "        -7.4798e-04,  1.2149e-04, -1.7939e-04,  2.5737e-04,  1.9928e-03,\r\n",
      "         9.1854e-05,  9.6831e-04,  6.3934e-04,  1.1711e-04,  6.8039e-04,\r\n",
      "         2.9692e-04, -4.8085e-04,  5.5933e-05,  1.1697e-05, -7.9785e-04,\r\n",
      "         7.8787e-04, -5.6656e-04,  3.9885e-06, -1.0120e-03,  4.1932e-04,\r\n",
      "         1.6256e-03,  1.2281e-04, -1.6543e-04]), 'exp_avg_sq': tensor([6.9525e-07, 1.3345e-06, 5.9300e-07, 7.5960e-07, 5.2329e-07, 4.7270e-09,\r\n",
      "        2.5368e-08, 1.5546e-07, 8.4596e-08, 7.1861e-07, 6.0503e-09, 9.8007e-08,\r\n",
      "        1.0230e-07, 3.5269e-08, 5.2067e-08, 8.8280e-08, 3.1318e-07, 2.0966e-09,\r\n",
      "        2.9515e-08, 1.0852e-07, 1.3866e-07, 9.0833e-07, 2.6302e-07, 6.4813e-07,\r\n",
      "        6.4502e-08, 2.8196e-09, 7.2347e-07, 9.9854e-07, 2.2296e-09, 3.3693e-08,\r\n",
      "        2.2622e-08, 1.8044e-07, 4.2246e-08, 6.2717e-08, 2.6770e-08, 2.1914e-08,\r\n",
      "        2.1833e-08, 2.2231e-06, 6.2997e-08, 1.8041e-07, 1.1712e-07, 7.2799e-07,\r\n",
      "        1.1241e-08, 1.0095e-07, 5.1731e-09, 5.1129e-07, 5.8722e-08, 2.2867e-08,\r\n",
      "        3.3322e-09, 8.0282e-08, 1.3415e-07, 1.4416e-06, 3.6466e-08, 2.5730e-07,\r\n",
      "        6.8807e-08, 6.8053e-08, 1.7718e-08, 2.7905e-09, 5.0999e-08, 2.1150e-08,\r\n",
      "        1.2484e-07, 1.0530e-06, 1.8956e-08, 5.3540e-06, 2.0594e-08, 4.2799e-07,\r\n",
      "        4.0796e-07, 4.4446e-07, 2.8471e-06, 4.5058e-08, 3.7669e-08, 1.6720e-08,\r\n",
      "        1.2663e-06, 8.9753e-08, 4.8574e-08, 1.5548e-07, 4.5478e-09, 7.0476e-07,\r\n",
      "        1.1215e-08, 1.3324e-08, 5.0203e-08, 1.1330e-07, 1.8748e-07, 5.7660e-09,\r\n",
      "        5.2659e-08, 2.5318e-09, 6.5778e-08, 6.4278e-08, 9.0093e-09, 7.6975e-08,\r\n",
      "        4.4276e-08, 7.3930e-08, 1.8756e-08, 2.9581e-08, 4.1279e-07, 1.1385e-08,\r\n",
      "        5.1122e-08, 7.0949e-09, 1.7344e-07, 1.1992e-08, 1.5743e-07, 9.5117e-07,\r\n",
      "        1.6931e-08, 3.2807e-09, 4.4646e-07, 2.5268e-07, 6.3178e-08, 1.3129e-08,\r\n",
      "        2.3107e-08, 1.0941e-06, 4.9459e-08, 2.0340e-07, 1.8971e-07, 2.7512e-08,\r\n",
      "        2.1407e-07, 6.1454e-08, 1.4631e-07, 9.9837e-09, 7.1819e-09, 5.5756e-07,\r\n",
      "        3.5279e-07, 1.1579e-07, 2.6592e-09, 3.5648e-07, 6.8727e-08, 1.3997e-06,\r\n",
      "        2.3730e-08, 2.1194e-08])}, 11: {'step': 63, 'exp_avg': tensor([-4.4616e-03,  3.2289e-03, -1.9147e-03,  2.9144e-03, -3.2414e-03,\r\n",
      "         6.2743e-04, -2.3228e-03,  1.6578e-03,  1.8220e-03,  2.7431e-03,\r\n",
      "         1.0628e-03, -1.9990e-03,  7.1668e-04,  2.1006e-03, -4.4429e-03,\r\n",
      "         1.5510e-03, -3.2625e-03,  6.0069e-04, -4.3764e-04,  1.7688e-03,\r\n",
      "        -4.6674e-03, -2.9773e-03, -1.7793e-03,  6.7813e-03, -3.0829e-03,\r\n",
      "         4.5961e-04, -3.4851e-03,  2.9722e-03,  2.6583e-04, -4.2315e-03,\r\n",
      "         1.8972e-03,  3.9871e-03,  1.4672e-03, -3.0530e-03, -2.4112e-03,\r\n",
      "        -1.1515e-03,  1.8503e-03, -2.5714e-03,  4.2940e-04,  6.9884e-03,\r\n",
      "        -2.2283e-03, -3.3811e-03, -5.3199e-04, -1.4590e-03,  1.3718e-03,\r\n",
      "         1.1656e-03, -2.1506e-03,  2.1374e-04, -5.3703e-04, -2.9945e-03,\r\n",
      "        -4.8464e-03,  4.0749e-03,  6.5238e-04,  3.6372e-03,  4.7002e-03,\r\n",
      "        -2.0258e-03,  1.9063e-03,  1.2881e-03,  6.5876e-04,  1.6710e-03,\r\n",
      "         1.7869e-03,  3.2458e-03, -6.2726e-04, -4.0737e-03, -8.9099e-04,\r\n",
      "        -2.0625e-03, -2.3996e-03,  5.7085e-03,  5.4694e-03, -5.1998e-04,\r\n",
      "         2.5129e-04,  1.1482e-03, -2.8886e-03, -1.3575e-03, -1.3380e-03,\r\n",
      "        -1.7089e-03, -2.2893e-04, -5.3546e-03, -2.2676e-04,  8.8343e-04,\r\n",
      "        -9.4826e-04, -1.7876e-03, -6.2493e-03,  6.8204e-04,  3.2782e-03,\r\n",
      "        -2.4263e-04,  1.6048e-03,  1.2183e-03,  9.1215e-04,  3.0685e-03,\r\n",
      "         1.1696e-03, -3.3600e-03,  1.7906e-03,  3.2905e-04,  3.0237e-03,\r\n",
      "        -5.0715e-04, -1.5066e-03,  3.4759e-06,  2.3857e-03,  4.7460e-04,\r\n",
      "        -1.5737e-03, -6.6500e-03,  1.6258e-03, -3.7130e-04, -4.4923e-03,\r\n",
      "        -3.1050e-03,  4.2825e-03, -6.6298e-04,  1.0076e-03,  4.7960e-03,\r\n",
      "        -1.6168e-03, -3.8724e-03, -2.9569e-03,  1.6318e-03,  8.6082e-04,\r\n",
      "         1.2461e-03,  1.7620e-03, -7.0346e-04, -5.8327e-04,  2.6302e-03,\r\n",
      "         2.0690e-03, -1.5250e-03,  2.0973e-04, -2.3976e-03,  4.2470e-03,\r\n",
      "         3.1688e-03, -1.4542e-03,  2.2334e-03]), 'exp_avg_sq': tensor([7.9845e-06, 3.9899e-06, 1.4751e-06, 3.0455e-06, 3.8614e-06, 1.5952e-07,\r\n",
      "        2.3755e-06, 1.3129e-06, 1.1538e-06, 3.0653e-06, 4.2383e-07, 1.8165e-06,\r\n",
      "        2.2423e-07, 2.0235e-06, 8.1953e-06, 1.0542e-06, 4.0443e-06, 1.4833e-07,\r\n",
      "        5.9769e-08, 1.5678e-06, 8.5799e-06, 3.6193e-06, 1.1307e-06, 1.8355e-05,\r\n",
      "        4.1374e-06, 1.7442e-07, 4.6150e-06, 3.5107e-06, 3.9567e-08, 6.8760e-06,\r\n",
      "        1.2850e-06, 6.1458e-06, 9.2726e-07, 3.2981e-06, 2.1660e-06, 5.9370e-07,\r\n",
      "        1.3348e-06, 2.4123e-06, 8.0062e-08, 1.9285e-05, 2.2632e-06, 4.4362e-06,\r\n",
      "        9.7491e-08, 7.8170e-07, 6.7998e-07, 4.7004e-07, 1.7740e-06, 7.9359e-08,\r\n",
      "        9.8941e-08, 3.7063e-06, 8.7171e-06, 6.5798e-06, 1.5874e-07, 5.3598e-06,\r\n",
      "        8.6060e-06, 1.6997e-06, 1.4264e-06, 5.3873e-07, 1.7229e-07, 1.4118e-06,\r\n",
      "        1.2425e-06, 4.3143e-06, 1.4279e-07, 6.1974e-06, 3.8050e-07, 1.5431e-06,\r\n",
      "        2.1971e-06, 1.2445e-05, 1.2307e-05, 7.4503e-08, 2.6092e-08, 4.5101e-07,\r\n",
      "        3.3149e-06, 8.0530e-07, 6.0288e-07, 1.3739e-06, 3.4738e-08, 1.1170e-05,\r\n",
      "        5.0891e-08, 4.5549e-07, 5.1325e-07, 1.2008e-06, 1.6289e-05, 1.8438e-07,\r\n",
      "        4.0979e-06, 3.3793e-08, 8.7993e-07, 5.1123e-07, 4.2390e-07, 3.6126e-06,\r\n",
      "        5.0901e-07, 4.3097e-06, 1.1645e-06, 3.4604e-08, 3.4118e-06, 1.0252e-07,\r\n",
      "        8.9418e-07, 1.9330e-08, 1.9780e-06, 1.3112e-07, 8.7008e-07, 1.6732e-05,\r\n",
      "        1.0477e-06, 1.0496e-07, 7.8616e-06, 3.7563e-06, 7.6959e-06, 1.8686e-07,\r\n",
      "        3.6929e-07, 8.7531e-06, 1.0491e-06, 5.8946e-06, 3.4216e-06, 1.2932e-06,\r\n",
      "        2.6143e-07, 5.8425e-07, 1.2086e-06, 2.9110e-07, 2.1556e-07, 2.7552e-06,\r\n",
      "        1.6538e-06, 1.0540e-06, 1.6054e-08, 2.4488e-06, 6.8476e-06, 4.0168e-06,\r\n",
      "        8.8010e-07, 2.1588e-06])}, 12: {'step': 63, 'exp_avg': tensor([ 2.3209e-03, -2.5689e-03, -1.0668e-03, -1.2623e-03, -8.5254e-04,\r\n",
      "        -4.3434e-04,  3.1759e-04,  2.9915e-03,  8.5176e-04,  1.9128e-03,\r\n",
      "         4.9692e-04,  1.3023e-03,  7.6314e-05,  3.1040e-04,  7.0880e-04,\r\n",
      "         2.9657e-04, -3.7787e-04,  3.2449e-04, -3.1974e-04,  2.8616e-04,\r\n",
      "         9.0305e-04,  1.4664e-03,  8.3840e-04, -7.1512e-04, -2.1233e-03,\r\n",
      "         2.7351e-09, -1.8715e-03, -7.4092e-04, -3.9586e-04,  4.6175e-04,\r\n",
      "         5.5715e-04,  2.6788e-03, -4.4405e-04,  3.2923e-04,  9.9102e-05,\r\n",
      "        -1.2077e-03, -1.8662e-04, -1.9086e-03,  1.7683e-05,  2.5423e-03,\r\n",
      "         1.5212e-04,  5.4140e-04,  2.9790e-05, -4.1640e-04, -4.6386e-04,\r\n",
      "        -5.5837e-04,  1.1861e-03,  8.9110e-04,  7.1944e-04,  5.5214e-04,\r\n",
      "        -1.4492e-03,  1.7106e-03,  1.1460e-04,  4.0283e-04,  1.3337e-03,\r\n",
      "        -2.4814e-04, -7.5698e-04,  5.4455e-05,  1.2810e-04,  1.6533e-06,\r\n",
      "        -3.6334e-04,  8.0915e-04, -6.7363e-05, -3.2171e-03,  3.7284e-04,\r\n",
      "         2.2695e-03, -8.1181e-04,  4.8347e-04, -1.6780e-03, -2.2838e-04,\r\n",
      "        -1.9818e-04, -3.2392e-05,  2.1307e-03,  1.4166e-03,  4.2192e-05,\r\n",
      "        -1.0401e-03, -4.1870e-04,  3.2289e-04, -2.5320e-04,  7.8449e-04,\r\n",
      "         1.2468e-04,  2.0602e-04, -2.5633e-04,  5.1085e-04, -2.4360e-04,\r\n",
      "         6.9612e-04, -1.6355e-04, -4.8207e-04,  4.0215e-06, -1.2629e-05,\r\n",
      "        -7.7572e-05, -1.0581e-03, -6.4680e-04, -1.1516e-04, -2.4636e-03,\r\n",
      "         1.5960e-05, -5.6366e-04, -4.4019e-04, -3.4407e-04, -2.1026e-04,\r\n",
      "         4.8287e-04, -2.6599e-03, -9.3051e-05,  2.9331e-04,  6.0996e-05,\r\n",
      "         2.1974e-04,  2.5811e-03, -1.2718e-04,  1.9874e-04,  1.6458e-05,\r\n",
      "         5.6449e-04,  1.5501e-03,  3.4923e-04,  9.0783e-04, -1.2355e-04,\r\n",
      "        -3.9350e-04, -8.1425e-04,  6.6488e-04, -5.9033e-05, -1.2068e-03,\r\n",
      "         6.1706e-04, -9.8645e-04,  7.0780e-04, -4.8603e-04,  1.8257e-04,\r\n",
      "         2.6274e-03,  4.1781e-04,  1.5521e-05]), 'exp_avg_sq': tensor([1.7058e-06, 2.5015e-06, 6.0165e-07, 6.5542e-07, 3.2378e-07, 1.3777e-07,\r\n",
      "        3.6362e-08, 3.2511e-06, 2.4392e-07, 1.1202e-06, 7.8505e-08, 8.4322e-07,\r\n",
      "        2.4270e-09, 4.4493e-08, 4.1394e-07, 4.1551e-08, 6.2059e-08, 4.7971e-08,\r\n",
      "        3.4896e-08, 2.5813e-07, 6.2056e-07, 1.5980e-06, 2.5729e-07, 2.8005e-07,\r\n",
      "        1.5402e-06, 3.0617e-11, 1.5502e-06, 2.8094e-07, 5.1022e-08, 9.4414e-08,\r\n",
      "        1.9578e-07, 2.2415e-06, 8.7225e-08, 9.1015e-08, 6.2250e-09, 5.0342e-07,\r\n",
      "        1.6398e-08, 1.9051e-06, 1.7550e-10, 2.6027e-06, 9.4104e-08, 2.8039e-07,\r\n",
      "        5.4358e-09, 2.6049e-07, 7.6217e-08, 1.1659e-07, 5.3911e-07, 3.3304e-07,\r\n",
      "        2.4171e-07, 4.8457e-07, 8.4577e-07, 1.2204e-06, 5.1699e-09, 8.9729e-08,\r\n",
      "        1.3243e-06, 2.1871e-07, 2.8825e-07, 9.6000e-10, 7.8667e-09, 2.3702e-12,\r\n",
      "        4.3657e-08, 9.0750e-07, 1.8061e-08, 3.8541e-06, 1.2297e-07, 1.7401e-06,\r\n",
      "        2.1130e-07, 1.1702e-06, 2.4329e-06, 3.6653e-08, 2.0042e-08, 9.6486e-10,\r\n",
      "        1.8804e-06, 8.7635e-07, 1.0076e-08, 3.8955e-07, 1.2376e-07, 3.0757e-07,\r\n",
      "        2.1220e-08, 7.4496e-07, 6.1877e-09, 4.7597e-08, 3.8269e-07, 1.4825e-07,\r\n",
      "        1.0821e-07, 2.6104e-07, 2.4677e-08, 1.5084e-07, 4.0538e-09, 1.6125e-08,\r\n",
      "        1.8245e-09, 9.2700e-07, 1.7283e-07, 1.1595e-08, 1.9641e-06, 3.8557e-10,\r\n",
      "        1.0933e-07, 1.0326e-07, 4.8382e-08, 1.8546e-08, 5.8894e-08, 2.6611e-06,\r\n",
      "        1.0285e-08, 5.4994e-08, 1.0545e-06, 4.7234e-08, 2.5411e-06, 5.4721e-09,\r\n",
      "        1.5643e-08, 9.5970e-08, 1.5098e-07, 1.0381e-06, 1.1178e-07, 3.7033e-07,\r\n",
      "        8.3564e-09, 5.4693e-08, 2.6587e-07, 3.4189e-07, 1.5552e-08, 9.5759e-07,\r\n",
      "        3.4362e-07, 3.3971e-07, 1.9604e-07, 7.2231e-08, 2.4555e-08, 2.4820e-06,\r\n",
      "        5.8733e-08, 9.4647e-10])}, 13: {'step': 63, 'exp_avg': tensor([-3.3585e-03,  5.1285e-03, -1.7866e-03,  1.5354e-03, -3.4596e-03,\r\n",
      "         2.1683e-03, -2.5161e-03,  2.8570e-03,  2.6326e-03,  3.6102e-03,\r\n",
      "         1.3764e-03, -3.3327e-03, -1.5088e-04,  2.2056e-03, -5.3744e-03,\r\n",
      "         4.9248e-04, -5.1423e-03,  2.0385e-03,  7.5874e-04,  2.0499e-03,\r\n",
      "        -4.8855e-03, -3.2499e-03, -1.8683e-03,  7.0879e-03, -4.1085e-03,\r\n",
      "         1.4637e-04, -3.4488e-03,  2.9317e-03, -1.2439e-03, -2.8554e-03,\r\n",
      "         2.9712e-03,  3.6317e-03,  2.0151e-03, -1.9359e-03, -7.3563e-04,\r\n",
      "        -5.5944e-03,  3.8034e-03, -2.9419e-03, -4.8856e-05,  5.9047e-03,\r\n",
      "        -3.2766e-03, -3.0127e-03, -2.0724e-03, -3.2193e-03,  1.0380e-03,\r\n",
      "         1.2305e-03, -2.3578e-03,  1.0126e-03, -2.7752e-03, -4.7430e-03,\r\n",
      "        -4.2015e-03,  3.1652e-03, -5.9820e-04,  5.6489e-03,  4.5623e-03,\r\n",
      "        -2.9351e-03,  2.8637e-03,  6.6431e-04, -5.0593e-04,  8.1174e-06,\r\n",
      "         5.5848e-04,  5.1708e-03, -7.1486e-04, -3.7525e-03, -1.1803e-03,\r\n",
      "        -3.2969e-03, -1.2012e-03,  4.9770e-03,  5.9363e-03, -9.1370e-04,\r\n",
      "         5.1066e-04, -1.9348e-04, -3.3165e-03, -2.3465e-03, -7.1737e-04,\r\n",
      "        -1.6695e-03,  1.7955e-03, -5.3966e-03,  2.6334e-04,  2.5723e-03,\r\n",
      "        -2.1622e-04, -2.1922e-03, -5.5530e-03,  1.5476e-03,  2.5406e-03,\r\n",
      "        -2.7167e-03,  2.5925e-03,  1.0585e-03,  4.8757e-04,  3.5652e-03,\r\n",
      "        -2.7190e-04, -3.8125e-03,  1.3509e-03, -5.3606e-04,  2.7183e-03,\r\n",
      "         1.9299e-04, -1.3716e-03,  9.5051e-04,  1.2546e-03,  8.3279e-04,\r\n",
      "        -2.7133e-03, -5.3473e-03,  1.6001e-03,  6.4831e-04, -6.1546e-03,\r\n",
      "        -3.7678e-03,  5.3935e-03,  2.7288e-04,  4.5390e-04,  5.3046e-03,\r\n",
      "        -2.8164e-03, -4.9300e-03, -1.9360e-03,  2.3432e-03, -2.6113e-04,\r\n",
      "        -6.3195e-04,  2.6237e-03, -1.8391e-03, -5.2144e-04,  4.3701e-03,\r\n",
      "         2.4482e-03, -1.2147e-03, -2.3368e-03, -1.3239e-03,  4.2882e-03,\r\n",
      "         5.1296e-03, -1.9528e-03,  1.0272e-03]), 'exp_avg_sq': tensor([4.4013e-06, 1.0255e-05, 1.2438e-06, 9.1842e-07, 4.6659e-06, 1.8330e-06,\r\n",
      "        2.4697e-06, 3.1854e-06, 2.7043e-06, 5.0857e-06, 7.3976e-07, 4.3339e-06,\r\n",
      "        8.9692e-09, 1.8982e-06, 1.1269e-05, 9.4866e-08, 1.0310e-05, 1.6220e-06,\r\n",
      "        2.2401e-07, 1.6395e-06, 9.3121e-06, 4.1212e-06, 1.3626e-06, 1.9589e-05,\r\n",
      "        6.5804e-06, 8.3463e-09, 4.6366e-06, 3.3500e-06, 6.0267e-07, 3.1818e-06,\r\n",
      "        3.4444e-06, 5.1465e-06, 1.5826e-06, 1.4622e-06, 2.1152e-07, 1.2203e-05,\r\n",
      "        5.6404e-06, 3.3736e-06, 9.6074e-10, 1.3601e-05, 4.1884e-06, 3.5408e-06,\r\n",
      "        1.6756e-06, 4.0414e-06, 4.1955e-07, 5.8977e-07, 2.1695e-06, 4.0062e-07,\r\n",
      "        3.0057e-06, 8.7749e-06, 6.8819e-06, 3.9094e-06, 1.3990e-07, 1.2446e-05,\r\n",
      "        8.1196e-06, 3.3592e-06, 3.1972e-06, 1.7247e-07, 1.0015e-07, 3.1024e-11,\r\n",
      "        1.2129e-07, 1.0431e-05, 1.9934e-07, 5.4894e-06, 5.4379e-07, 4.2415e-06,\r\n",
      "        5.6193e-07, 9.6623e-06, 1.3743e-05, 3.2513e-07, 1.0139e-07, 1.4495e-08,\r\n",
      "        4.2922e-06, 2.1490e-06, 2.0083e-07, 1.0859e-06, 1.2563e-06, 1.1359e-05,\r\n",
      "        2.6872e-08, 2.5814e-06, 1.8369e-08, 1.8754e-06, 1.2025e-05, 9.3491e-07,\r\n",
      "        2.5168e-06, 2.8797e-06, 2.6206e-06, 4.3658e-07, 9.2634e-08, 4.9566e-06,\r\n",
      "        2.8654e-08, 5.6678e-06, 7.1095e-07, 1.1176e-07, 2.8801e-06, 1.4568e-08,\r\n",
      "        7.3302e-07, 3.5197e-07, 6.1325e-07, 2.7001e-07, 2.8728e-06, 1.1148e-05,\r\n",
      "        9.9775e-07, 1.6420e-07, 1.4774e-05, 5.5368e-06, 1.1349e-05, 2.8865e-08,\r\n",
      "        8.0657e-08, 1.0974e-05, 3.0957e-06, 9.4823e-06, 1.4626e-06, 2.1429e-06,\r\n",
      "        2.6437e-08, 1.5535e-07, 2.6833e-06, 1.3201e-06, 1.0602e-07, 7.4459e-06,\r\n",
      "        2.3387e-06, 5.7464e-07, 2.1311e-06, 6.8290e-07, 7.1744e-06, 1.0266e-05,\r\n",
      "        1.4885e-06, 4.1152e-07])}, 14: {'step': 63, 'exp_avg': tensor([[-6.0751e-05, -1.1138e-04,  2.8427e-05,  ..., -1.4078e-05,\r\n",
      "         -9.0347e-06, -7.6244e-05],\r\n",
      "        [ 1.9793e-04,  3.6353e-04, -4.0309e-04,  ..., -4.2020e-04,\r\n",
      "          1.2279e-04,  8.0040e-06],\r\n",
      "        [ 1.1079e-04,  2.1277e-04, -1.9487e-04,  ..., -1.6995e-04,\r\n",
      "          4.2343e-05,  2.8789e-05],\r\n",
      "        ...,\r\n",
      "        [-2.8204e-05, -6.1132e-05,  6.5896e-05,  ...,  6.0870e-05,\r\n",
      "         -1.6783e-05, -1.5879e-05],\r\n",
      "        [-6.8749e-04, -1.3113e-03,  1.3965e-03,  ...,  1.4761e-03,\r\n",
      "         -5.0792e-04, -2.4359e-04],\r\n",
      "        [-3.3586e-04, -6.5158e-04,  6.6059e-04,  ...,  8.0162e-04,\r\n",
      "         -2.7243e-04, -1.7335e-04]]), 'exp_avg_sq': tensor([[3.5355e-09, 6.8263e-09, 9.5683e-10,  ..., 2.0535e-09, 1.1480e-09,\r\n",
      "         3.0603e-09],\r\n",
      "        [2.0045e-08, 5.1129e-08, 6.7817e-08,  ..., 8.1848e-08, 4.4067e-09,\r\n",
      "         3.8583e-09],\r\n",
      "        [4.7236e-09, 1.6781e-08, 1.5208e-08,  ..., 2.3324e-08, 1.3445e-09,\r\n",
      "         8.5240e-10],\r\n",
      "        ...,\r\n",
      "        [3.3532e-10, 1.2426e-09, 1.5056e-09,  ..., 1.7683e-09, 1.3555e-10,\r\n",
      "         9.6754e-11],\r\n",
      "        [2.5803e-07, 7.3252e-07, 1.0050e-06,  ..., 1.2622e-06, 9.5195e-08,\r\n",
      "         3.3498e-08],\r\n",
      "        [5.6591e-08, 1.8200e-07, 2.4207e-07,  ..., 3.1469e-07, 2.2057e-08,\r\n",
      "         9.1237e-09]])}, 15: {'step': 63, 'exp_avg': tensor([ 3.4356e-04, -5.6625e-04, -3.2086e-04, -2.8337e-03, -8.8174e-04,\r\n",
      "         2.6063e-04, -1.8614e-03, -7.6014e-04, -1.1995e-04,  5.2848e-04,\r\n",
      "         6.4585e-04, -2.3904e-05,  4.2128e-04,  8.2930e-04,  8.6877e-04,\r\n",
      "        -3.3367e-04,  6.3219e-04, -2.5652e-04, -5.6071e-04,  6.4128e-04,\r\n",
      "        -3.3617e-04,  5.7022e-04, -3.2378e-04,  1.5973e-03, -1.1219e-03,\r\n",
      "         3.7859e-04, -1.0134e-03, -8.5996e-04,  1.3808e-05, -2.0225e-04,\r\n",
      "         2.9838e-04,  1.1032e-03, -4.1868e-04,  4.8232e-04, -8.8589e-05,\r\n",
      "         2.8653e-04,  1.0626e-03, -1.3641e-03, -7.3294e-04,  5.7822e-04,\r\n",
      "         4.9974e-04, -9.6185e-05,  3.7685e-04,  4.0608e-04,  7.2547e-04,\r\n",
      "        -2.4365e-04,  1.6464e-03,  9.9293e-04, -3.5418e-04,  2.6686e-04,\r\n",
      "        -7.2328e-04,  1.2360e-03,  2.4985e-04,  1.1344e-03, -7.0942e-05,\r\n",
      "        -1.2352e-03,  5.8457e-04,  4.4507e-05, -4.2528e-04,  2.5604e-04,\r\n",
      "        -2.0914e-04, -8.2148e-04,  1.7797e-05, -8.9372e-05,  4.4584e-04,\r\n",
      "        -7.3473e-05, -6.1526e-04, -7.1963e-04, -1.9516e-05,  6.9230e-04,\r\n",
      "         1.0527e-03,  5.0985e-04,  1.7280e-03,  4.9546e-04,  7.8662e-04,\r\n",
      "         1.2393e-03,  1.6591e-03, -1.3099e-03,  3.2917e-04,  2.5763e-04,\r\n",
      "         7.1411e-04,  6.8225e-04,  2.1612e-04, -2.2156e-04,  1.1441e-03,\r\n",
      "        -2.9519e-04,  2.8637e-04, -5.3060e-04,  5.2359e-04, -1.1555e-03,\r\n",
      "         1.3898e-03, -9.4090e-06, -1.8897e-04, -9.0596e-04,  9.3965e-04,\r\n",
      "        -9.1469e-04,  3.0850e-04,  8.9553e-04,  1.7900e-04,  6.0320e-04,\r\n",
      "        -3.9338e-04,  1.1932e-04,  2.7478e-04, -2.2780e-04,  1.0923e-04,\r\n",
      "        -6.4812e-04, -7.5551e-04,  1.5681e-04,  7.4314e-04,  1.3541e-03,\r\n",
      "        -1.0931e-04,  1.9980e-04, -3.3637e-04, -1.6091e-03,  2.4348e-04,\r\n",
      "        -4.0155e-04,  5.3981e-05, -1.3413e-05,  4.9435e-04,  2.0593e-04,\r\n",
      "         9.1391e-05,  9.0714e-04, -5.9383e-04, -3.9456e-04,  4.3132e-04,\r\n",
      "        -7.6801e-04,  1.7367e-03,  1.1331e-03, -1.4891e-04, -8.6696e-04,\r\n",
      "        -6.3805e-04,  2.2636e-03, -3.5637e-04,  9.1877e-04, -1.6857e-04,\r\n",
      "         1.1317e-03,  9.9820e-04,  1.2768e-03,  1.3779e-03,  1.2960e-03,\r\n",
      "        -1.3618e-04, -9.0036e-04, -2.9949e-04,  1.6354e-03, -2.0992e-04,\r\n",
      "        -8.3284e-05,  4.3452e-04, -1.1504e-03,  6.8054e-04,  6.5335e-05,\r\n",
      "        -3.4209e-04, -7.9797e-04, -6.5534e-05,  1.6483e-04, -2.5869e-04,\r\n",
      "         9.9340e-05, -2.0040e-04,  8.0799e-04,  7.3866e-04, -7.3436e-05,\r\n",
      "         9.2035e-04, -6.7888e-04, -5.0148e-04, -3.6135e-04, -2.9107e-04,\r\n",
      "         1.0673e-03, -1.4379e-03, -1.5198e-04, -4.2669e-04, -1.4998e-03,\r\n",
      "        -2.1734e-03,  1.0500e-03, -9.6236e-04,  1.3109e-03, -3.0960e-04,\r\n",
      "         3.3825e-04, -8.1176e-04, -1.9520e-04,  6.3550e-05, -1.5988e-04,\r\n",
      "        -1.4922e-04,  9.3584e-04, -4.4921e-05,  4.4877e-04,  5.1717e-06,\r\n",
      "        -1.8092e-03, -3.5686e-04,  6.3719e-04,  5.5122e-04, -1.1187e-03,\r\n",
      "        -1.7133e-04, -8.6470e-04, -7.6266e-04, -1.0428e-03,  7.0805e-04,\r\n",
      "        -9.8016e-04, -1.4175e-03,  7.9022e-05,  4.3701e-04,  6.4754e-04,\r\n",
      "        -4.2709e-04,  2.5545e-04,  2.7869e-04,  7.3660e-04, -2.0591e-05,\r\n",
      "        -1.9438e-03,  7.5715e-04,  1.5378e-03, -6.1502e-04, -4.3645e-04,\r\n",
      "        -4.3811e-04,  6.1962e-04,  1.0371e-03, -2.7755e-04, -7.0805e-06,\r\n",
      "        -7.6561e-04, -1.0745e-03,  6.1418e-04, -2.6341e-04,  1.1381e-03,\r\n",
      "         9.4200e-04,  4.0781e-04,  1.0535e-03,  1.4289e-03, -2.1644e-04,\r\n",
      "        -2.3742e-04,  3.6684e-04, -9.7409e-04,  2.5764e-04,  5.3161e-04,\r\n",
      "         1.0697e-03, -5.7119e-04,  3.3841e-05,  2.8822e-04,  1.1756e-03,\r\n",
      "        -6.3574e-04, -2.7768e-05,  1.4081e-04, -5.7014e-04,  4.0986e-04,\r\n",
      "         1.6314e-03,  1.1646e-06,  8.5491e-04,  3.2847e-04,  1.0767e-03,\r\n",
      "         1.7958e-06,  4.1881e-04, -7.9394e-04, -9.3937e-04, -1.1989e-03,\r\n",
      "        -5.7778e-04, -4.4367e-04, -3.6321e-04,  1.6095e-04,  1.2511e-03,\r\n",
      "         1.0658e-03, -8.6210e-04,  1.3688e-03,  9.7915e-04,  4.1571e-04,\r\n",
      "         2.6867e-06, -5.8535e-04, -2.1106e-04,  4.6423e-04,  7.1898e-04,\r\n",
      "         6.6903e-04,  2.9977e-04,  9.4526e-04, -3.2357e-04,  8.5386e-04,\r\n",
      "        -1.4834e-03, -6.9777e-04, -7.5126e-04, -1.4789e-03,  5.8211e-04,\r\n",
      "         5.7544e-04, -1.1020e-03,  2.6116e-04, -2.1809e-04,  1.3353e-03,\r\n",
      "         7.5680e-04,  1.4113e-04,  8.4225e-05,  1.4838e-03,  3.4629e-04,\r\n",
      "        -3.6614e-04,  3.1616e-05,  1.8932e-04, -2.4904e-04, -9.2297e-04,\r\n",
      "        -1.1544e-05,  3.1997e-04,  6.7361e-04,  6.5741e-05, -1.3584e-04,\r\n",
      "        -1.4715e-03,  1.0719e-03, -9.2726e-04,  4.5295e-04,  6.7807e-05,\r\n",
      "         1.0089e-04, -5.5861e-05, -3.9436e-04, -4.0852e-04, -6.3597e-04,\r\n",
      "        -1.0923e-03,  3.6431e-04,  6.8910e-04,  2.0246e-04, -1.5963e-04,\r\n",
      "         5.6203e-04, -4.7802e-04,  5.3243e-04, -9.6069e-04,  5.9740e-04,\r\n",
      "        -2.4501e-03,  6.8380e-05,  4.0038e-04, -7.8193e-04,  1.8077e-03,\r\n",
      "         1.8429e-04,  1.0968e-03,  5.2586e-04,  1.0949e-03,  1.2118e-03,\r\n",
      "        -1.3223e-03, -2.3578e-03,  3.0937e-04,  2.5770e-04, -3.8575e-04,\r\n",
      "         7.7083e-04,  3.6631e-04,  1.4414e-03, -5.1090e-04,  9.6092e-05,\r\n",
      "        -1.4891e-04, -6.4823e-04,  1.0352e-03, -7.3996e-04, -1.0498e-05,\r\n",
      "        -7.7297e-04,  8.2672e-04,  4.7835e-04, -9.5418e-05, -1.3968e-03,\r\n",
      "        -1.9933e-04, -2.0126e-03, -2.5300e-04, -2.3496e-03,  1.2730e-04,\r\n",
      "         2.6763e-04, -6.3037e-05, -4.3421e-04,  1.6334e-03, -4.3185e-04,\r\n",
      "        -1.6781e-03,  2.2464e-04,  6.2209e-04, -1.0247e-03, -2.8330e-04,\r\n",
      "         2.0330e-03,  4.0559e-04, -8.2355e-04,  8.2581e-04,  1.6310e-03,\r\n",
      "        -8.5047e-04, -1.0108e-03,  5.8743e-04, -3.1012e-04, -6.5963e-04,\r\n",
      "         1.3052e-03, -7.9070e-04, -5.1822e-04,  4.7393e-04, -1.7597e-03,\r\n",
      "        -3.8588e-04, -2.3755e-05,  1.9811e-03, -6.0825e-04,  3.5539e-04,\r\n",
      "        -7.1883e-04,  2.8320e-05,  5.1058e-04, -6.4363e-04, -2.3877e-04,\r\n",
      "        -4.0515e-04, -7.1987e-04, -7.8239e-04, -1.1770e-03, -7.7885e-04,\r\n",
      "        -5.0784e-04, -1.4204e-04, -8.8747e-04,  1.2598e-03, -4.7530e-04,\r\n",
      "        -9.6150e-04, -1.1482e-03, -7.3525e-04, -2.0107e-04,  4.2855e-04,\r\n",
      "        -3.9600e-04,  5.0101e-04, -1.0884e-03, -4.6154e-04, -5.1770e-04,\r\n",
      "         4.8731e-04, -4.0188e-04,  7.0828e-04, -1.5947e-03, -1.7249e-03,\r\n",
      "         4.5511e-05,  7.9280e-04,  5.0275e-04,  4.8314e-04,  1.4173e-04,\r\n",
      "         5.1528e-04,  4.6762e-04, -4.3664e-05, -3.7038e-04, -7.2871e-05,\r\n",
      "         8.9504e-04, -2.2076e-04, -1.0913e-04,  6.2386e-04,  1.4942e-03,\r\n",
      "        -8.8522e-05, -8.5265e-05, -1.1851e-03,  3.3399e-04,  1.0242e-03,\r\n",
      "        -9.7635e-04, -1.0301e-03, -3.2225e-04,  8.7913e-04,  1.3223e-04,\r\n",
      "        -1.7755e-03,  1.2554e-03, -5.5595e-04,  5.0857e-04, -6.2451e-04,\r\n",
      "         2.0534e-04, -8.3279e-04,  3.1302e-05, -1.0746e-03,  1.1293e-03,\r\n",
      "         1.6685e-03, -1.1339e-04,  5.0130e-04, -3.1844e-04, -9.2712e-05,\r\n",
      "        -5.0000e-04, -6.7464e-04, -2.6012e-04, -6.3158e-04, -2.1667e-03,\r\n",
      "         5.0802e-05,  3.4608e-04, -7.5509e-04, -9.3456e-05,  1.1835e-03,\r\n",
      "         8.1173e-04,  1.5641e-04, -9.6492e-04, -1.2505e-03, -1.6897e-03,\r\n",
      "        -3.9844e-04,  3.3470e-04,  3.5754e-04, -7.1552e-04,  6.1426e-04,\r\n",
      "        -2.2596e-03, -3.4755e-04, -8.0111e-04,  7.4266e-05,  6.0353e-04,\r\n",
      "         4.4214e-04, -1.5520e-04, -4.2670e-04,  8.1619e-05,  3.4764e-05,\r\n",
      "        -1.7265e-04,  1.8147e-04,  6.6059e-04,  7.8981e-04, -9.6457e-04,\r\n",
      "        -1.6663e-03,  2.0860e-03, -1.0387e-03, -1.6116e-04,  5.2364e-05,\r\n",
      "         2.1849e-04, -1.3966e-04, -1.2589e-03, -5.0960e-04,  3.3034e-05,\r\n",
      "        -5.2385e-04,  4.6268e-04, -5.5936e-05,  4.0273e-04, -3.0315e-04,\r\n",
      "         9.7559e-04, -1.5536e-03, -6.4939e-04,  2.3879e-04, -1.7089e-04,\r\n",
      "         6.6516e-04, -3.1148e-04, -1.3353e-03, -5.9000e-04,  1.0411e-04,\r\n",
      "         1.8208e-03,  9.1764e-04]), 'exp_avg_sq': tensor([7.7164e-08, 1.2276e-07, 3.9763e-08, 2.7476e-06, 2.8208e-07, 2.4540e-08,\r\n",
      "        1.2958e-06, 2.8723e-07, 6.7628e-09, 1.5729e-07, 1.4048e-07, 1.7917e-10,\r\n",
      "        7.5934e-08, 2.5622e-07, 3.1886e-07, 3.9950e-08, 2.0422e-07, 4.4736e-08,\r\n",
      "        1.0834e-07, 1.4797e-07, 4.4960e-08, 1.1075e-07, 5.5176e-08, 9.3280e-07,\r\n",
      "        4.2697e-07, 5.8640e-08, 4.8285e-07, 5.9150e-07, 1.8070e-10, 1.3858e-08,\r\n",
      "        5.6137e-08, 4.1980e-07, 6.0681e-08, 1.5638e-07, 3.3218e-09, 3.7582e-08,\r\n",
      "        5.9207e-07, 8.5039e-07, 2.3026e-07, 1.1192e-07, 9.5069e-08, 3.3837e-09,\r\n",
      "        5.8893e-08, 6.1765e-08, 2.6988e-07, 2.5571e-08, 1.0796e-06, 3.3118e-07,\r\n",
      "        4.4337e-08, 2.4072e-08, 2.0912e-07, 7.1323e-07, 2.1474e-08, 5.8774e-07,\r\n",
      "        3.4236e-09, 5.8140e-07, 1.1715e-07, 1.0792e-09, 6.5682e-08, 2.6431e-08,\r\n",
      "        2.4579e-08, 2.3870e-07, 2.3818e-10, 2.9445e-09, 9.2466e-08, 2.1638e-09,\r\n",
      "        1.5967e-07, 2.9621e-07, 1.5311e-10, 1.7868e-07, 4.0631e-07, 9.4049e-08,\r\n",
      "        1.2783e-06, 1.5529e-07, 2.3470e-07, 5.1737e-07, 1.0109e-06, 6.5505e-07,\r\n",
      "        5.6971e-08, 2.8899e-08, 1.8853e-07, 2.2736e-07, 1.8648e-08, 3.0431e-08,\r\n",
      "        5.2836e-07, 5.8717e-08, 2.9887e-08, 1.8443e-07, 1.3772e-07, 5.4288e-07,\r\n",
      "        6.0030e-07, 2.8913e-11, 1.1615e-08, 2.8804e-07, 3.6456e-07, 3.1107e-07,\r\n",
      "        3.6394e-08, 2.8339e-07, 1.7628e-08, 1.9999e-07, 6.5376e-08, 5.1498e-09,\r\n",
      "        3.6036e-08, 1.6800e-08, 5.7396e-09, 1.5287e-07, 2.3175e-07, 1.6933e-08,\r\n",
      "        1.9125e-07, 6.4655e-07, 1.0063e-08, 1.5092e-08, 7.0094e-08, 8.5471e-07,\r\n",
      "        2.1754e-08, 7.5882e-08, 1.1735e-09, 5.8986e-11, 1.5434e-07, 2.2813e-08,\r\n",
      "        3.0066e-09, 3.9508e-07, 2.0319e-07, 6.8392e-08, 7.1557e-08, 2.2621e-07,\r\n",
      "        1.1815e-06, 4.5215e-07, 8.1154e-09, 2.5502e-07, 1.6138e-07, 1.7869e-06,\r\n",
      "        7.7598e-08, 4.8514e-07, 1.8044e-08, 4.8622e-07, 4.1384e-07, 5.5739e-07,\r\n",
      "        7.0132e-07, 6.0883e-07, 6.1369e-09, 4.0546e-07, 4.3095e-08, 9.7279e-07,\r\n",
      "        1.5124e-08, 2.2133e-09, 6.8439e-08, 4.1823e-07, 2.2202e-07, 2.3480e-09,\r\n",
      "        4.6031e-08, 2.3302e-07, 2.6273e-09, 1.5229e-08, 2.3330e-08, 5.7089e-09,\r\n",
      "        1.4436e-08, 2.6527e-07, 2.1237e-07, 1.7993e-09, 3.1333e-07, 2.8960e-07,\r\n",
      "        8.8677e-08, 4.9227e-08, 3.3770e-08, 4.0395e-07, 9.1236e-07, 9.3860e-09,\r\n",
      "        1.0496e-07, 8.6555e-07, 1.5651e-06, 4.0784e-07, 4.8400e-07, 6.3990e-07,\r\n",
      "        6.2178e-08, 4.0991e-08, 3.5065e-07, 1.5784e-08, 2.5838e-09, 1.0279e-08,\r\n",
      "        8.3801e-09, 3.2360e-07, 7.6021e-10, 7.6595e-08, 6.3048e-11, 1.0476e-06,\r\n",
      "        4.5757e-08, 1.8560e-07, 1.1966e-07, 4.6001e-07, 1.1229e-08, 3.1772e-07,\r\n",
      "        2.0347e-07, 4.1695e-07, 2.0672e-07, 3.5286e-07, 8.5105e-07, 4.1574e-09,\r\n",
      "        1.0018e-07, 1.9547e-07, 1.0155e-07, 2.9017e-08, 4.4842e-08, 3.3442e-07,\r\n",
      "        2.5247e-10, 1.3241e-06, 2.0793e-07, 9.3541e-07, 2.5218e-07, 6.7595e-08,\r\n",
      "        7.8131e-08, 1.4880e-07, 4.3086e-07, 3.7909e-08, 1.6296e-11, 4.4890e-07,\r\n",
      "        4.1582e-07, 1.4200e-07, 4.4643e-08, 4.6475e-07, 4.6135e-07, 6.1341e-08,\r\n",
      "        4.1083e-07, 7.3851e-07, 2.5412e-08, 1.8770e-08, 5.5031e-08, 3.8410e-07,\r\n",
      "        2.6068e-08, 1.0516e-07, 3.8503e-07, 1.3092e-07, 8.3837e-10, 3.6744e-08,\r\n",
      "        5.9749e-07, 1.5523e-07, 3.9450e-10, 7.0087e-09, 1.6873e-07, 7.4174e-08,\r\n",
      "        9.6825e-07, 1.1996e-10, 2.5604e-07, 7.7410e-08, 4.3956e-07, 8.3464e-11,\r\n",
      "        6.4294e-08, 2.5907e-07, 3.0863e-07, 5.4198e-07, 1.1932e-07, 8.2664e-08,\r\n",
      "        4.9562e-08, 9.9265e-09, 5.3287e-07, 4.3629e-07, 3.8510e-07, 7.2622e-07,\r\n",
      "        3.4450e-07, 6.9586e-08, 1.3734e-10, 1.2351e-07, 1.7736e-08, 8.0141e-08,\r\n",
      "        2.1063e-07, 1.7363e-07, 5.5324e-08, 3.3079e-07, 3.3567e-08, 3.1930e-07,\r\n",
      "        9.2579e-07, 2.5153e-07, 2.0341e-07, 8.7013e-07, 2.5432e-07, 1.8002e-07,\r\n",
      "        4.6384e-07, 2.3834e-08, 1.7415e-08, 6.6014e-07, 2.0678e-07, 7.4208e-09,\r\n",
      "        3.5246e-09, 8.4552e-07, 5.1215e-08, 8.2986e-08, 6.5979e-10, 1.9791e-08,\r\n",
      "        3.6656e-08, 4.6385e-07, 2.8962e-10, 8.7413e-08, 2.7122e-07, 2.5078e-09,\r\n",
      "        6.1454e-09, 7.6110e-07, 5.4169e-07, 2.8717e-07, 9.3327e-08, 2.0969e-09,\r\n",
      "        3.7432e-09, 1.2590e-09, 8.5745e-08, 8.3672e-08, 1.3330e-07, 4.9149e-07,\r\n",
      "        6.0410e-08, 2.1402e-07, 1.8590e-08, 1.0770e-08, 1.5294e-07, 1.1295e-07,\r\n",
      "        1.3132e-07, 4.5380e-07, 1.4627e-07, 2.5475e-06, 1.8846e-09, 7.0171e-08,\r\n",
      "        2.1795e-07, 1.2818e-06, 1.1481e-08, 4.7501e-07, 1.8780e-07, 4.9639e-07,\r\n",
      "        1.0706e-06, 7.7913e-07, 2.0207e-06, 3.3890e-08, 3.2225e-08, 5.6859e-08,\r\n",
      "        2.0166e-07, 5.3125e-08, 7.7074e-07, 8.9850e-08, 3.7124e-09, 7.5196e-09,\r\n",
      "        1.5428e-07, 5.3680e-07, 3.4537e-07, 8.5126e-11, 2.4905e-07, 2.6430e-07,\r\n",
      "        1.0958e-07, 4.3862e-09, 6.9246e-07, 1.2762e-08, 1.5601e-06, 2.3709e-08,\r\n",
      "        2.1115e-06, 6.9972e-09, 3.1576e-08, 3.2171e-09, 7.7415e-08, 1.3857e-06,\r\n",
      "        6.0510e-08, 1.0584e-06, 2.4855e-08, 1.6015e-07, 3.8742e-07, 3.6693e-08,\r\n",
      "        1.4279e-06, 5.7121e-08, 2.4689e-07, 4.2912e-07, 1.1047e-06, 2.7451e-07,\r\n",
      "        4.2226e-07, 1.4443e-07, 5.9093e-08, 1.5411e-07, 6.6563e-07, 2.4608e-07,\r\n",
      "        1.9091e-07, 8.3161e-08, 1.0843e-06, 6.7922e-08, 3.8880e-10, 1.4987e-06,\r\n",
      "        1.9938e-07, 8.1705e-08, 2.4367e-07, 3.2630e-10, 9.1798e-08, 1.3959e-07,\r\n",
      "        3.3219e-08, 9.4293e-08, 1.8718e-07, 2.1636e-07, 5.7280e-07, 2.1038e-07,\r\n",
      "        2.1831e-07, 8.4361e-09, 2.7328e-07, 5.5400e-07, 8.7320e-08, 3.3456e-07,\r\n",
      "        4.3830e-07, 1.9260e-07, 1.4234e-08, 6.8543e-08, 8.5020e-08, 1.0171e-07,\r\n",
      "        4.7955e-07, 9.9048e-08, 9.9538e-08, 1.4217e-07, 8.8828e-08, 1.8539e-07,\r\n",
      "        9.4320e-07, 1.1663e-06, 9.4108e-10, 2.5739e-07, 1.4656e-07, 1.0224e-07,\r\n",
      "        7.9717e-09, 1.3084e-07, 1.0355e-07, 5.3899e-10, 9.0838e-08, 1.7078e-09,\r\n",
      "        2.8519e-07, 1.7264e-08, 4.5490e-09, 1.4607e-07, 8.1578e-07, 4.1729e-09,\r\n",
      "        2.8266e-09, 5.0028e-07, 3.9925e-08, 3.6853e-07, 3.1738e-07, 3.9705e-07,\r\n",
      "        6.9891e-08, 3.5640e-07, 7.4517e-09, 1.0367e-06, 6.6246e-07, 1.0598e-07,\r\n",
      "        9.4155e-08, 2.4291e-07, 2.0929e-08, 3.2073e-07, 5.5937e-10, 5.4015e-07,\r\n",
      "        4.5852e-07, 1.2060e-06, 5.8675e-09, 8.2978e-08, 3.4781e-08, 3.2848e-09,\r\n",
      "        9.2601e-08, 1.6602e-07, 2.9814e-08, 2.0885e-07, 1.7393e-06, 1.6198e-09,\r\n",
      "        5.1644e-08, 2.5278e-07, 3.7122e-09, 4.8242e-07, 4.9779e-07, 8.4997e-09,\r\n",
      "        3.2494e-07, 5.9601e-07, 1.0640e-06, 1.3780e-07, 4.5851e-08, 4.5727e-08,\r\n",
      "        1.7578e-07, 1.4484e-07, 1.7583e-06, 8.4173e-08, 2.5657e-07, 1.7598e-09,\r\n",
      "        1.4595e-07, 1.2430e-07, 1.5368e-08, 6.8456e-08, 2.7557e-09, 6.9048e-10,\r\n",
      "        1.0779e-08, 1.8902e-08, 1.5419e-07, 2.6334e-07, 6.3469e-07, 1.2235e-06,\r\n",
      "        1.6909e-06, 4.0208e-07, 9.0005e-09, 9.5711e-10, 2.8056e-08, 6.2779e-09,\r\n",
      "        6.4702e-07, 1.1289e-07, 7.4439e-10, 9.5989e-08, 1.6195e-07, 1.1897e-09,\r\n",
      "        7.4498e-08, 3.8580e-08, 5.5186e-07, 7.8925e-07, 1.5203e-07, 2.3335e-08,\r\n",
      "        9.7102e-09, 2.3388e-07, 3.3068e-08, 5.8107e-07, 1.2994e-07, 3.6334e-09,\r\n",
      "        1.1865e-06, 2.9147e-07])}, 16: {'step': 63, 'exp_avg': tensor([[-0.0005, -0.0008, -0.0005,  ..., -0.0008, -0.0013, -0.0011],\r\n",
      "        [ 0.0008,  0.0013,  0.0008,  ...,  0.0013,  0.0021,  0.0019],\r\n",
      "        [-0.0002, -0.0004, -0.0003,  ..., -0.0004, -0.0007, -0.0006],\r\n",
      "        ...,\r\n",
      "        [ 0.0007,  0.0013,  0.0008,  ...,  0.0013,  0.0020,  0.0018],\r\n",
      "        [-0.0003, -0.0004, -0.0003,  ..., -0.0005, -0.0007, -0.0006],\r\n",
      "        [ 0.0002,  0.0003,  0.0002,  ...,  0.0003,  0.0005,  0.0004]]), 'exp_avg_sq': tensor([[1.5071e-07, 2.2182e-07, 1.4133e-07,  ..., 2.1688e-07, 5.6303e-07,\r\n",
      "         4.2556e-07],\r\n",
      "        [4.0671e-07, 6.2023e-07, 3.7865e-07,  ..., 5.8829e-07, 1.6308e-06,\r\n",
      "         1.2116e-06],\r\n",
      "        [4.1108e-08, 6.9581e-08, 3.9151e-08,  ..., 6.4132e-08, 1.9712e-07,\r\n",
      "         1.4335e-07],\r\n",
      "        ...,\r\n",
      "        [4.0124e-07, 5.9530e-07, 3.7620e-07,  ..., 5.7028e-07, 1.4966e-06,\r\n",
      "         1.1299e-06],\r\n",
      "        [4.6516e-08, 7.0286e-08, 4.4482e-08,  ..., 6.7178e-08, 1.8037e-07,\r\n",
      "         1.3483e-07],\r\n",
      "        [1.9375e-08, 2.7958e-08, 1.7635e-08,  ..., 2.7783e-08, 7.4635e-08,\r\n",
      "         5.5282e-08]])}, 17: {'step': 63, 'exp_avg': tensor([-2.7314e-03,  4.5521e-03, -1.5093e-03,  1.5033e-03, -2.8897e-03,\r\n",
      "         1.9738e-03, -2.0448e-03,  2.4790e-03,  2.3579e-03,  3.1486e-03,\r\n",
      "         1.2563e-03, -2.7171e-03,  2.3843e-05,  1.9702e-03, -4.4975e-03,\r\n",
      "         4.8098e-04, -4.3260e-03,  1.8192e-03,  7.9246e-04,  1.8403e-03,\r\n",
      "        -4.0595e-03, -2.6163e-03, -1.4689e-03,  6.1680e-03, -3.4806e-03,\r\n",
      "         2.1066e-04, -2.9052e-03,  2.6591e-03, -1.0005e-03, -2.3325e-03,\r\n",
      "         2.6296e-03,  3.1344e-03,  1.8546e-03, -1.5536e-03, -5.3160e-04,\r\n",
      "        -4.7317e-03,  3.3668e-03, -2.5125e-03,  1.1670e-04,  5.1152e-03,\r\n",
      "        -2.6984e-03, -2.4880e-03, -1.6857e-03, -2.6734e-03,  1.0027e-03,\r\n",
      "         1.1926e-03, -1.8673e-03,  8.6586e-04, -2.2720e-03, -3.9526e-03,\r\n",
      "        -3.5212e-03,  2.7527e-03, -4.2030e-04,  4.9466e-03,  4.0054e-03,\r\n",
      "        -2.4244e-03,  2.5702e-03,  6.5825e-04, -3.1459e-04,  4.6345e-05,\r\n",
      "         6.1662e-04,  4.5044e-03, -5.1747e-04, -3.2171e-03, -9.2677e-04,\r\n",
      "        -2.6690e-03, -9.8000e-04,  4.3453e-03,  5.1763e-03, -7.3344e-04,\r\n",
      "         5.7635e-04, -9.4478e-05, -2.6757e-03, -1.8439e-03, -5.0046e-04,\r\n",
      "        -1.3959e-03,  1.6925e-03, -4.5539e-03,  4.1378e-04,  2.3032e-03,\r\n",
      "        -2.7259e-05, -1.7680e-03, -4.6652e-03,  1.4123e-03,  2.2745e-03,\r\n",
      "        -2.2365e-03,  2.3321e-03,  1.0262e-03,  5.3511e-04,  3.1705e-03,\r\n",
      "        -1.8377e-04, -3.1653e-03,  1.2897e-03, -4.0360e-04,  2.4968e-03,\r\n",
      "         2.6049e-04, -1.0885e-03,  9.1628e-04,  1.2187e-03,  8.4507e-04,\r\n",
      "        -2.2091e-03, -4.5385e-03,  1.4674e-03,  6.4689e-04, -5.1809e-03,\r\n",
      "        -3.1276e-03,  4.6737e-03,  3.6968e-04,  4.3618e-04,  4.6556e-03,\r\n",
      "        -2.2924e-03, -4.1095e-03, -1.5272e-03,  2.0875e-03, -2.1069e-04,\r\n",
      "        -5.0718e-04,  2.3863e-03, -1.4181e-03, -3.3743e-04,  3.8617e-03,\r\n",
      "         2.1538e-03, -1.0261e-03, -1.8953e-03, -1.0620e-03,  3.7754e-03,\r\n",
      "         4.4608e-03, -1.5279e-03,  9.6831e-04]), 'exp_avg_sq': tensor([2.9615e-06, 8.0739e-06, 8.7716e-07, 8.4930e-07, 3.2566e-06, 1.5389e-06,\r\n",
      "        1.6300e-06, 2.4507e-06, 2.1893e-06, 3.9294e-06, 6.2640e-07, 2.9127e-06,\r\n",
      "        1.0818e-09, 1.5314e-06, 7.9327e-06, 9.0836e-08, 7.3437e-06, 1.3058e-06,\r\n",
      "        2.3738e-07, 1.3463e-06, 6.4773e-06, 2.7431e-06, 8.4899e-07, 1.4933e-05,\r\n",
      "        4.7250e-06, 1.8336e-08, 3.2834e-06, 2.7617e-06, 3.9871e-07, 2.1488e-06,\r\n",
      "        2.7107e-06, 3.8874e-06, 1.3439e-06, 9.4668e-07, 1.0605e-07, 8.7572e-06,\r\n",
      "        4.4490e-06, 2.4266e-06, 4.6953e-09, 1.0277e-05, 2.8443e-06, 2.4196e-06,\r\n",
      "        1.1056e-06, 2.8051e-06, 3.9242e-07, 5.4619e-07, 1.3734e-06, 3.1986e-07,\r\n",
      "        2.0325e-06, 6.1683e-06, 4.8512e-06, 2.9853e-06, 6.8119e-08, 9.6271e-06,\r\n",
      "        6.2585e-06, 2.3001e-06, 2.5962e-06, 1.6258e-07, 3.6661e-08, 1.6601e-09,\r\n",
      "        1.4073e-07, 7.9568e-06, 1.1051e-07, 3.9865e-06, 3.3178e-07, 2.8523e-06,\r\n",
      "        3.6464e-07, 7.4063e-06, 1.0508e-05, 1.9758e-07, 1.2556e-07, 4.0538e-09,\r\n",
      "        2.8507e-06, 1.3688e-06, 9.3710e-08, 7.5177e-07, 1.1000e-06, 8.0723e-06,\r\n",
      "        5.9014e-08, 2.0752e-06, 1.7667e-09, 1.2303e-06, 8.5194e-06, 7.8038e-07,\r\n",
      "        2.0371e-06, 1.9501e-06, 2.1315e-06, 4.1054e-07, 1.1085e-07, 3.9407e-06,\r\n",
      "        1.1385e-08, 3.9360e-06, 6.4634e-07, 6.1136e-08, 2.4213e-06, 2.9081e-08,\r\n",
      "        4.6366e-07, 3.3109e-07, 5.6203e-07, 2.7470e-07, 1.9384e-06, 7.9825e-06,\r\n",
      "        8.5253e-07, 1.6310e-07, 1.0508e-05, 3.8497e-06, 8.6030e-06, 5.0874e-08,\r\n",
      "        7.7511e-08, 8.4839e-06, 2.0790e-06, 6.6286e-06, 9.2488e-07, 1.7103e-06,\r\n",
      "        1.6569e-08, 9.6465e-08, 2.2144e-06, 8.0324e-07, 4.6477e-08, 5.8493e-06,\r\n",
      "        1.8480e-06, 4.0143e-07, 1.4250e-06, 4.4317e-07, 5.5846e-06, 7.8226e-06,\r\n",
      "        9.2733e-07, 3.7279e-07])}, 18: {'step': 63, 'exp_avg': tensor([[ 2.9235e-02,  2.1193e-02, -2.5264e-02,  3.4786e-02, -1.0427e-02,\r\n",
      "          8.4752e-03,  5.3395e-03, -4.4295e-02, -1.3688e-02, -2.2414e-02,\r\n",
      "         -1.5273e-02,  1.6531e-02,  2.1390e-02, -5.9534e-03,  5.5785e-03,\r\n",
      "         -2.5473e-02, -3.1096e-03, -6.7329e-03,  1.7830e-02, -5.9045e-03,\r\n",
      "          7.8188e-03,  1.9087e-02,  1.8983e-02,  4.2695e-03, -2.1867e-02,\r\n",
      "          6.8758e-07, -2.2960e-02,  1.0694e-02, -1.3465e-02,  6.8403e-03,\r\n",
      "         -7.9325e-03, -3.1205e-02,  9.3241e-03,  7.1942e-03,  5.6966e-03,\r\n",
      "         -9.1339e-03,  2.0766e-03, -2.7449e-02,  1.5286e-02, -1.8214e-02,\r\n",
      "          1.9632e-03,  7.6021e-03,  6.0719e-04, -5.4730e-03,  1.8907e-02,\r\n",
      "          1.9199e-02,  2.1282e-02, -3.7223e-02,  1.0966e-02,  4.9242e-03,\r\n",
      "         -1.4595e-02, -2.2862e-02,  8.1031e-03, -3.0162e-03, -1.2366e-02,\r\n",
      "         -3.5777e-03,  1.1184e-02, -3.4684e-03,  1.0708e-02, -8.3682e-03,\r\n",
      "          2.7527e-02, -6.6192e-03, -3.9874e-03, -3.6274e-02,  1.3363e-02,\r\n",
      "          2.9122e-02, -2.8594e-02, -4.1087e-03,  1.1959e-02, -1.0577e-02,\r\n",
      "          1.6425e-02, -7.0929e-03,  2.7178e-02,  2.5538e-02,  2.4871e-03,\r\n",
      "         -2.6359e-02,  9.8676e-03,  2.5305e-03,  4.0685e-02, -1.2901e-02,\r\n",
      "          2.4389e-02,  3.9745e-03, -1.9538e-03, -1.3964e-02,  4.0574e-03,\r\n",
      "          1.0840e-02,  2.6698e-03,  1.9269e-02, -3.4739e-04,  1.5073e-04,\r\n",
      "         -1.2070e-02, -1.1742e-02,  2.0258e-02, -9.0936e-03,  3.8345e-02,\r\n",
      "         -3.4966e-03, -1.7386e-02,  1.9593e-02,  1.1603e-02,  1.0683e-02,\r\n",
      "          7.5283e-03, -2.1047e-02,  2.4617e-03, -1.9140e-02,  4.1848e-04,\r\n",
      "          2.4666e-03, -2.0245e-02,  1.9723e-02, -1.8516e-02, -1.3046e-04,\r\n",
      "          8.4780e-03,  1.3301e-02,  7.6302e-03, -1.6389e-02, -2.0028e-02,\r\n",
      "         -2.6347e-02,  1.3131e-02,  1.5293e-02, -4.7905e-03,  1.1684e-02,\r\n",
      "         -1.0662e-02, -3.4361e-02,  1.2813e-02, -1.5532e-02, -1.8003e-03,\r\n",
      "         -2.1669e-02,  9.0510e-03, -6.3843e-04],\r\n",
      "        [-2.9235e-02, -2.1193e-02,  2.5264e-02, -3.4786e-02,  1.0427e-02,\r\n",
      "         -8.4752e-03, -5.3395e-03,  4.4295e-02,  1.3688e-02,  2.2414e-02,\r\n",
      "          1.5273e-02, -1.6531e-02, -2.1390e-02,  5.9534e-03, -5.5785e-03,\r\n",
      "          2.5473e-02,  3.1096e-03,  6.7329e-03, -1.7830e-02,  5.9045e-03,\r\n",
      "         -7.8188e-03, -1.9087e-02, -1.8983e-02, -4.2695e-03,  2.1867e-02,\r\n",
      "         -6.8761e-07,  2.2960e-02, -1.0694e-02,  1.3465e-02, -6.8403e-03,\r\n",
      "          7.9325e-03,  3.1205e-02, -9.3241e-03, -7.1942e-03, -5.6966e-03,\r\n",
      "          9.1339e-03, -2.0766e-03,  2.7449e-02, -1.5286e-02,  1.8214e-02,\r\n",
      "         -1.9632e-03, -7.6021e-03, -6.0719e-04,  5.4730e-03, -1.8907e-02,\r\n",
      "         -1.9199e-02, -2.1282e-02,  3.7223e-02, -1.0966e-02, -4.9242e-03,\r\n",
      "          1.4595e-02,  2.2862e-02, -8.1031e-03,  3.0162e-03,  1.2366e-02,\r\n",
      "          3.5777e-03, -1.1184e-02,  3.4684e-03, -1.0708e-02,  8.3682e-03,\r\n",
      "         -2.7527e-02,  6.6192e-03,  3.9874e-03,  3.6274e-02, -1.3363e-02,\r\n",
      "         -2.9122e-02,  2.8594e-02,  4.1087e-03, -1.1959e-02,  1.0577e-02,\r\n",
      "         -1.6425e-02,  7.0929e-03, -2.7178e-02, -2.5538e-02, -2.4871e-03,\r\n",
      "          2.6359e-02, -9.8676e-03, -2.5305e-03, -4.0685e-02,  1.2901e-02,\r\n",
      "         -2.4389e-02, -3.9745e-03,  1.9538e-03,  1.3964e-02, -4.0574e-03,\r\n",
      "         -1.0840e-02, -2.6698e-03, -1.9269e-02,  3.4739e-04, -1.5073e-04,\r\n",
      "          1.2070e-02,  1.1742e-02, -2.0258e-02,  9.0936e-03, -3.8345e-02,\r\n",
      "          3.4966e-03,  1.7386e-02, -1.9593e-02, -1.1603e-02, -1.0683e-02,\r\n",
      "         -7.5283e-03,  2.1047e-02, -2.4617e-03,  1.9140e-02, -4.1848e-04,\r\n",
      "         -2.4666e-03,  2.0245e-02, -1.9723e-02,  1.8516e-02,  1.3046e-04,\r\n",
      "         -8.4780e-03, -1.3301e-02, -7.6302e-03,  1.6389e-02,  2.0028e-02,\r\n",
      "          2.6347e-02, -1.3131e-02, -1.5293e-02,  4.7905e-03, -1.1684e-02,\r\n",
      "          1.0662e-02,  3.4361e-02, -1.2813e-02,  1.5532e-02,  1.8003e-03,\r\n",
      "          2.1669e-02, -9.0510e-03,  6.3843e-04]]), 'exp_avg_sq': tensor([[2.7054e-04, 1.7030e-04, 3.3771e-04, 4.9820e-04, 4.8446e-05, 5.2477e-05,\r\n",
      "         1.0277e-05, 7.1246e-04, 6.2959e-05, 1.5375e-04, 7.4074e-05, 1.3581e-04,\r\n",
      "         1.8879e-04, 1.6361e-05, 2.5641e-05, 3.0574e-04, 4.2021e-06, 2.0642e-05,\r\n",
      "         1.0876e-04, 1.0990e-04, 4.6517e-05, 2.7066e-04, 1.3181e-04, 9.9819e-06,\r\n",
      "         1.6340e-04, 2.5619e-06, 2.3340e-04, 5.8549e-05, 5.9103e-05, 2.0712e-05,\r\n",
      "         3.9673e-05, 3.0403e-04, 3.8477e-05, 4.3446e-05, 2.0541e-05, 2.8802e-05,\r\n",
      "         2.0300e-06, 3.9424e-04, 1.2738e-04, 1.3357e-04, 1.5683e-05, 5.5273e-05,\r\n",
      "         2.2644e-06, 4.4997e-05, 1.2683e-04, 1.3802e-04, 1.7347e-04, 5.8026e-04,\r\n",
      "         5.6131e-05, 3.8546e-05, 8.5796e-05, 2.1791e-04, 2.5792e-05, 5.0327e-06,\r\n",
      "         1.1384e-04, 4.5455e-05, 6.2943e-05, 3.8831e-06, 5.4815e-05, 5.2838e-05,\r\n",
      "         2.5124e-04, 6.0731e-05, 6.3247e-05, 4.9015e-04, 1.5784e-04, 2.8638e-04,\r\n",
      "         2.6251e-04, 8.4540e-05, 1.2359e-04, 7.8716e-05, 1.3803e-04, 4.6517e-05,\r\n",
      "         3.0581e-04, 2.8466e-04, 3.5017e-05, 2.5043e-04, 6.8778e-05, 1.8900e-05,\r\n",
      "         5.5103e-04, 2.0144e-04, 2.3521e-04, 1.7715e-05, 2.2216e-05, 1.1068e-04,\r\n",
      "         3.0017e-05, 6.3275e-05, 6.5739e-06, 2.4122e-04, 3.0553e-05, 2.2715e-06,\r\n",
      "         4.4461e-05, 1.1418e-04, 1.6969e-04, 7.2455e-05, 4.7605e-04, 1.8460e-05,\r\n",
      "         1.0412e-04, 2.0484e-04, 5.5085e-05, 4.7954e-05, 1.4309e-05, 1.6664e-04,\r\n",
      "         7.1957e-06, 2.3374e-04, 4.9824e-05, 5.9543e-06, 1.5630e-04, 1.3230e-04,\r\n",
      "         1.3537e-04, 6.1051e-06, 3.4041e-05, 7.6417e-05, 5.3341e-05, 1.2064e-04,\r\n",
      "         2.2082e-04, 2.4576e-04, 6.9172e-05, 1.8077e-04, 1.0241e-04, 8.9783e-05,\r\n",
      "         1.0256e-04, 4.1270e-04, 6.4214e-05, 7.3839e-05, 2.3892e-06, 1.6877e-04,\r\n",
      "         2.7542e-05, 1.6056e-06],\r\n",
      "        [2.7054e-04, 1.7030e-04, 3.3771e-04, 4.9820e-04, 4.8446e-05, 5.2477e-05,\r\n",
      "         1.0277e-05, 7.1246e-04, 6.2959e-05, 1.5375e-04, 7.4074e-05, 1.3581e-04,\r\n",
      "         1.8879e-04, 1.6361e-05, 2.5641e-05, 3.0574e-04, 4.2021e-06, 2.0642e-05,\r\n",
      "         1.0876e-04, 1.0990e-04, 4.6517e-05, 2.7066e-04, 1.3181e-04, 9.9819e-06,\r\n",
      "         1.6340e-04, 2.5619e-06, 2.3340e-04, 5.8549e-05, 5.9103e-05, 2.0712e-05,\r\n",
      "         3.9673e-05, 3.0403e-04, 3.8477e-05, 4.3446e-05, 2.0541e-05, 2.8802e-05,\r\n",
      "         2.0300e-06, 3.9424e-04, 1.2738e-04, 1.3357e-04, 1.5683e-05, 5.5273e-05,\r\n",
      "         2.2644e-06, 4.4997e-05, 1.2683e-04, 1.3802e-04, 1.7347e-04, 5.8026e-04,\r\n",
      "         5.6131e-05, 3.8546e-05, 8.5796e-05, 2.1791e-04, 2.5792e-05, 5.0327e-06,\r\n",
      "         1.1384e-04, 4.5455e-05, 6.2943e-05, 3.8831e-06, 5.4815e-05, 5.2838e-05,\r\n",
      "         2.5124e-04, 6.0731e-05, 6.3247e-05, 4.9015e-04, 1.5784e-04, 2.8638e-04,\r\n",
      "         2.6251e-04, 8.4540e-05, 1.2359e-04, 7.8716e-05, 1.3803e-04, 4.6517e-05,\r\n",
      "         3.0581e-04, 2.8466e-04, 3.5017e-05, 2.5043e-04, 6.8778e-05, 1.8900e-05,\r\n",
      "         5.5103e-04, 2.0144e-04, 2.3521e-04, 1.7715e-05, 2.2216e-05, 1.1068e-04,\r\n",
      "         3.0017e-05, 6.3275e-05, 6.5739e-06, 2.4122e-04, 3.0553e-05, 2.2715e-06,\r\n",
      "         4.4461e-05, 1.1418e-04, 1.6969e-04, 7.2455e-05, 4.7605e-04, 1.8460e-05,\r\n",
      "         1.0412e-04, 2.0484e-04, 5.5085e-05, 4.7954e-05, 1.4309e-05, 1.6664e-04,\r\n",
      "         7.1957e-06, 2.3374e-04, 4.9824e-05, 5.9543e-06, 1.5630e-04, 1.3230e-04,\r\n",
      "         1.3537e-04, 6.1051e-06, 3.4041e-05, 7.6417e-05, 5.3341e-05, 1.2064e-04,\r\n",
      "         2.2082e-04, 2.4576e-04, 6.9172e-05, 1.8077e-04, 1.0241e-04, 8.9783e-05,\r\n",
      "         1.0256e-04, 4.1270e-04, 6.4214e-05, 7.3839e-05, 2.3892e-06, 1.6877e-04,\r\n",
      "         2.7542e-05, 1.6056e-06]])}, 19: {'step': 63, 'exp_avg': tensor([-0.0423,  0.0423]), 'exp_avg_sq': tensor([0.0007, 0.0007])}}\r\n",
      "param_groups \t [{'lr': 2.52e-06, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.0001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}]\r\n"
     ]
    }
   ],
   "source": [
    "!python ./experiments/classify.py -e 1 -t -d1 -H1 -D -m single_transformer.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pytorch model to tvm \n",
    "- [tvm reference](https://tvm.apache.org/docs/tutorials/frontend/from_pytorch.html#sphx-glr-tutorials-frontend-from-pytorch-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvm modules\n",
    "\n",
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tvm.contrib.download import download_testdata\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer modules\n",
    "\n",
    "import transformer_simple\n",
    "import classifier\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"transformer\"\n",
    "# single transformer\n",
    "mx = 512\n",
    "embedding_size = 128\n",
    "vocab_size = 50000\n",
    "NUM_CLS = 2\n",
    "max_pool = False\n",
    "num_heads = 1\n",
    "depth = 1\n",
    "\n",
    "PATH = 'saved_model/single_transformer1.pt'\n",
    "\n",
    "model = classifier.TransformerSimpleClassify(n_seq=mx, dim_emb=embedding_size, dim_internal=embedding_size, \\\n",
    "                                                         num_tokens=vocab_size, num_classes=NUM_CLS, max_pool=max_pool, \\\n",
    "                                                         heads=num_heads, depth=depth)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We grab the TorchScripted model via tracing\n",
    "input_shape = [4, 498]\n",
    "input_data = torch.randint(0, vocab_size, input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the graph to Relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"input0\"\n",
    "shape_list = [(input_name, input_shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relay Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm\"\n",
    "target_host = \"llvm\"\n",
    "ctx = tvm.cpu(0)\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, target_host=target_host, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the portable graph on TVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "m = graph_runtime.GraphModule(lib[\"default\"](ctx))\n",
    "# Set inputs\n",
    "m.set_input(input_name, tvm.nd.array(input_data))\n",
    "# Execute\n",
    "m.run()\n",
    "# Get outputs\n",
    "tvm_output = m.get_output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.runtime.ndarray.NDArray"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tvm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.nd.NDArray shape=(4, 2), cpu(0)>\n",
       "array([[-0.7326672 , -0.6551298 ],\n",
       "       [-0.7252913 , -0.66200423],\n",
       "       [-0.73297906, -0.6548413 ],\n",
       "       [-0.73238647, -0.65538967]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3765, 35163, 22374,  ..., 10840, 34026, 31777],\n",
       "        [16322, 12776, 30706,  ...,  7692, 48182, 26912],\n",
       "        [ 9161, 34760, 14639,  ..., 29835, 30657, 18810],\n",
       "        [17196, 32012, 24887,  ..., 49110, 43611,  2869]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_PATH='saved_model/input_data.pt'\n",
    "torch.save(input_data, INPUT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_output = tvm_output.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_output = torch.from_numpy(np_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7327, -0.6551],\n",
       "        [-0.7253, -0.6620],\n",
       "        [-0.7330, -0.6548],\n",
       "        [-0.7324, -0.6554]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DATA_PATH='saved_model/output_data.pt'\n",
    "torch.save(torch_output, OUTPUT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate code (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "type tensor_float16_t {\n",
      "  tensor_nil_float16,\n",
      "  tensor0_float16(float16),\n",
      "  tensor1_float16(Tensor[(?), float16]),\n",
      "  tensor2_float16(Tensor[(?, ?), float16]),\n",
      "  tensor3_float16(Tensor[(?, ?, ?), float16]),\n",
      "  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),\n",
      "  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),\n",
      "  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),\n",
      "}\n",
      "\n",
      "type Tree[A] {\n",
      "  Rose(A, List[Tree[A]]),\n",
      "}\n",
      "\n",
      "type tensor_float64_t {\n",
      "  tensor_nil_float64,\n",
      "  tensor0_float64(float64),\n",
      "  tensor1_float64(Tensor[(?), float64]),\n",
      "  tensor2_float64(Tensor[(?, ?), float64]),\n",
      "  tensor3_float64(Tensor[(?, ?, ?), float64]),\n",
      "  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),\n",
      "  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),\n",
      "  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),\n",
      "}\n",
      "\n",
      "type List[A] {\n",
      "  Cons(A, List[A]),\n",
      "  Nil,\n",
      "}\n",
      "\n",
      "type tensor_uint16_t {\n",
      "  tensor_nil_uint16,\n",
      "  tensor0_uint16(uint16),\n",
      "  tensor1_uint16(Tensor[(?), uint16]),\n",
      "  tensor2_uint16(Tensor[(?, ?), uint16]),\n",
      "  tensor3_uint16(Tensor[(?, ?, ?), uint16]),\n",
      "  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),\n",
      "  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),\n",
      "  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),\n",
      "}\n",
      "\n",
      "type tensor_int8_t {\n",
      "  tensor_nil_int8,\n",
      "  tensor0_int8(int8),\n",
      "  tensor1_int8(Tensor[(?), int8]),\n",
      "  tensor2_int8(Tensor[(?, ?), int8]),\n",
      "  tensor3_int8(Tensor[(?, ?, ?), int8]),\n",
      "  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),\n",
      "  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),\n",
      "  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),\n",
      "}\n",
      "\n",
      "type Option[A] {\n",
      "  Some(A),\n",
      "  None,\n",
      "}\n",
      "\n",
      "type tensor_int64_t {\n",
      "  tensor_nil_int64,\n",
      "  tensor0_int64(int64),\n",
      "  tensor1_int64(Tensor[(?), int64]),\n",
      "  tensor2_int64(Tensor[(?, ?), int64]),\n",
      "  tensor3_int64(Tensor[(?, ?, ?), int64]),\n",
      "  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),\n",
      "  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),\n",
      "  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),\n",
      "}\n",
      "\n",
      "type tensor_uint8_t {\n",
      "  tensor_nil_uint8,\n",
      "  tensor0_uint8(uint8),\n",
      "  tensor1_uint8(Tensor[(?), uint8]),\n",
      "  tensor2_uint8(Tensor[(?, ?), uint8]),\n",
      "  tensor3_uint8(Tensor[(?, ?, ?), uint8]),\n",
      "  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),\n",
      "  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),\n",
      "  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),\n",
      "}\n",
      "\n",
      "type tensor_float32_t {\n",
      "  tensor_nil_float32,\n",
      "  tensor0_float32(float32),\n",
      "  tensor1_float32(Tensor[(?), float32]),\n",
      "  tensor2_float32(Tensor[(?, ?), float32]),\n",
      "  tensor3_float32(Tensor[(?, ?, ?), float32]),\n",
      "  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),\n",
      "  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),\n",
      "  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),\n",
      "}\n",
      "\n",
      "type tensor_int16_t {\n",
      "  tensor_nil_int16,\n",
      "  tensor0_int16(int16),\n",
      "  tensor1_int16(Tensor[(?), int16]),\n",
      "  tensor2_int16(Tensor[(?, ?), int16]),\n",
      "  tensor3_int16(Tensor[(?, ?, ?), int16]),\n",
      "  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),\n",
      "  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),\n",
      "  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),\n",
      "}\n",
      "\n",
      "type tensor_int32_t {\n",
      "  tensor_nil_int32,\n",
      "  tensor0_int32(int32),\n",
      "  tensor1_int32(Tensor[(?), int32]),\n",
      "  tensor2_int32(Tensor[(?, ?), int32]),\n",
      "  tensor3_int32(Tensor[(?, ?, ?), int32]),\n",
      "  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),\n",
      "  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),\n",
      "  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),\n",
      "}\n",
      "\n",
      "def @main(%token_embedding.weight: Tensor[(50000, 128), float32], %input0: Tensor[(4, 498), int64], %pos_embedding.weight: Tensor[(512, 128), float32], %trfm_blocks.0.mha.attentions.0.toqueries.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.toqueries.bias: Tensor[(128), float32], %trfm_blocks.0.mha.attentions.0.tokeys.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.tokeys.bias: Tensor[(128), float32], %trfm_blocks.0.mha.attentions.0.tovalues.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.attentions.0.tovalues.bias: Tensor[(128), float32], %trfm_blocks.0.mha.w_o.0.weight: Tensor[(128, 128), float32], %trfm_blocks.0.mha.w_o.0.bias: Tensor[(128), float32], %trfm_blocks.0.norm1.weight: Tensor[(128), float32], %trfm_blocks.0.norm1.bias: Tensor[(128), float32], %trfm_blocks.0.ff.0.weight: Tensor[(512, 128), float32], %trfm_blocks.0.ff.0.bias: Tensor[(512), float32], %trfm_blocks.0.ff.2.weight: Tensor[(128, 512), float32], %trfm_blocks.0.ff.2.bias: Tensor[(128), float32], %trfm_blocks.0.norm2.weight: Tensor[(128), float32], %trfm_blocks.0.norm2.bias: Tensor[(128), float32], %toprobs.weight: Tensor[(2, 128), float32], %toprobs.bias: Tensor[(2), float32]) -> Tensor[(4, 2), float32] {\n",
      "  %0 = cast(%input0, dtype=\"int32\") /* ty=Tensor[(4, 498), int32] */;\n",
      "  %1 = take(%token_embedding.weight, %0, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %2 = arange(0 /* ty=int64 */, 498 /* ty=int64 */, 1 /* ty=int64 */, start=meta[relay.Constant][0], stop=meta[relay.Constant][1], step=meta[relay.Constant][2], dtype=\"int64\") /* ty=Tensor[(498), int64] */;\n",
      "  %3 = cast(%2, dtype=\"int32\") /* ty=Tensor[(498), int32] */;\n",
      "  %4 = take(%pos_embedding.weight, %3, axis=0) /* ty=Tensor[(498, 128), float32] */;\n",
      "  %5 = expand_dims(%4, axis=0) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %6 = strided_slice(%5, begin=[0, 0, 0], end=[1, 498, 128], strides=[1, 1, 1]) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %7 = strided_slice(%6, begin=[0, 0, 0], end=[1, 498, 128], strides=[1, 1, 1]) /* ty=Tensor[(1, 498, 128), float32] */;\n",
      "  %8 = repeat(%7, repeats=4, axis=0) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %9 = add(%1, %8) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %10 = nn.dropout(%9, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %11 = %10.0;\n",
      "  %12 = zeros_like(%11) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %13 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %14 = transpose(%trfm_blocks.0.mha.attentions.0.toqueries.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %15 = reshape(%14, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %16 = broadcast_to(%15, meta[relay.attrs.InitOpAttrs][0]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %17 = transpose(%16, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %18 = nn.batch_matmul(%13, %17) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %19 = reshape(%18, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %20 = add(%19, %trfm_blocks.0.mha.attentions.0.toqueries.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %21 = reshape(%20, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %22 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %23 = transpose(%trfm_blocks.0.mha.attentions.0.tokeys.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %24 = reshape(%23, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %25 = broadcast_to(%24, meta[relay.attrs.InitOpAttrs][1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %26 = transpose(%25, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %27 = nn.batch_matmul(%22, %26) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %28 = reshape(%27, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %29 = add(%28, %trfm_blocks.0.mha.attentions.0.tokeys.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %30 = transpose(%29, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %31 = reshape(%30, newshape=[-1, 128, 498]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %32 = transpose(%31, axes=[0, 2, 1]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %33 = nn.batch_matmul(%21, %32) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %34 = reshape(%33, newshape=[4, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %35 = divide(%34, 11.3137f /* ty=float32 */) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %36 = nn.softmax(%35, axis=2) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %37 = reshape(%36, newshape=[-1, 498, 498]) /* ty=Tensor[(4, 498, 498), float32] */;\n",
      "  %38 = reshape(%11, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %39 = transpose(%trfm_blocks.0.mha.attentions.0.tovalues.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %40 = reshape(%39, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %41 = broadcast_to(%40, meta[relay.attrs.InitOpAttrs][2]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %42 = transpose(%41, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %43 = nn.batch_matmul(%38, %42) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %44 = reshape(%43, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %45 = add(%44, %trfm_blocks.0.mha.attentions.0.tovalues.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %46 = reshape(%45, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %47 = transpose(%46, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 498), float32] */;\n",
      "  %48 = nn.batch_matmul(%37, %47) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %49 = reshape(%48, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %50 = reshape(%49, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %51 = transpose(%trfm_blocks.0.mha.w_o.0.weight, axes=[1, 0]) /* ty=Tensor[(128, 128), float32] */;\n",
      "  %52 = reshape(%51, newshape=[-1, 128, 128]) /* ty=Tensor[(1, 128, 128), float32] */;\n",
      "  %53 = broadcast_to(%52, meta[relay.attrs.InitOpAttrs][3]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %54 = transpose(%53, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 128), float32] */;\n",
      "  %55 = nn.batch_matmul(%50, %54) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %56 = reshape(%55, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %57 = add(%56, %trfm_blocks.0.mha.w_o.0.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %58 = add(%12, %57) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %59 = add(%58, %11) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %60 = nn.layer_norm(%59, %trfm_blocks.0.norm1.weight, %trfm_blocks.0.norm1.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %61 = nn.dropout(%60, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %62 = %61.0;\n",
      "  %63 = reshape(%62, newshape=[-1, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %64 = transpose(%trfm_blocks.0.ff.0.weight, axes=[1, 0]) /* ty=Tensor[(128, 512), float32] */;\n",
      "  %65 = reshape(%64, newshape=[-1, 128, 512]) /* ty=Tensor[(1, 128, 512), float32] */;\n",
      "  %66 = broadcast_to(%65, meta[relay.attrs.InitOpAttrs][4]) /* ty=Tensor[(4, 128, 512), float32] */;\n",
      "  %67 = transpose(%66, axes=[0, 2, 1]) /* ty=Tensor[(4, 512, 128), float32] */;\n",
      "  %68 = nn.batch_matmul(%63, %67) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %69 = reshape(%68, newshape=[4, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %70 = add(%69, %trfm_blocks.0.ff.0.bias) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %71 = nn.relu(%70) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %72 = reshape(%71, newshape=[-1, 498, 512]) /* ty=Tensor[(4, 498, 512), float32] */;\n",
      "  %73 = transpose(%trfm_blocks.0.ff.2.weight, axes=[1, 0]) /* ty=Tensor[(512, 128), float32] */;\n",
      "  %74 = reshape(%73, newshape=[-1, 512, 128]) /* ty=Tensor[(1, 512, 128), float32] */;\n",
      "  %75 = broadcast_to(%74, meta[relay.attrs.InitOpAttrs][5]) /* ty=Tensor[(4, 512, 128), float32] */;\n",
      "  %76 = transpose(%75, axes=[0, 2, 1]) /* ty=Tensor[(4, 128, 512), float32] */;\n",
      "  %77 = nn.batch_matmul(%72, %76) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %78 = reshape(%77, newshape=[4, 498, 128]) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %79 = add(%78, %trfm_blocks.0.ff.2.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %80 = add(%79, %62) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %81 = nn.layer_norm(%80, %trfm_blocks.0.norm2.weight, %trfm_blocks.0.norm2.bias) /* ty=Tensor[(4, 498, 128), float32] */;\n",
      "  %82 = nn.dropout(%81, rate=0f) /* ty=(Tensor[(4, 498, 128), float32], Tensor[(4, 498, 128), float32]) */;\n",
      "  %83 = %82.0;\n",
      "  %84 = mean(%83, axis=[1]) /* ty=Tensor[(4, 128), float32] */;\n",
      "  %85 = transpose(%toprobs.weight, axes=[1, 0]) /* ty=Tensor[(128, 2), float32] */;\n",
      "  %86 = transpose(%85, axes=[1, 0]) /* ty=Tensor[(2, 128), float32] */;\n",
      "  %87 = nn.dense(%84, %86, units=2) /* ty=Tensor[(4, 2), float32] */;\n",
      "  %88 = add(%87, %toprobs.bias) /* ty=Tensor[(4, 2), float32] */;\n",
      "  nn.log_softmax(%88, axis=1) /* ty=Tensor[(4, 2), float32] */\n",
      "}\n",
      "\n",
      "#[metadata]\n",
      "{\n",
      "  \"root\": 1, \n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"type_key\": \"\"\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Map\", \n",
      "      \"keys\": [\n",
      "        \"relay.attrs.InitOpAttrs\", \n",
      "        \"relay.Constant\"\n",
      "      ], \n",
      "      \"data\": [2, 33]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [3, 8, 13, 18, 23, 28]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.attrs.InitOpAttrs\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"\", \n",
      "        \"shape\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [5, 6, 7]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.attrs.InitOpAttrs\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"\", \n",
      "        \"shape\": \"9\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [10, 11, 12]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.attrs.InitOpAttrs\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"\", \n",
      "        \"shape\": \"14\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [15, 16, 17]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.attrs.InitOpAttrs\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"\", \n",
      "        \"shape\": \"19\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [20, 21, 22]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.attrs.InitOpAttrs\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"\", \n",
      "        \"shape\": \"24\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [25, 26, 27]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"512\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.attrs.InitOpAttrs\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"\", \n",
      "        \"shape\": \"29\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [30, 31, 32]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"4\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"512\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"IntImm\", \n",
      "      \"attrs\": {\n",
      "        \"dtype\": \"int32\", \n",
      "        \"value\": \"128\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"Array\", \n",
      "      \"data\": [34, 35, 36]\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.Constant\", \n",
      "      \"attrs\": {\n",
      "        \"_checked_type_\": \"0\", \n",
      "        \"data\": \"0\", \n",
      "        \"span\": \"0\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.Constant\", \n",
      "      \"attrs\": {\n",
      "        \"_checked_type_\": \"0\", \n",
      "        \"data\": \"1\", \n",
      "        \"span\": \"0\"\n",
      "      }\n",
      "    }, \n",
      "    {\n",
      "      \"type_key\": \"relay.Constant\", \n",
      "      \"attrs\": {\n",
      "        \"_checked_type_\": \"0\", \n",
      "        \"data\": \"2\", \n",
      "        \"span\": \"0\"\n",
      "      }\n",
      "    }\n",
      "  ], \n",
      "  \"b64ndarrays\": [\n",
      "    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAABAAQAIAAAAAAAAAAAAAAAAAAAA\", \n",
      "    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAABAAQAIAAAAAAAAAPIBAAAAAAAA\", \n",
      "    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAAAAAABAAQAIAAAAAAAAAAEAAAAAAAAA\"\n",
      "  ], \n",
      "  \"attrs\": {\"tvm_version\": \"0.7.dev1\"}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#mhost = tvm.build(mod, target=target)\n",
    "print(mod.astext(show_meta_data=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Compiled Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph, lib and params into separate files\n",
    "from tvm.contrib import util\n",
    "\n",
    "LIB_PATH='saved_model/deploy_lib.tar'\n",
    "lib.export_library(LIB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_model/deploy_lib.tar'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the module back.\n",
    "loaded_lib = tvm.runtime.load_module(LIB_PATH)\n",
    "\n",
    "\n",
    "m = graph_runtime.GraphModule(loaded_lib[\"default\"](ctx))\n",
    "# Set inputs\n",
    "m.set_input(input_name, tvm.nd.array(input_data))\n",
    "# Execute\n",
    "m.run()\n",
    "# Get outputs\n",
    "tvm_output = m.get_output(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.nd.NDArray shape=(4, 2), cpu(0)>\n",
       "array([[-0.7326672 , -0.6551298 ],\n",
       "       [-0.7252913 , -0.66200423],\n",
       "       [-0.73297906, -0.6548413 ],\n",
       "       [-0.73238647, -0.65538967]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
